[{"employer_name":"Wattpad","employer_logo":"https:\/\/www.wattpad.com\/img\/logos\/wp-logo-orange.png","employer_website":"http:\/\/www.wattpad.com","employer_company_type":null,"job_publisher":"LinkedIn","job_id":"PHB2re4Gv4cAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer, Analytics","job_apply_link":"https:\/\/ca.linkedin.com\/jobs\/view\/data-engineer-analytics-at-wattpad-3594739979","job_apply_is_direct":false,"job_apply_quality_score":0.5546,"job_description":"Wattpad is a global multiplatform entertainment company whose vision is to entertain and connect the world through stories. Since 2006, we\u2019ve been on a mission to use the power of community and technology to unleash the full potential of stories to the world. Every month 85 million people around the world spend over 23 billion minutes on Wattpad to share and discover stories they can\u2019t find anywhere else. Our brand banner includes: Wattpad, Wattpad WEBTOON Studios, Wattpad Books and Wattpad Brand Partnerships. We\u2019re proudly based in Toronto, but our reach is global. Come build the future of entertainment and storytelling, and write your next chapter with us!\n\nWe are looking for a Data Engineer, Analytics to join our growing Data organization and support the Analytics squad. The squad's main focus is to partner with all of Wattpad's business units and product squads, to build ad-hoc reporting to metrics creation to forecasting and predictive insights projects. The goal is to advocate for and facilitate data-informed decision-making throughout the organization.\n\nIn this role, you will partner with data engineers, analysts and scientists. You will develop solutions and build analytics infrastructure to deliver trusted data. Data is critical to how we make decisions at Wattpad and you will play a key role in helping Wattpad continue to scale!\n\nWhat you'll do:\n\u2022 Build and own analytics infrastructure that delivers good quality data, reliably\n\u2022 Support the building of robust, scalable data ingestion pipelines\n\u2022 Develop complex data models and transformations that standardize analytics products\n\u2022 Provide technical leadership on data solutions that are forward looking\n\u2022 Establish best practices for data warehousing\n\u2022 Evaluate new tools, build prototypes and be an advocate for modern, scalable data infrastructure\n\nWhat we're looking for:\n\u2022 You have solid experience in designing schemas and data models for use in transformation and BI tools\n\u2022 You are comfortable building ETL\/ELT flows that extract data from various systems\n\u2022 You have a good understanding of data engineering best practices (batch data processing, streaming, etc.)\n\u2022 You understand software engineering fundamentals and principles\n\u2022 You are comfortable leading data architecture and design discussions\n\u2022 You have curiosity towards experimenting with new data tools\/methods and are abreast with the latest trends in data\n\u2022 Bonus: You have experience with DBT core\/DBT cloud and LookML\/Looker\n\nWattpad is conducting all interviews in a distributed manner using applicable third party software where needed and using visual interface tools such as Google Hangouts and Zoom.\n\nAbout Wattpad\n\nWho are we? Entrepreneurs and Do-ers. Our vision is to entertain and connect the world through stories, and our mission is to use the power of community and technology to unleash the full potential of stories to the world.\n\nWhat does that mean? We are visionaries, community builders, passionate problem solvers, storytellers, coffee snobs (tea drinkers, too!), curious by nature, and culturally diverse.\n\nWhat are we obsessed with? Our users. Solving complex problems and maximizing flow. Learning constantly. Building the next great storytelling product. Finding the greatest stories ever told. Dogs (and cats), coffee, and good snacks.\n\nHow do we work? Autonomously, collaboratively, respectfully. Balancing with work, family, and play...and all while having a great time.\n\nWattpad is a remote friendly company and encourages remote candidates to apply as long as they are located and authorized to work in either the US or Canada (excluding Quebec) as a precondition of employment. We are not able to sponsor applicants for work permits.\n\nIf you happen to live near the areas of either Toronto, Ontario or Halifax, Nova Scotia, you may also have the opportunity to work from our beautiful offices - 1 located in Downtown Toronto and the other in Halifax.\n\nCulture and Diversity\n\nWattpad is an equal opportunity employer. We do not discriminate. Period.\n\nWattpad welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. We have taken a leadership position on creating a culture and an organization that truly values diversity. We are committed to fostering a global team that reflects the diversity of the Wattpad community. At Wattpad, we believe cultural fit doesn\u2019t mean culturally identical, and diversity of thought helps us to challenge one another to think big and think differently. We consider employment applicants without regard to age, race, colour, national origin, citizenship, religion, creed, sex, sexual orientation, veteran status, marital status, disability status or any other protected status.\n\nIf you have any special needs or accessibility requirements, please let us know. We will do our utmost to accommodate, in accordance with applicable local legislation.\n\nDon\u2019t meet all the requirements? Studies show women and people of colour are less likely to apply to jobs if they do not meet all the qualifications. Therefore, in an effort to build a more diverse workplace, we encourage you to apply anyways. You might actually be the right person or you may be a good fit for a number of other openings we currently have.","job_is_remote":false,"job_posted_at_timestamp":1682979180,"job_posted_at_datetime_utc":"2023-05-01T22:13:00.000Z","job_city":"Toronto","job_state":"ON","job_country":"CA","job_latitude":43.653225,"job_longitude":-79.38319,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=PHB2re4Gv4cAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-31T22:13:00.000Z","job_offer_expiration_timestamp":1685571180.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"Restaurant Brands","employer_logo":"https:\/\/upload.wikimedia.org\/wikipedia\/en\/thumb\/3\/31\/Resturant_Brands_International.svg\/1200px-Resturant_Brands_International.svg.png","employer_website":"http:\/\/www.rbi.com","employer_company_type":"Restaurant","job_publisher":"Careers | Restaurant Brands International","job_id":"dc-gsTIx27gAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer, Tim Hortons, Canada","job_apply_link":"https:\/\/careers.rbi.com\/global\/en\/job\/5727700002\/Data-Engineer-Tim-Hortons-Canada","job_apply_is_direct":true,"job_apply_quality_score":0.8511,"job_description":"About Restaurant Brands International:\n\nRestaurant Brands International Inc. is one of the world's largest quick service restaurant companies with more than $35 billion in annual system-wide sales and over 28,000 restaurants in more than 100 countries. RBI owns four of the world's most prominent and iconic quick service restaurant brands \u2013 TIM HORTONS\u00ae, BURGER KING\u00ae, POPEYES\u00ae and FIREHOUSE SUBS\u00ae. These independently operated brands have been serving their respective guests, franchisees and communities for decades. Through its Restaurant Brands for Good framework, RBI working towards its goal of improving sustainable outcomes related to its food, the planet, and people and communities.\n\nTim Hortons\u00ae is one of North America's largest restaurant chains operating in the quick service segment, with more than 4,800 system wide restaurants located in Canada, the United States and around the world.\n\nWe are currently looking for experienced and motivated Data Engineering Specialist to join our Advanced Analytics team. The Data Engineer will report directly to Data Engineering Lead with the role principally located in Toronto King St office.\n\nWhat You\u2019ll Do:\n\u2022 Design, development and maintenance of big data pipelines\n\u2022 Integration with Enterprise Data Warehouse and other applications that generate and consume data from Big Data platforms \u2013 Databricks, mParticle, Braze,\n\u2022 Implement best practices across data industry to standardize and automate data pipelines\n\u2022 Understand business needs and coordinate with different stakeholders within and outside organization to translate business needs into technical requirements\n\u2022 Solve our data problems using optimal ETL techniques across structured and unstructured data sources\n\u2022 Implement security and governance guidelines and ensure compliance to regulations\n\nWho You Are:\n\u2022 Have strong problem-solving skills with an emphasis on product development.\n\u2022 Take ownership, with the ability to manage in an environment of quick change to help strategic moves in this rapidly evolving QSR environment.\n\u2022 Are outcome focused, critical thinkers with the ability to analyze and visualize, to ensure continuous improvement across our entire business.\n\u2022 Have ability to work in a fast-paced Agile environment and is transparent and professional in their communication If you\u2019re curious, ready to take on new challenges and open to doing things differently to help us evolve rapidly, then this is the place to\n\nRequirements:\n\u2022 Minimum under graduation degree or equivalent in Computer Science, Engineering, Statistics, Mathematics, or related technical field\n\u2022 5+ years experience in designed complex ETL solutions\n\u2022 3+ years experience in Big Data Space \u2013 Apache Spark, Hadoop, HDFS\n\u2022 3+ years experience in programming languages like Python, Scala, R, SQL\n\u2022 Ability to write complex SQL statements to query heterogenous big data sets to process, filter and present large quantities of data\n\u2022 Ability to integrate different data sources and familiarity with data modelling concepts\n\u2022 Knowledge of Databricks, Structured Streaming is an Asset\n\u2022 Good understanding of cloud platform concepts - AWS, such as EC2, S3, Dynamodb and Lambda\n\u2022 Experience with Loyalty Programs an asset\n\nBenefits:\n\u2022 Pension matching\n\u2022 Hybrid\n\u2022 Health benefits (medical, dental)\n\u2022 Short- and long-term disability\n\u2022 Comprehensive global paid parental leave\n\u2022 Telehealth\n\u2022 Employee Assistance Program\n\u2022 Discounted Gym Memberships\n\nRestaurant Brands International and all of its affiliated companies (collectively, RBI) are equal opportunity and affirmative action employers that do not discriminate on the basis of race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or veteran status, or any other characteristic protected by local, state, provincial or federal laws, rules, or regulations. RBI's policy applies to all terms and conditions of employment. Accommodation is available for applicants with disabilities upon request.\n\n#LI-Hybrid","job_is_remote":false,"job_posted_at_timestamp":1678898754,"job_posted_at_datetime_utc":"2023-03-15T16:45:54.000Z","job_city":"Toronto","job_state":"ON","job_country":"CA","job_latitude":43.653225,"job_longitude":-79.38319,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=dc-gsTIx27gAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":60,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":["ETL","Big Data","SQL","Scala","HDFS","Python","Programming Languages","agile","Apache Spark","Data Engineering","Integration","databricks","Applications","Big Data Platforms","Cloud Platform","AWS","Structured","cloud platform concepts","data modelling concepts","Engineering","Enterprise Data Warehouse","Hybrid","Computer Science","Mathematics","Governance","problem-solving","Product Development","Statistics","Outcome Focused","Security","Software Engineer Intermediate - Product Development","Senior Manager - Software Development & Product Manager","Lead Engineer - E-commerce","UX Designer & Architect & Developer","Software Engineer - Text Analytics","Junior Mid Java Software Engineer","Web UI Designer & Developer","Senior Manager - Software Engineering","Software Engineering Consultant","Senior Back End Engineer"],"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"Curinos","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTq0uSqEd0aU3cCxl_8l_engmXWHWiPafDjeN19&s=0","employer_website":"http:\/\/curinos.com","employer_company_type":null,"job_publisher":"LinkedIn","job_id":"CAL0o7sM8uAAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer (Remote)","job_apply_link":"https:\/\/ca.linkedin.com\/jobs\/view\/data-engineer-remote-at-curinos-3544869920","job_apply_is_direct":false,"job_apply_quality_score":0.5776,"job_description":"We find that the most successful candidates for the Data Engineerposition are natural and relentless problem solvers who are passionate about working with data to solve business problems. These individuals demonstrate ease with quantitative analysis, can work well as part of small multi-disciplinary teams, have a keen interest in software engineering and are passionate about developing leading edge analytical business applications.\n\nOur Data Engineers are part of the engineering team responsible for data architecture, backend development and maintenance of our proprietary decision support software applications. They work closely with product management and the front end development team to ensure that our products are constantly improving and have leading edge functionality.\n\nJob responsibilities include:\n\u2022 Engage with product owner to understand requirements about new features\n\u2022 Help navigate the cloud migration journey using a well-architected path\n\u2022 Support complex business logic encoded into the data\/analytics platform\n\u2022 Work with data science and product teams to design solutions to meet their use cases\n\u2022 Design pipelines and processes using Scala and Spark SQL\n\u2022 Support an ecosystem of proprietary and third-party tools and technologies to empower high performing ML\/data engineering and data science teams\n\u2022 Support continuous build and release process\n\u2022 Research and present emerging technologies and design patterns to engineering leadership\n\nQualifications\n\nDesired Skills & Expertise\n\nAspiring candidates should have the following background, skills and characteristics:\n\u2022 Bachelor\u2019s degree, preferably in computer science, or engineering field\n\u2022 4+ years of ETL experience using flat files to transposed Data Models\n\u2022 4+ years of working experience in Python and Scala.\n\u2022 Experience in troubleshooting and debugging SQL and Scala code\n\u2022 Working knowledge of enterprise data platforms like Databricks and\/or Snowflake\n\u2022 Exposure to Spark\n\u2022 Experience supporting and working with cross-functional teams in a dynamic environment.\n\u2022 Strong project management and organizational skills.\n\u2022 Self\u2013discipline and willingness to learn\n\u2022 Excellent verbal and written communication skills\n\nAdditional Information\n\nWhy work at Curinos?\n\u2022 Competitive benefits, including a range of Financial, Health and Lifestyle benefits tochoosefrom\n\u2022 Flexible working options, including home working, flexiblehoursand part time options,depending onthe rolerequirements\u2013 please ask!\n\u2022 Competitive annual leave,floatingholidays,volunteeringdaysand a day off for your birthday!\n\u2022 Learning and development tools to assist with your career development\n\u2022 Work with industry leadingSubject Matter Expertsandspecialist products\n\u2022 Regular social events and networking opportunities\n\u2022 Collaborative, supportive culture, includinganactiveDE&Iprogram\n\u2022 EmployeeAssistanceProgramwhich provides expert third-party advice on wellbeing, relationships, legal and financial matters,as well as access to counselling services\n\nApplying\n\nWe know that sometimes the 'perfect candidate' doesn't exist, and that people can be put off applying for a job if they don'tmeetall the requirements. If you're excited about working for us and haverelevantskills or experience, please goaheadand apply. You could be just what we need!\n\nIf you need any adjustments to support your application, such as information in alternative formats,special requirements to access our buildingsor adjusted interview formatsplease\u202fcontact usatcareers@curinos.comandwe\u2019ll do everything we can to help.\n\nInclusivityat Curinos\n\nWe believe strongly in the value of diversity and creating supportive, inclusive environments where our colleagues can succeed.\u202f As such, Curinos\u202fis proud to be an Equal Opportunity Employer.\u202fWe do not discriminateon the basis ofrace,colour, ancestry, national origin, religion, or religious creed, mental or physical disability,medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other protected characteristics","job_is_remote":true,"job_posted_at_timestamp":1682545037,"job_posted_at_datetime_utc":"2023-04-26T21:37:17.000Z","job_city":"Toronto","job_state":"ON","job_country":"CA","job_latitude":43.653225,"job_longitude":-79.38319,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=CAL0o7sM8uAAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-30T18:58:32.000Z","job_offer_expiration_timestamp":1685473112.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":48,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":true,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"Ample Insight Inc.","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRWiB4tMwLSqlZvZszN1imNCQfjmKEUlaYCMBHJ&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"Ai-Jobs.net","job_id":"fy-vwEzYQbEAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https:\/\/ai-jobs.net\/job\/48775-data-engineer\/","job_apply_is_direct":false,"job_apply_quality_score":0.6653,"job_description":"Company DescriptionYou will join a world-class team of engineers and data scientists from Facebook, Uber, Amazon and Google. We are a fast growing consulting firm based in Toronto with clients ranging from leading startups building impactful technologies to Fortune 500 companies looking to scale their engineering and data capabilities. Job DescriptionWe are looking for a data engineer who is passionate about analytics and helping companies build and scale data. You enjoy working with data and are motivated to produce high quality data tools and pipelines that help empower other data scientists. You are experienced in architecting data ETL workflows and schemas. Critical thinking and problem-solving skills are essential for this role.QualificationsBS (or higher, e.g., MS, or PhD) in Computer Science, Engineering, Math, or StatisticsHands on experience working with user engagement, social, marketing, and\/or finance dataProficient in Python (i.e. Pandas, Numpy, scikit-learn, etc), R, TensorFlow, amongst other data science related tools and librariesExtensive experience working on relational databases, designing complex data schemas, and writing SQL queriesDeep knowledge on performance tuning of ETL Jobs, SQL, and databasesWorking knowledge of SnowflakeExperience working with Airflow is a strong plusDevops experiences is a plusAdditional InformationWe have very competitive compensation.Work on cool projects based on your interests and skills. We believe in accountability and NOT micro-management.","job_is_remote":false,"job_posted_at_timestamp":1682614701,"job_posted_at_datetime_utc":"2023-04-27T16:58:21.000Z","job_city":"Toronto","job_state":"ON","job_country":"CA","job_latitude":43.653225,"job_longitude":-79.38319,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=fy-vwEzYQbEAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-11T00:00:00.000Z","job_offer_expiration_timestamp":1686441600.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":59888.0,"job_max_salary":135000.0,"job_salary_currency":"USD","job_salary_period":"YEAR","job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"Dataiku","employer_logo":"https:\/\/upload.wikimedia.org\/wikipedia\/en\/9\/91\/Dataiku_logo.png","employer_website":"http:\/\/www.dataiku.com","employer_company_type":"Information","job_publisher":"Wellfound","job_id":"fr2icExjjwIAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Scientist","job_apply_link":"https:\/\/wellfound.com\/company\/dataiku\/jobs\/2663448-data-scientist","job_apply_is_direct":true,"job_apply_quality_score":0.5664,"job_description":"The role of a Data Scientist at Dataiku is quite unique. Our Data Scientists not only code up solutions to real-world problems, but also participate in client-facing endeavors throughout the customer journey. This includes supporting their discovery of the platform, helping integrate Dataiku with other tools and technologies, some user training, and co-developing data science projects from design to deployment.\n\nJust as the non-technical skills are important, so too are the technical. Our Data Scientists work on the Dataiku platform every day. Aside from the visual tools, our team uses mostly python, with occasional work in other languages (e.g., R, SQL, pyspark, JavaScript, etc.). An ideal candidate is excited to learn complex new technologies and modeling techniques while being able to explain their work to other data scientists and clients.\n\nIn this role you'll help the team:\n\u2022 Co-develop production-level data science projects with our customers.\n\u2022 Analyze and investigate various kinds of data and machine learning applications across industries and use cases.\n\u2022 Help users discover and master the Dataiku platform, via user training, office hours, and ongoing consultative support.\n\u2022 Provide data science expertise both to customers and internally to Dataiku\u2019s sales and marketing teams.\n\u2022 Develop custom Python or R-based \u201cplugins\u201d in collaboration with Solutions, R&D, and Product teams, to enhance Dataiku\u2019s functionality.\n\nYou might be a good fit for the role if you have:\n\u2022 Curiosity and a desire to learn new topics and skills.\n\u2022 Empathy for others and an eagerness to share your knowledge and expertise with your colleagues, Dataiku\u2019s customers, and the general public.\n\u2022 The ability to clearly explain complex topics to technical as well as non-technical audiences.\n\u2022 1\u2013 4 years\u2019 of experience with ML tools (e.g., Python, R).\n\u2022 1 \u2013 4 years\u2019 of experience building models.\n\u2022 Familiarity with data visualization in python, R.\n\u2022 Understanding of underlying data systems such as Cloud architectures, Hadoop, or SQL.\n\u2022 Being bilingual in French would be a plus.\n\u2022 Location: Must be located on the East Coast or Central regions of the United States or Canada and can work remotely (20% client-based travel).\n\nTechnical skills that may help you in the role:\n\u2022 Experience with Consulting and\/or Customer-facing Data Science roles.\n\u2022 Experience with Data Engineering or MLOps.\n\u2022 Experience developing WebApps in Javascript, RShiny, or Dash.\n\u2022 Experience building APIs.\n\u2022 Experience using enterprise data science tools.\n\u2022 Passion for teaching or public speaking.\n\n#LI-Remote\n\nDataiku focuses on Enterprise Software, Analytics, Machine Learning, Big Data, and Artificial Intelligence. Their company has offices in New York City, New York, Denver, Dubai, and Singapore. They have a very large team that's between 1001-5000 employees. To date, Dataiku has raised $837.29M of funding; their latest round was closed on December 2022.\n\nYou can view their website at http:\/\/www.dataiku.com\/ or find them on Twitter, Facebook, and LinkedIn.","job_is_remote":false,"job_posted_at_timestamp":1683064038,"job_posted_at_datetime_utc":"2023-05-02T21:47:18.000Z","job_city":null,"job_state":null,"job_country":"US","job_latitude":37.09024,"job_longitude":-95.71289,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=fr2icExjjwIAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-08-03T05:44:48.000Z","job_offer_expiration_timestamp":1691041488.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":12,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Curiosity and a desire to learn new topics and skills","Empathy for others and an eagerness to share your knowledge and expertise with your colleagues, Dataiku\u2019s customers, and the general public","The ability to clearly explain complex topics to technical as well as non-technical audiences","1\u2013 4 years\u2019 of experience with ML tools (e.g., Python, R)","1 \u2013 4 years\u2019 of experience building models","Familiarity with data visualization in python, R","Understanding of underlying data systems such as Cloud architectures, Hadoop, or SQL","Location: Must be located on the East Coast or Central regions of the United States or Canada and can work remotely (20% client-based travel)","Experience with Consulting and\/or Customer-facing Data Science roles","Experience with Data Engineering or MLOps","Experience developing WebApps in Javascript, RShiny, or Dash","Experience building APIs","Experience using enterprise data science tools","Passion for teaching or public speaking"],"Responsibilities":["This includes supporting their discovery of the platform, helping integrate Dataiku with other tools and technologies, some user training, and co-developing data science projects from design to deployment","Aside from the visual tools, our team uses mostly python, with occasional work in other languages (e.g., R, SQL, pyspark, JavaScript, etc.). An ideal candidate is excited to learn complex new technologies and modeling techniques while being able to explain their work to other data scientists and clients","Co-develop production-level data science projects with our customers","Analyze and investigate various kinds of data and machine learning applications across industries and use cases","Help users discover and master the Dataiku platform, via user training, office hours, and ongoing consultative support","Provide data science expertise both to customers and internally to Dataiku\u2019s sales and marketing teams","Develop custom Python or R-based \u201cplugins\u201d in collaboration with Solutions, R&D, and Product teams, to enhance Dataiku\u2019s functionality"]},"job_job_title":"Data scientist","job_posting_language":"en","job_onet_soc":"15111100","job_onet_job_zone":"5"},{"employer_name":"Software International","employer_logo":null,"employer_website":null,"employer_company_type":null,"job_publisher":"ZipRecruiter","job_id":"f6C4BNDndQgAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer\/Analyst","job_apply_link":"https:\/\/www.ziprecruiter.com\/c\/Software-International\/Job\/Data-Engineer-Analyst\/-in-Saint-Catherines,PE?jid=356b2f944fcba822","job_apply_is_direct":true,"job_apply_quality_score":0.6784,"job_description":"Our client is an Government Crown Corporation entity in Canada and they are looking to add a Data Engineer\/Analyst who has a strong background with Python, Databricks, Power BI and\n\nAzure Data Lakes.\n\nRole: Data Engineer\/Analyst\n\nType: Contract\n\nDuration: 12 months\n\nLocation: Remote\n\nClient: Canada Government\n\nNumber of openings: 1\n\nSkills\n\nExperience and Skill Set Requirements\n\nEvaluation Criteria\n\nData Storage and Preparation - 35%\n\nThe candidate must demonstrate their experience with Azure Storage, Azure Data Lake Azure SQL DB, Azure Synapse and Azure Analysis Service structures in real world implementations\n\nData Pipelines - 35%\n\nThe candidate must demonstrate their experience with automating data pipelines using appropriate Microsoft Azure Platform\/Technologies (Python, Databricks and Azure Data Factory)\n\nData Analytics - 15%\n\nThe candidate must demonstrate their experience with Power BI reports and dashboards\n\nKnowledge Transfer - 15%\n\nThe candidate must demonstrate experience in conducting knowledge transfer sessions and building documentation for technical staff related to architecting, designing, and implementing end to end analytics solutions\n\nMust Haves:\n\u2022 Python\n\u2022 Databricks\n\u2022 Power BI\n\u2022 Azure Data Lake","job_is_remote":true,"job_posted_at_timestamp":1648045378,"job_posted_at_datetime_utc":"2022-03-23T14:22:58.000Z","job_city":"Saint Catherines","job_state":"PE","job_country":"CA","job_latitude":46.370373,"job_longitude":-62.21052,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=f6C4BNDndQgAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-02T00:00:00.000Z","job_offer_expiration_timestamp":1685664000.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":null,"job_posting_language":"en","job_onet_soc":"43911100","job_onet_job_zone":"4"},{"employer_name":"Sun Life","employer_logo":"https:\/\/www.sunlife.ca\/content\/dam\/sunlife\/folder1\/Sun_Life_weblogo_127x31.svg","employer_website":"http:\/\/www.sunlife.com","employer_company_type":"Finance","job_publisher":"LinkedIn","job_id":"9_9r93HiARUAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer (Security Analytics)","job_apply_link":"https:\/\/ca.linkedin.com\/jobs\/view\/data-engineer-security-analytics-at-sun-life-3586542162","job_apply_is_direct":false,"job_apply_quality_score":0.5663,"job_description":"You are as unique as your background, experience and point of view. Here, you\u2019ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world.\n\nJob Description:\n\nAs a member of the Security Analytics team, you will play a pivotal role in working closely with our partners to enable threat intelligence, internal threat identification, predictive modelling, business intelligence and deep dive analytics to understand and identify new threats and incidents to make client data safer. As a security analytics Data Engineer you will join a team that leverages and is on a journey of quickly enhancing our Big Data and Cloud capabilities to enable various use cases by ensuring there is a solid data foundation in place to support data mining, strategic insight and automated capability enablement.\n\nGiven this mandate, the role requires 1-2+ years of intermediate experience in data management\/programming and an understanding of the data needs of analytics and business and new technologies in the world of data.\n\nNote: The ability to attain Reliability Status Clearance for this role is essential. When you are required to apply for this clearance, you must have lived continuously in Canada for the last 5+ years at the time of your clearance application. No exceptions please.\n\nWhat will you do?\n\u2022 Work with the core security analytics team (data engineers and Business intelligence (BI) specialists) for data ingestion, management, AWS infra management and user 360s\n\u2022 Build data pipelines using AWS services that clean and structure data sets into a readable and searchable format for reporting, data science, analytics, and ad-hoc querying.\n\u2022 Maintain a large and complex data repository that provides accurate and reliable data to support reporting and insights about the user behavior.\n\u2022 Develop a strong understanding of the insights roadmap with the focus on providing data engineering solutions and continuous platform improvements to support real-time analytics.\n\u2022 Work intimately building a user data model to create easy access to user data and behavior.\n\u2022 Deepen the organizations understanding of user level data and provide expert guidance on how best to leverage data to provide actionable insights.\n\u2022 Execute on business data requests ensuring requests are aligned to Information Security priorities and the request fulfillment meets the stakeholder needs.\n\u2022 Demonstrates business values via PoC and promoting PoC to production.\n\u2022 Collaborates well in an agile environment to understand objectives and develop data solutions that deliver best in class, engaging and highly relevant experiences.\n\nWhat do you need to succeed?\n\u2022 Bachelor\u2019s Degree in Computer Science is preferred.\n\u2022 SQL\/Python Programming along with experience in database technologies with 1-2 years of hands-on experience\n\u2022 Experience in data, analytics technology with relevant experience in data modelling.\n\u2022 Some experience is required on cloud technologies. Good to have AWS skills like S3, Glue, Lambda, Redshift\n\u2022 Able to understand the structure and build processes to build a data repository (includes basic ETL type processes, QA, data model etc.) with expertise with Python\/ Spark\/ Scala\/ Glue\/ Lambda\/ RedShift or similar technologies. Knowledge of Java or any OOP is a Plus.\n\u2022 As a self-starter and someone who champions improvements, you will be expected to bring new ideas.\n\u2022 Work and coordinate on projects from initiation through planning, requirements, construction to implementation and post-implementation reviews.\n\u2022 Experience working within the Agile methodology.\n\u2022 Good communication skills and a team player\n\u2022 Information Security background is a PLUS but not mandatory.\n\nThe Base Pay range is for the primary location for which the job is posted. It may vary depending on the work location of the successful candidate or other factors. In addition to Base Pay, eligible Sun Life employees participate in various incentive plans, payment under which is discretionary and subject to individual and company performance. Certain sales focused roles have sales incentive plans based on individual or group sales results.\n\nDiversity and inclusion have always been at the core of our values at Sun Life. A diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. We welcome applications from qualified individuals from all backgrounds.\n\nPersons with disabilities who need accommodation in the application process or those needing job postings in an alternative format may e-mail a request to thebrightside@sunlife.com.\n\nAt Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.\n\nWe thank all applicants for showing an interest in this position. Only those selected for an interview will be contacted.\n\nSalary Range:\n\n58,700\/58 700 - 93,900\/93 900\n\nJob Category:\n\nIT - Technology Services\n\nPosting End Date:","job_is_remote":false,"job_posted_at_timestamp":1682701479,"job_posted_at_datetime_utc":"2023-04-28T17:04:39.000Z","job_city":null,"job_state":"ON","job_country":"CA","job_latitude":51.253777,"job_longitude":-85.32321,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=9_9r93HiARUAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-28T17:04:39.000Z","job_offer_expiration_timestamp":1685293479.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":12,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"11302100","job_onet_job_zone":"4"},{"employer_name":"Wattpad","employer_logo":"https:\/\/www.wattpad.com\/img\/logos\/wp-logo-orange.png","employer_website":"http:\/\/www.wattpad.com","employer_company_type":null,"job_publisher":"Wellfound","job_id":"P1oVKy4cWtoAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer, Analytics","job_apply_link":"https:\/\/wellfound.com\/company\/wattpad\/jobs\/2662146-data-engineer-analytics","job_apply_is_direct":true,"job_apply_quality_score":0.5735,"job_description":"Wattpad is a global multiplatform entertainment company whose vision is to entertain and connect the world through stories. Since 2006, we\u2019ve been on a mission to use the power of community and technology to unleash the full potential of stories to the world. Every month 85 million people around the world spend over 23 billion minutes on Wattpad to share and discover stories they can\u2019t find anywhere else. Our brand banner includes: Wattpad, Wattpad WEBTOON Studios, Wattpad Books and Wattpad Brand Partnerships. We\u2019re proudly based in Toronto, but our reach is global. Come build the future of entertainment and storytelling, and write your next chapter with us!\n\nWe are looking for a Data Engineer, Analytics to join our growing Data organization and support the Analytics squad. The squad's main focus is to partner with all of Wattpad's business units and product squads, to build ad-hoc reporting to metrics creation to forecasting and predictive insights projects. The goal is to advocate for and facilitate data-informed decision-making throughout the organization.\n\nIn this role, you will partner with data engineers, analysts and scientists. You will develop solutions and build analytics infrastructure to deliver trusted data. Data is critical to how we make decisions at Wattpad and you will play a key role in helping Wattpad continue to scale!\n\nWhat you'll do:\n\u2022 Build and own analytics infrastructure that delivers good quality data, reliably\n\u2022 Support the building of robust, scalable data ingestion pipelines\n\u2022 Develop complex data models and transformations that standardize analytics products\n\u2022 Provide technical leadership on data solutions that are forward looking\n\u2022 Establish best practices for data warehousing\n\u2022 Evaluate new tools, build prototypes and be an advocate for modern, scalable data infrastructure\n\nWhat we're looking for:\n\u2022 You have solid experience in designing schemas and data models for use in transformation and BI tools\n\u2022 You are comfortable building ETL\/ELT flows that extract data from various systems\n\u2022 You have a good understanding of data engineering best practices (batch data processing, streaming, etc.)\n\u2022 You understand software engineering fundamentals and principles\n\u2022 You are comfortable leading data architecture and design discussions\n\u2022 You have curiosity towards experimenting with new data tools\/methods and are abreast with the latest trends in data\n\u2022 Bonus: You have experience with DBT core\/DBT cloud and LookML\/Looker\n\nWattpad focuses on Mobile, Digital Media, Social Media, Entertainment, and Publishing. Their company has offices in Toronto. They have a large team that's between 201-500 employees. To date, Wattpad has raised $117.8M of funding; their latest round was closed on January 2018.\n\nYou can view their website at https:\/\/www.wattpad.com\/ or find them on Twitter, Facebook, and LinkedIn.","job_is_remote":false,"job_posted_at_timestamp":1683007854,"job_posted_at_datetime_utc":"2023-05-02T06:10:54.000Z","job_city":null,"job_state":"NS","job_country":"CA","job_latitude":44.69226,"job_longitude":-62.65719,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=P1oVKy4cWtoAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-08-02T21:16:44.000Z","job_offer_expiration_timestamp":1691011004.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"BCE","employer_logo":null,"employer_website":null,"employer_company_type":null,"job_publisher":"ZipRecruiter","job_id":"4P-Ve2RMltUAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Senior Data Engineer","job_apply_link":"https:\/\/www.ziprecruiter.com\/c\/BCE\/Job\/Senior-Data-Engineer\/-in-Mississauga,ON?jid=e9a3b5bf47dbc65e","job_apply_is_direct":false,"job_apply_quality_score":0.5649,"job_description":"Req Id: 410879\n\nAt Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content - we advance how Canadians connect with each other and the world.\n\nIf you're ready to bring game-changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the Bell team.\n\nThe Finance Team manages the performance and risk profile of Bell, ensuring the needs of customers, investors and employees are balanced with long-term business success. We work closely with internal and external stakeholders to develop and execute plans that help the company achieve its strategic objectives and ensure financial sustainability.\n\nA Senior Data Engineer reporting to the Director of Finance, you will need to consult with various stakeholders to understand business and technology challenges, design solutions in partnership with other subject matter experts. The ideal candidate will deliver solutions that improve Finance efficiencies and insights. Using your Leadership, technical, Business Intelligence and Finance skills, you will build tools to improve speed and accuracy in reports and generate insights that will allow Finance Operations to analyze, predict and optimize business results.\n\nIn particular, you will lead a team to create solutions and insight that combine, transform, analyze, share and catalyze consumption of financial results and related performance KPIs. The ideal candidate will leverage their leadership, technical, business, digital and creative competencies to drive information and insight from the large amount of data stored within our environments reporting status to the Senior Leadership.\n\nThe ideal candidate will leverage your natural curiosity, in testing and learning various tools, models, media and design as you continually look for new ways to glean key insights from the data, display results, and engage the stakeholder community with relevant solutions.\n\nThis unique position will expose you to the finance, BI, visualization and analytics fields. Leveraging leading edge enterprise technologies, process and governance will enable you to gather and share valuable information allowing us to better evaluate operational strategies while at the same time, from a finance perspective, allowing us to determine potential impact on future financial results.\n\nWorking individually and leading a team, you will provide accurate and useful information to the appropriate audiences.\n\nThe opportunity to communicate and work with employees & senior finance leadership from across the company, advocating the D&A CoE vision, will provide excellent networking opportunities.\n\nResponsibilities:\nLead a team of Data Engineers & Data Analyst\nCreate and maintain optimal data pipeline architecture\nAssemble large, complex data sets that meet functional \/ non-functional business requirements.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL 'big data' technologies.\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\nWork with stakeholders to assist with data-related technical issues and support their data infrastructure needs.\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\nWork with data and analytics experts to strive for greater functionality in our data systems.\n\nCritical Qualifications & Experience:\nCandidate with 5+ years of senior experience working in the telecom industry on complex data sets\nStrong leadership and high tolerance of ambiguity\nPolished written and verbal communication skills\nExperience leading team to build and optimize 'big data' data pipelines, architectures and data sets\nProven Leadership and business acumen, with demonstrated ability to influence and to be a trusted advisor to senior management\nAdvanced working SaS knowledge and experience working with relational databases, query authoring (PROC SQL).\nAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\nStrong analytic skills related to working with unstructured datasets.\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management.\nA successful history of manipulating, processing and extracting value from large disconnected datasets.\nStrong organizational and communication skills.\nExperience supporting and working with cross-functional teams in a dynamic environment.\nWe are looking for a candidate with 3+ years of experience in a Data Engineer role\nExperience with relational databases SaS, Teradata, Oracle & MS SQL.\n\nOther Qualifications & Experience:\nInternal Bell systems knowledge required (ie: P77, PBW, Network Capital)\nExperience with data pipeline and workflow management tools.\nGraduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software\/tools: Alteryx, SaS EG, SQL Assistant, MS Office\nExperience with big data tools: Hadoop, Spark, Kafka, \"Cloud computing solutions\", an asset\nExperience with object-oriented\/object function scripting languages: Python, Java, C++, Scala, etc.\n\n#EmployeeReferralProgram\n\nBilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.\n\nAdditional Information:\n\nPosition Type: Management\nJob Status: Regular - Full Time\nJob Location: Canada : Ontario : Mississauga || Canada : Ontario : Ottawa || Canada : Ontario : Toronto || Canada : Quebec : Montreal\nFlexible work profile: Mobile\nApplication Deadline: 05\/11\/2023\n\nPlease apply directly online to be considered for this role. Applications through email will not be accepted.\n\nAt Bell, we don't just accept difference - we celebrate it. We're committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.\n\nAccommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.\n\nCreated: Canada, ON, Mississauga\n\n#Talent #Indeed #Tech\n\nBell, one of Canada's Top 100 Employers.","job_is_remote":false,"job_posted_at_timestamp":1682660280,"job_posted_at_datetime_utc":"2023-04-28T05:38:00.000Z","job_city":"Mississauga","job_state":"ON","job_country":"CA","job_latitude":43.589046,"job_longitude":-79.64412,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=4P-Ve2RMltUAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-28T00:00:00.000Z","job_offer_expiration_timestamp":1685232000.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":60,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"President's Choice Financial","employer_logo":"https:\/\/www.pcfinancial.ca\/docs\/default-source\/assets\/logo-header-en.svg?sfvrsn=6acc4fb4_24","employer_website":"https:\/\/www.pcfinancial.ca\/en","employer_company_type":"Finance","job_publisher":"LinkedIn","job_id":"VDWig3go7kgAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https:\/\/ca.linkedin.com\/jobs\/view\/data-engineer-at-president-s-choice-financial-3585960539","job_apply_is_direct":false,"job_apply_quality_score":0.5744,"job_description":"Referred applicants should not apply directly to this role.\n\nAll referred applicants must first be submitted through Workday by a current Loblaw Colleague.\n\nLocation:\n\n500 Lakeshore Blvd. West, Toronto, Ontario, M5V 2V9\n\nWhen you hire great people, great things can happen.\n\nPC Financial offers unprecedented value to Canadians through payment products. We're a different kind of bank with a different type of team\u2014we\u2019re collaborative and supportive and have the freedom and responsibility to thrive. Our purpose is to make the everyday simple and better for our customers, and we strive to make every dollar worth more.\n\nProudly serving over 3 million customers, PC Financial continues to grow by offering payment solutions and services that reward our customers every day. As a subsidiary of Loblaws Company Inc., we share the CORE values of Care, Ownership, Respect and Excellence. We are dedicated to helping Canadians Live Life Well. Join us on our journey.\n\nOur mission is to build the PC Bank Payment & Rewards Data Platform, which would serve as an integrated data platform to perform complex big-data processing, advanced analytics, and machine learning. The Data Engineer position is a fantastic opportunity to join our expanding PC Bank Payment & Rewards Engineering team.\n\nThe Data Engineering team is looking for passionate engineers working in a fast-paced organization using Agile\/Scrum methodology to deliver excellent solutions for our demanding customer service, operations requirements, and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy.\n\nSome Of The Challenges The Candidate Would Tackle Are\n\nYou will participate in defining technical solutions, code architectures, and will be responsible for developing and delivering production-ready code. The ideal candidate will be someone who genuinely enjoys problem-solving and writing high-quality code to build robust, highly distributed, and scalable data processing systems and pipelines.\n\u2022 Design, implement and operate PC Bank\u2019s core datasets that have extreme requirements on scalability, reliability, maintainability, flexibility, auditability, and quality\n\u2022 Design large scale streaming and batch data pipelines (billions of data points) that involve analyzing transactions over a long period without reprocessing vast amounts of data\n\u2022 Perform data profiling and source to target mapping analysis for the best design\n\u2022 Collaborate with business solution analysts, other engineers, solution architects, and other team members to innovate and evolve our datasets to data products to create a single coherent platform with sources of truth that serve a plethora of stakeholders within PC Bank\n\nWhat You\u2019ll Do\n\u2022 Apply your expertise in data and software engineering to design and implement data products that meet extreme requirements on scalability, reliability, maintainability, flexibility, auditability, and quality\n\u2022 Be T-Shaped. Your primary area is data engineering, but you are comfortable working in a secondary area of expertise such as data presentation\/visualization, backend engineering, or data modeling (SQL, NoSQL, Graph & Time-series)\n\u2022 Work closely with cross-functional teams of data, backend and frontend engineers, product owners, technical product owners, and technical support personnel\n\u2022 Gaining technical expertise in building a data platform at scale to solve business, product, and technical use cases\n\u2022 Getting hands-on experience with technologies such as Elasticsearch, Apache Airflow, Apache Kafka, Apache Beam, Apache Spark, Hive, HDFS, Kubernetes (Openshift)\n\u2022 Getting hands-on experience with Google Cloud Platform and technologies such as BigQuery, Cloud Composer, Pub\/Sub, Dataflow, Dataproc, GCS, Looker, and other cloud-native offerings in GCP\n\nWho You Are\n\u2022 An undergraduate or Master\u2019s degree in Computer Science or equivalent engineering experience\n\u2022 2+ years of professional software engineering and programming experience (Java, Python) with a focus on designing and developing complex data-intensive applications\n\u2022 Familiarity with architecture and design (patterns, reliability, scalability, quality) of complex systems\n\u2022 Advanced coding skills and practices (concurrency, distributed systems, functional principles, performance optimization)\n\u2022 Professional experience working in an agile environment\n\u2022 Strong analytical and problem-solving ability\n\u2022 Strong written and verbal communication skills\n\u2022 Experience in operating and maintaining production-grade software\n\u2022 Comfortable with tackling very loosely defined problems and thrive when working on a team which has autonomy in their day to day decisions\n\nPreferred Skills\n\u2022 Knowledge of software and data engineering best practices\n\u2022 Experience with large scale distributed data technologies and tools\n\u2022 Experience pulling data from a variety of data source types including Mainframe (EBCDIC), Fixed Length and delimited files, databases (SQL, NoSQL, Time-series)\n\u2022 Strong coding skills for analytics and data engineering (Java, Python, and Scala)\n\u2022 Experience performing analysis with large datasets in a cloud-based environment, preferably with an understanding of Google\u2019s Cloud Platform (GCP)\n\u2022 Understands how to translate business requirements to technical architectures and designs\n\u2022 Comfortable communicating with various stakeholders (technical and non-technical)\n\nNice To Have Skills (though Not Required)\n\u2022 Exposure to data-science or machine-learning packages (Pandas, Pytorch, Keras, TensorFlow, etc...)\n\u2022 Contributions to open-source software (code, docs, or mailing list posts)\n\u2022 GCP Professional Data Engineer Certification\n\u2022 Confluent Certified Developer for Kafka\n\nCOVID-19 is a serious condition and has had a devastating impact on Canadians and others across the globe. As a leading Health and Wellness provider for millions of Canadians, our goal is to help all Canadians \"Live Life Well\".\n\nIn support of this goal, we have adopted a COVID-19 Vaccination Policy to protect the health and well-being of our employees as we continue our phased approach of office reopening. Employees will be required either to be fully vaccinated or undergo regular COVID-19 Rapid Antigen Screening in order to access the workplace.\n\nCome and join a winning team who demonstrates innovation, energy, creativity and vision. We recognize the importance of a diverse workforce and we therefor encourage applications from Aboriginal Peoples, women, members of a visible minority and persons with a disability. We thank all applicants for their interest, however, only those selected for an interview will be contacted.\n\nNumber Of Openings\n\n0\n\nPC Financial recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation\u2019s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. Accommodation is available upon request for applicants and colleagues with disabilities.\n\nIn addition, we believe that compliance with laws is about doing the right thing. Upholding the law is part of our Code of Conduct \u2013 it reinforces what our customers and stakeholders expect of us.\n\nPlease Note: If you have Employee Self Service (ESS) on Workday, apply to this job via the Workday application.","job_is_remote":false,"job_posted_at_timestamp":1682681737,"job_posted_at_datetime_utc":"2023-04-28T11:35:37.000Z","job_city":"Toronto","job_state":"ON","job_country":"CA","job_latitude":43.653225,"job_longitude":-79.38319,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+canada&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+canada&htidocid=VDWig3go7kgAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-28T11:35:37.000Z","job_offer_expiration_timestamp":1685273737.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":24,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":true},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"High Finance (UK) Limited T\/A HFG","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSICxFZuNPQ5sdTq6iH2ETKqxkaVij_ci-b4A_U&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"reed.co.uk","job_id":"mxrut48of94AAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineering Analyst","job_apply_link":"https:\/\/www.reed.co.uk\/jobs\/data-engineering-analyst\/50344348?source=searchResults&filter=%2Fjobs%2Fgeneral-insurance-jobs%3Fsortby%3DDisplayDate","job_apply_is_direct":false,"job_apply_quality_score":0.6343,"job_description":"\u2022 Responsibilities will include, but are not limited to, the following:\n\u2022 Provide technical support for the design, construction and maintenance of data for the business\n\u2022 Coordination of data projects with different levels of complexity depending on existing methods, processes and tools\n\u2022 Manages and coordinates stakeholders and builds a robust communication structure for data-related projects\n\u2022 Advises stakeholders and actively clarifies their expectations and requirements\n\u2022 Ability to assume responsibility for change, communication, quality and risk management\n\u2022 Understand the data relationships that exist between the business processes and systems. In turn apply this knowledge when interpreting the information requirements from the business\n\u2022 Translate data, analysis and commentary into a format for presentation to senior management\n\u2022 Gather, interpret, identify gaps and translate business MI and reporting requirements into solutions\n\u2022 Carry out analysis and interpret data to support the business in strategic and commercial decisions\n\u2022 Understand database and data science concepts and terminology, design principles and elements in order to deliver data and analytics\n\u2022 REQUIREMENTS\n\u2022 To be successful in this position you will need to have the following skills\/ experience:\n\u2022 Programming experience essential with direct exposure to SQL and ideally Power BI.\n\u2022 Exceptional academic background in Maths and IT from top tier university\n\u2022 Experience in working cross functionally and collaboratively with others\n\u2022 Ability to interpret user needs and translate into technical requirements\n\u2022 Works with little guidance and direction and performs majority of tasks independently\n\u2022 Customer Focused\n\u2022 Ability to work effectively within a team environment\n\u2022 Honesty and Integrity\n\u2022 Excellent communication skills, with the ability to explain complicated processes and concepts to non-experts\n\u2022 Excellent analytical skills (capable of understanding complex data structures, organise and structure data extracts)\n\u2022 High attention to detail including a commitment to accuracy of work.\n\u2022 Ability to work independently and resolve complex problems without direct supervision","job_is_remote":false,"job_posted_at_timestamp":1683072000,"job_posted_at_datetime_utc":"2023-05-03T00:00:00.000Z","job_city":"London","job_state":null,"job_country":"GB","job_latitude":51.507217,"job_longitude":-0.1275862,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=mxrut48of94AAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-14T23:55:00.000Z","job_offer_expiration_timestamp":1686786900.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":40000.0,"job_max_salary":50000.0,"job_salary_currency":"GBP","job_salary_period":"YEAR","job_highlights":{},"job_job_title":"Analyst","job_posting_language":"en","job_onet_soc":"43911100","job_onet_job_zone":"4"},{"employer_name":"The People Network","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSENcuUxBGhemqi2_OvdDCtSNC6jJm5nVLS9ThI&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"LinkedIn","job_id":"dOJ1uLt1HsoAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https:\/\/uk.linkedin.com\/jobs\/view\/data-engineer-at-the-people-network-3594559414","job_apply_is_direct":false,"job_apply_quality_score":0.5719,"job_description":"Are you an experienced Data Engineer with expertise in the AWS package looking to progress your experience in a highly innovative consultancy that is leading the forefront delivering digital transformations across the globe.\n\nRequired Skills\/Experience:\n\u2022 Expertise in both Python and SQL\n\u2022 Good exposure to AWS Services like AWS Lambda, AWS Glue, S3, IAM, Cloudwatch, SQS, etc.\n\u2022 Proficiency in working on data platforms such as Teradata and Snowflake\n\u2022 Experience evaluating business requirements and mapping technical stories\n\nDesirable Skills\/Experience:\n\u2022 Experience of Apache Airflow.\n\u2022 Exposure of developing an automation framework to validate data.\n\u2022 Good understanding of CI\/CD process.\n\nApplications from candidates working on a dependant visa, as well as post-study work visa's are accepted.(As long as you currently living in the UK, and possess full time working rights in the UK)\n\nSalary expectations for this role are between \u00a345k and \u00a350k\n\nIf you are ready to advance your career and join a dynamic team of Data Engineering professionals, apply now!","job_is_remote":false,"job_posted_at_timestamp":1683122022,"job_posted_at_datetime_utc":"2023-05-03T13:53:42.000Z","job_city":"London","job_state":null,"job_country":"GB","job_latitude":51.507217,"job_longitude":-0.1275862,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=dOJ1uLt1HsoAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-02T13:53:41.000Z","job_offer_expiration_timestamp":1685714021.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":true,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":45000.0,"job_max_salary":50000.0,"job_salary_currency":"GBP","job_salary_period":"YEAR","job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"iwoca","employer_logo":"https:\/\/assets-global.website-files.com\/62b040bf442187a12361b14f\/62d68830cfa706162442d9dc_iwoca-logo.svg","employer_website":"http:\/\/www.iwoca.co.uk","employer_company_type":"Retail","job_publisher":"Ai-Jobs.net","job_id":"hFbonp6_B04AAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer - Core Systems","job_apply_link":"https:\/\/ai-jobs.net\/job\/48785-data-engineer-core-systems\/","job_apply_is_direct":false,"job_apply_quality_score":0.669,"job_description":"We\u2019re here because we believe in small businesses. We believe they deserve better than waiting weeks for a loan. And we believe it\u2019s our job to help them grow. We started in 2012 with these principles, and we hold true to them today \u2013 now that we\u2019re one of the fastest-growing fintechs in Europe. In the time between, we\u2019ve built the best tech platform in lending, won several awards and opened up \u00a33.5 billion in loans to over 90,000 businesses. So what\u2019s next? Our mission now is to help one million businesses who need us. To do this, we\u2019ll need new products and partnerships. But most of all, we\u2019ll need smart, hands-on people to join us on the journey and get us to our goal. The roleAt iwoca we are dedicated to building the smartest lending platform in the world as we believe that finance should be as simple, seamless and powerful as electricity. We like to use Agile(ish) processes, which means features or projects go live in days or weeks rather than months or years. We run our Django-powered site on AWS, use asynchronous tools (Twisted, Celery) for time-consuming tasks and scientific libraries (NumPy, Scikit-learn, SciPy, Pandas) for risk aspects. Application orchestration is done with Docker\/Terraform\/ECS and our monitoring is set up using DataDog\/Sentry. We are looking for someone who has a solid amount of data engineering experience across different environments. Who can advise on and implement data architecture design. Who will collaborate with business users, analysts and data scientists to deliver high-quality reporting products. You'll have the opportunity to learn lots on the job and develop rapidly within a high performing team of engineers. Responsibilities Develop, construct, test and maintain data architectures and pipelines that align with business requirements. Identify practical ways to improve data reliability, efficiency and quality. Build, maintain, and document reporting tools that support data driven decision-making by business users. Liaise with stakeholders in the wider business to help improve data quality, advise on data strategy and help implement ingestion of new data assets from external sources. Assist data scientists in systemising data analysis to be deployed into a production environment. Work with analysts to streamline and improve operational and developmental access to data. Troubleshoot emerging data and operational problems, and be a source of knowledge for end-users on the most appropriate way of using data for their purposes. Support your teammates by learning and sharing your knowledge. RequirementsWe look for people that are smart, humble, motivated and who are always looking to improve. Ideally, you\u2019ll have: Experience in implementing reliable and performant data architectures, including ETL pipelines, relational databases, and columnar-storage data warehouses. Professional experience in data engineering \/ software development. Professional experience or a degree in a quantitative field, such as Mathematics, Physics, Engineering or Computer Sciences. Solid understanding of SQL and relational databases (esp. PostgreSQL). Comfortable implementing custom (in-house) data solutions where off-the-shelf products are unavailable or unsuitable. Bonus: Advanced LookML knowledge. Experience using TensorFlow, Scikit-learn, Matplotlib. Building backend systems, frameworks, and libraries. DevOps practices (CI\/CD), Docker and Kubernetes. Understanding of data science concepts. Typescript \/ React. Experience with Docker. We expect to pay from \u00a3100,000 - \u00a3120,000 for this role. But, we\u2019re open-minded, so definitely include your salary goals with your application. We routinely benchmark salaries against market rates, and regularly remunerate staff for their increasing value to our business. At iwoca, we prioritise a culture of learning, growth, and support, and invest in the professional development of our team members. You'll have access to ample opportunities for skill-building, mentorship, and career progression, and can decide your career path, focusing on frontend, branching into full-stack, or developing your skills in project and people leadership. We value thought and skill diversity, and encourage you to explore new areas of interest to help us innovate and improve our products and services. Our friendly and inclusive environment, combined with our flexible work policies, ensures that you'll have the perfect balance between work and life, empowering you to thrive both personally and professionally.BenefitsWe put a lot of effort into making iwoca a brilliant place to work: Offices in London, Leeds, and Frankfurt Events and clubs, like bingo, comedy nights, yoga classes, football\u2026 Two company retreats a year, we\u2019ve been to France, Italy, Spain and further afield Plenty of drinks and snacks in our offices. We offer a wide range of benefits: Medical insurance from Vitality, including discounted gym membership 25 days\u2019 holiday and an extra day off for your birthday Instant access to emotional and mental health support with our partner, Spill Generous maternity leave and shared parental leave A nursery tax benefit scheme to help you save money Paid volunteering time to support your chosen charity Extra leave if you want to travel or study One-month fully paid sabbatical after 4 years Cycle-to-work scheme and electric car scheme And to make sure we all keep learning, we offer: An L&D budget for everyone, including a book budget Company-wide talks with internal and external speakers Access to learning platforms like Treehouse, Frontend-masters and Pluralsight","job_is_remote":false,"job_posted_at_timestamp":1682589985,"job_posted_at_datetime_utc":"2023-04-27T10:06:25.000Z","job_city":"London","job_state":null,"job_country":"GB","job_latitude":51.507217,"job_longitude":-0.1275862,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=hFbonp6_B04AAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-11T00:00:00.000Z","job_offer_expiration_timestamp":1686441600.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":100000.0,"job_max_salary":120000.0,"job_salary_currency":"GBP","job_salary_period":"YEAR","job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"CERVELLO LIMITED","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTo2OXILCiaUQLpD9amh7uV7-MHSLgHdWy9HHT-&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"Totaljobs","job_id":"mKRlvgskrkkAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Analyst \/ Junior Data Engineer","job_apply_link":"https:\/\/www.totaljobs.com\/job\/analyst-junior\/cervello-limited-job100236189","job_apply_is_direct":false,"job_apply_quality_score":0.7186,"job_description":"Data Analyst \/ Junior Data Engineer\n\nCervello is looking for innovative data-driven individuals who are keen to get hands-on experience working with businesses to unleash the value from their data. As a data analyst\/junior data engineer, you will join an interdisciplinary team of architects, data scientists and big data consultants and get exposed to data in a commercial context.\n\nRequired skills:\n\u2022 Bachelor\u2019s degree in STEM subjects\n\u2022 Strong analytic abilities, with the demonstrable desire to identify insights from qualitative and quantitative data\n\u2022 Ability to understand and apply highly technical specification to datasets across different industries\n\u2022 High attention to detail and flexibility in juggling different responsibilities\n\u2022 Ability to work independently in a high pressure, time-critical \/ client-centric environment\n\u2022 Proficient in data visualization skills with technologies such as PowerBI, Tableau\n\u2022 SQL, relational database and (structured\/unstructured) data querying\n\nDesired skills:\n\u2022 Master\u2019s degree in STEM subjects\n\u2022 Ability to gather and process raw data at scale (including writing scripts, web scraping, working with APIs, writing SQL queries, etc.) Strong programming experience in Python, R, Java, Scala, Bash\n\u2022 Understanding of data warehousing and data modelling\n\u2022 Practical knowledge of data structures and algorithm\n\u2022 Distributed cloud computing (AWS \/ Azure \/ GCP)\n\u2022 Experience working with a variety of ELT\/ETL tools like Matillion, Talend, Streamsets\n\nAbout us: our workplace is fun and fast-paced:\n\nWe are Cervello. We believe in the power of connected data. We are laser focused on helping organizations harness the interconnectedness of digital, data and decision-making. We are problem solvers and builders focused on helping our clients win with data. Our culture is cool and innovative. Our environment is casual and conducive to collaboration and problem solving. We take our work seriously but not ourselves. It\u2019s the perfect balance of freedom and accountability. If you want to be part of something great \u2013 join us!\n\nEqual Employment Opportunity and Non-discrimination\n\nCervello prides itself on providing a culture that allows employees to bring their best selves to work every day. Our people can feel comfortable, confident, and joyful to do great things for our firm, our teams, and our clients. Cervello aims to build diverse capabilities to help our clients solve their most mission critical problems. Cervello is committed to building a diverse, unbiased and inclusive workforce. Cervello is an equal opportunity employer; we recruit, hire, train, promote, develop, and provide other conditions of employment without regard to a person\u2019s gender identity or expression, sexual orientation, race, religion, age, national origin, disability, marital status, pregnancy status, veteran status, genetic information or any other differences consistent with applicable laws. This includes providing reasonable accommodation for disabilities, or religious beliefs and practices. Members of communities historically underrepresented in analytics and consulting are encouraged to apply.","job_is_remote":false,"job_posted_at_timestamp":1681471320,"job_posted_at_datetime_utc":"2023-04-14T11:22:00.000Z","job_city":"London","job_state":null,"job_country":"GB","job_latitude":51.507217,"job_longitude":-0.1275862,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=mKRlvgskrkkAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-26T11:22:00.000Z","job_offer_expiration_timestamp":1685100120.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data analyst","job_posting_language":"en","job_onet_soc":"43911100","job_onet_job_zone":"4"},{"employer_name":"Mott MacDonald","employer_logo":"https:\/\/www.mottmac.com\/Content\/_WebsiteContent\/Images\/logo.svg","employer_website":"http:\/\/www.mottmac.com","employer_company_type":"Engineering Services","job_publisher":"LinkedIn","job_id":"rG6boSIEbdQAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"2023 UK Graduate Data Scientist Career Path","job_apply_link":"https:\/\/uk.linkedin.com\/jobs\/view\/2023-uk-graduate-data-scientist-career-path-at-mott-macdonald-3589659823","job_apply_is_direct":false,"job_apply_quality_score":0.5595,"job_description":"Job Description\n\nWorking as a Data Scientist for our buildings and cities (BNC) business, you will join our growing digital solutions team to deliver leading-edge digital solutions to our clients from various industries. By working together, you will help solve complex problems and develop innovative data-driven analytics and solutions in the field of physical and digital infrastructure, all through the application of data science.\n\nYou will join an enthusiastic and diverse team of geographic information systems and data science professionals passionate about data, location intelligence, analytics and powerful visualisation of the results. Through connected thinking and collaboration with colleagues across the Mott MacDonald organisation internationally you will be part of the wider team of data scientist, software engineers, solution architects, and engineers focusing on excellence and digital innovation.\n\nYou will support development of innovative solutions to client\u2019s asset management problems, applying data science and data engineering, including machine learning\/deep learning and computer vision as well as analysing a broad range of spatial and non-spatial information within the public domain including openly available data, websites, new feeds, connecting to data stream through web services and APIs.\n\nResponsibilities\n\nWithin the scope of the projects delivered, you may be responsible for any number of these elements\n\nAs a Data Scientist you will have a chance to work with and learn from the other members of our team.\n\u2022 Applying AI and advanced analytics, including spatial and geostatistical analytics, to large data sets within the asset management domain and across sectors including Buildings and Cities, Transport, Energy, Water and Environment.\n\u2022 Partnering with other GIS consultants, data scientists and software engineers to define and develop machine learning and data engineering products on premise or cloud-based platforms.\n\u2022 Working with cloud based platforms such as Azure or AWS\n\u2022 Designing and implementing ETL processes.\n\u2022 Presenting information using data visualisation techniques.\n\u2022 Inspiring self-serve data use by building dashboards and reports to drive awareness and understanding.\nOur ideal candidate would have experience developing\/implementing real-time computer vision algorithms on GPU will be advantageous as well as experience with a version control system such as Git to collaborate and manage a large codebase, ability to create fully reproducible and documented results with machine learning using principles like data versioning. Familiarity with using Linux shell, and SSH for remote code deployment would also be beneficial.\n\nAs a Data Scientist you will have a chance to work with and learn from the other members of our team, including GIS professionals and data scientists, join first class GIS and Data Science communities as well as wider teams at Mott MacDonald including software engineers, solution architects, and engineers. Duties to include;\n\u2022 Define and develop machine learning products.\n\u2022 Define and develop data engineering pipelines.\n\u2022 Designing and implementing ETL processes, including spatial ETL.\n\u2022 Presenting information using data visualisation techniques.\n\u2022 Inspiring self-serve data use by building dashboards and reports to drive awareness and understanding\n\nCandidate Specification\n\nWe are looking for committed and motivated graduates with a genuine passion and a desire to make a difference in the world. If this describes you, apply today to launch your career at Mott MacDonald.\n\nTo Be Eligible For This Opportunity, You Will Have Less Than 12 Months Experience And Have a Degree Or Are Expected To Achieve One Of The Following Degree Disciplines\n\u2022 Data Science\n\u2022 Mathematics\n\u2022 Statistics\n\u2022 Machine Learning\nIn your application you should be able to demonstrate your interest through relevant experience, such as studying relevant modules, or previous work experience.\n\nWe Are Looking For Graduates With The Following Characteristics\n\u2022 Methodical approach to problem solving\n\u2022 Ability to use your initiative to undertake tasks efficiently and independently.\n\u2022 Excellent verbal communication skills, which allow you to confidently liaise with clients and team members.\n\u2022 Excellent written communication and attention to detail and be able to demonstrate accurate technical drawings and good report writing.\n\u2022 Strong programming skills (Python\/R) with exposure to Machine Learning packages such as Tensorflow\/Keras, Pytorch or scikit-learn.\nAs we want the best people for the role, it is available as part time, job share or full time. This is because we recognise that sometimes people are not available full time. Please ask us at interview stage about any flexibility you may need.\n\nJob Profile\n\nAbout Your Development\n\nA graduate position should be more than just a job. We know this and so do you. That\u2019s why with our graduate roles, we aim to give you the experience and technical knowledge you need to progress your career.\n\nFrom the moment you join us, you\u2019ll receive the training you need. You will be assigned a chartered mentor, who will guide you to meet the objectives of your professional training agreement. We\u2019ll support you on your journey to gaining chartered status with your chosen institution.\n\nWhat else is involved?\n\nYou\u2019ll be enrolled onto Accelerate Your Future, a structured three-year soft-skills development programme which develops the strengths that we know graduates need to be successful at Mott MacDonald. It also gives you the opportunity to network and meet other graduates in your cohort. The programme is a mix of residential events, classroom-based learning, virtual webinars, and CSR (Corporate Social Responsibility) challenges. We understand that each person\u2019s career goals vary, therefore we tailor make each individual\u2019s development programme to suit them. With our vast library of e-learning courses available to you, you can choose which direction you want your career to go in.\n\nYou will have the opportunity to make a difference; learn more about our Social Outcomes and the difference we can make!\n\nDid you know that Mott MacDonald are Work180 accredited \u2013 which means we actively support and encourage women to join our work force!\n\nYou\u2019re probably wondering what else is on offer. Join us, and you\u2019ll get:\n\u2022 Biannual salary reviews: we believe that hard work should be rewarded and recognised. Therefore, for the first three years of your career with us, you\u2019ll have biannual salary reviews.\n\u2022 A competitive salary: in addition to biannual reviews, we will ensure that you\u2019re given a salary that matches the current industry standard.\n\u2022 Contributory pension up to 7% of your salary: we have the best people on our team, and we like to look out for them. With our support, you\u2019ll have all the advice and options you need to be able to invest in your future.\n\u2022 A flexible benefits scheme: our company is made up of a range of different people and we understand that different people want different things. That\u2019s why with our flexible plan, you\u2019ll have the ability to manage the range of benefits we have on offer, to suit your specific needs.\nOur social side\n\nBeing part of Mott MacDonald means more than just work, there\u2019s a huge range of fun and exciting things that you can get involved in.\n\nFrom the moment you join us, you\u2019ll have the opportunity to expand your social and professional network, whether it\u2019s meeting other graduates or joining forces with other members of staff from around the company at our annual sports day. Each of our offices have a sports and social committee which will give you the chance to be part of a variety of sports, social and charity events. We\u2019re committed to promoting a strong culture of social responsibility and encourage our staff to play active roles in the local community.\n\nIt's worth noting that sports and social committees tend to vary from office to office, so as well as getting involved in what\u2019s already on offer, don\u2019t be afraid to suggest new events or initiatives that you think could be a great addition.\n\nIt doesn\u2019t stop there. As well as events, you\u2019ll also have access to discounts on cinema tickets, travel, fashion, utilities and much more as part of our company benefits which you can take advantage of the moment you join.\n\nOther Information\n\nEquality, diversity and inclusion\n\nWe put equality, diversity and inclusion at the heart of our business, seeking to promote fair employment procedures and practices to ensure equal opportunities for all. We encourage individual expression in our workplace and are committed to creating an inclusive environment where everyone feels they have the opportunity to contribute.\n\nAgile working\n\nAt Mott MacDonald, we believe it makes business sense for you and your manager to choose how you can work most effectively to meet your client, team and personal commitments. We embrace agility, flexibility and trust.\n\nMore About Mott MacDonald\n\nWe\u2019re a global engineering, management and development consultancy.\n\nOur purpose is to improve society by considering social outcomes in everything we do, relentlessly focusing on excellence and digital innovation, transforming our clients\u2019 businesses, our communities and employee opportunities.\n\nA fundamental part of this is respecting each person\u2019s differences and striving to meet their needs.\n\nOur values: progress, respect, integrity, drive, excellence\n\nJob Ref\n\n59364BR\n\nRecruiter Contact\n\nearlycareers.recruitment@mottmac.com\n\nCountry\n\nUnited Kingdom\n\nRegion\/State\n\nEngland - South West\n\nDiscipline\n\nConsultancy\n\nSector\n\nBuilt environment\n\nWebsite Region\n\nEurope and Central Asia\n\nWebsite Sector\n\nBuildings","job_is_remote":false,"job_posted_at_timestamp":1682621729,"job_posted_at_datetime_utc":"2023-04-27T18:55:29.000Z","job_city":"Birmingham","job_state":null,"job_country":"GB","job_latitude":52.486244,"job_longitude":-1.890401,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=rG6boSIEbdQAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-27T18:55:29.000Z","job_offer_expiration_timestamp":1685213729.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":2,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data scientist","job_posting_language":"en","job_onet_soc":"15111100","job_onet_job_zone":"5"},{"employer_name":"Apple","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRDABy2RmEybCFwy2gEop4ngh827T3On461qdZo&s=0","employer_website":"http:\/\/www.apple.com","employer_company_type":"Manufacturing","job_publisher":"Careers At Apple","job_id":"tF1GONrVQNIAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Analytics Site Reliability Engineer","job_apply_link":"https:\/\/jobs.apple.com\/en-us\/details\/200449123\/data-analytics-site-reliability-engineer","job_apply_is_direct":false,"job_apply_quality_score":0.9191,"job_description":"Summary\nPosted: Apr 11, 2023\nWeekly Hours: 35\nRole Number:200449123\n\nAt Apple, our Data Analytics team focuses on improving the user experience by improving operating system stability, gathering feature usage telemetry, and evaluating device performance. This requires capturing data from customers who have given consent, utilizes strong privacy preserving techniques, and entails aggregating information, all to help inform direction. We develop and operate a variety of Big Data infrastructure products and applications in support of these goals.\n\nKey Qualifications\n\nKey Qualifications\n\u2022 Demonstrable experience of production experience managing and supporting large scale distributed Big Data applications (from development to production)\n\u2022 Experience with at least one of the following languages and related development tools: (Python, Ruby, Java, Scala)\n\u2022 Experience with one or more of the following platforms: HDFS, Yarn, Spark, Impala, Hbase, MapReduce, Kubernetes, other cloud services\n\u2022 Passion for quality and attention to detail\n\u2022 Excellent written and verbal communication skills\n\nDescription\n\nDescription\nWe are looking for Site Reliability Engineer to be a member of our team. If working on large scale problems excites you then we\u2019re excited to talk to you! Our team helps Apple engineers answer mission critical questions about their hardware, firmware, and software. We work with engineers across Apple to help keep our suite of analytics applications available and to ensure the integrity of their data.\nThe successful candidate will write code to automate our processes to ensure reliability and manage thousands of compute and storage instances across large heterogeneous infrastructure. You'll dive into complex data and application issues to drive root cause analysis of large scale problems.\nYou'll partner with your teammates and peers to solve problems, applying critical thinking skills and understanding of complex distributed systems.\nThe candidate will have to opportunity to contribute to the development of Apple's applications such as Mail and Safari, in addition to help to improve the performance of macOS and iOS.\nBuild, monitor, troubleshoot complex data infrastructure at the petabyte scale\n- Support the continuous development and deployment of multi service analytics applications\n- Develop tools and processes to automate the management of our systems and data\n\nEducation & Experience\n\nEducation & Experience\nBachelor's degree or equivalent experience\n\nAdditional Requirements\n\nAdditional Requirements\n\u2022 Apple\u2019s most important resource, our soul, is our people. Apple benefits help further the well-being of our employees and their families in meaningful ways. No matter where you work at Apple, you can take advantage of our health and wellness resources and time-away programmes. We\u2019re proud to provide stock grants to employees at all levels of the company, and we also give employees the option to buy Apple stock at a discount \u2014 both offer everyone at Apple the chance to share in the company\u2019s success. You\u2019ll discover many more benefits of working at Apple, such as programmes that match your charitable contributions, reimburse you for continuing your education and give you special employee pricing on Apple products.\n\u2022 Apple benefits programmes vary by country and are subject to eligibility requirements. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities.","job_is_remote":false,"job_posted_at_timestamp":1681171200,"job_posted_at_datetime_utc":"2023-04-11T00:00:00.000Z","job_city":"London","job_state":null,"job_country":"GB","job_latitude":51.507217,"job_longitude":-0.1275862,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=tF1GONrVQNIAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Reliability engineer","job_posting_language":"en","job_onet_soc":"15113300","job_onet_job_zone":"4"},{"employer_name":"Insight International (UK) Ltd","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSei09JRwZFHJR_zBJKHsIn7ezN__lAfi2TquAS&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"LinkedIn","job_id":"xgI86In4K4MAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Lead Data Engineer-Data Management","job_apply_link":"https:\/\/uk.linkedin.com\/jobs\/view\/lead-data-engineer-data-management-at-insight-international-uk-ltd-3585919733","job_apply_is_direct":false,"job_apply_quality_score":0.5719,"job_description":"Role: Lead Data Engineer-Data Management\n\nLocation: Bristol or London, UK\n\nJob Type: Contract\n\nJob Description:\n\u2022 Overall 15 years or more experience in delivering Data projects\n\u2022 Experience in introducing new products and maturing the services and adoption of new technologies\/ features within the organisation\n\u2022 Experience in designing and developing integration patterns for the products, components or features being introduced, including the security aspects of the solution design\n\u2022 Integration experience with Cloud (GCP) hosted applications\n\u2022 Experience in at least two of the domains of Reference Data (Informatica Ref360), Unstructured Data Management, Archiving (Informatica ILM), Data Protection (Protegrity) and Model Inventory (IBM OpenPages)\n\nImportant:\n\u2022 Need either MDM\/Ref Data and\/or Unstructured data and someone who can adapt and extend.\n\u2022 A good data architect who can work on multiple fronts and has great communication will fit.","job_is_remote":false,"job_posted_at_timestamp":1682676148,"job_posted_at_datetime_utc":"2023-04-28T10:02:28.000Z","job_city":"London","job_state":null,"job_country":"GB","job_latitude":51.507217,"job_longitude":-0.1275862,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=xgI86In4K4MAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-28T10:02:28.000Z","job_offer_expiration_timestamp":1685268148.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":180,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":true,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Management","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"BP","employer_logo":"https:\/\/www.bp.com\/etc\/designs\/bp-responsive\/images\/bp-responsive.svg","employer_website":"http:\/\/www.bp.com","employer_company_type":"Mining","job_publisher":"BP","job_id":"rEjc6XF3vIYAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Staff Data Engineer","job_apply_link":"https:\/\/www.bp.com\/en\/global\/corporate\/careers\/jobs-at-bp\/Staff-Data-Engineer-130846BR.html","job_apply_is_direct":false,"job_apply_quality_score":0.7335,"job_description":"Responsible for delivering business analysis and consulting activities for the defined specialism using advanced technical capabilities, building and maintaining effective working relationships with a range of stakeholders, ensuring relevant standards are defined and maintained, and managing process and system improvements to deliver business value. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.","job_is_remote":false,"job_posted_at_timestamp":1683072000,"job_posted_at_datetime_utc":"2023-05-03T00:00:00.000Z","job_city":null,"job_state":null,"job_country":"GB","job_latitude":55.37805,"job_longitude":-3.435973,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=rEjc6XF3vIYAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":false,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"GSK","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRURJD6ptBmouVnKh9GiajOFFHi249wg1r7VNZy&s=0","employer_website":"http:\/\/www.gsk.com","employer_company_type":"Manufacturing","job_publisher":"The Muse","job_id":"QzHZeVRQgUwAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Principal Data Engineer, Scientific Digital & Tech","job_apply_link":"https:\/\/www.themuse.com\/jobs\/gsk\/principal-data-engineer-scientific-digital-tech-345632","job_apply_is_direct":false,"job_apply_quality_score":0.5785,"job_description":"Site Name: USA - Pennsylvania - Upper Providence, UK - Hertfordshire - Stevenage, Wavre\nPosted Date: Apr 19 2023\n\nCome join us as we supercharge GSK's data capability! At GSK we are building a best-in-class data and prediction powered team that is ambitious for patients.\n\nScientific Digital and Tech's goal is to power the discovery, development and supply of medicines and vaccines to patients. This means new tools to discover new medicines and vaccines, predictive capability for pre-clinical research, accelerated CMC and supply chain and an improved day-to-day laboratory experience for our scientists. Our Digital & Tech solutions will automate workflows and speed up decisions; freeing hands and releasing minds to focus on science.\n\nAs R&D enters a new era of data driven science, we are building a data engineering capability to ensure we have high quality data captured with context and aligned data models, so that the data is useable and reusable for a variety of use cases.\n\nGSK R&D and Digital and Tech's collective goal is to deliver business impact, including the acceleration of the discovery and development of medicines and vaccines to patients. The R&D Digital and Tech remit has expanded over the past 2 years, and to position GSK for the future, The change will strengthen R&D Tech, to provide more strategic impact, focus, accountability, and improved decision making in the use of Digital, Data and Analytics (DDA) to strengthen the pipeline.\n\nThe Scientific Digital and Tech organization part of R&D Digital & Tech is an integrated family that powers the GSK R&D discovery, manufacture, and supply of new medicines and vaccines to patients. It focuses on optimizing CMC, informing Vaccine and Medicine design, and delivering a competitive, modern laboratory experience.\n\nScientific Data Engineering is a new organization responsible for enterprise data and architecture, providing thought leadership and architecture services for all aspects of data across the Scientific area. This includes the use of, and augmentation to, the two GSK data platforms on GCP and Azure, design and creation of data pipelines to surface data as a \"product\" in a data Mesh architecture across two platforms.\n\nJob Purpose:\n\nThe Principal Data Engineer contributes to the construction of the CMC data Mesh and data strategy. This role will interact with architects, engineers, data modelers, product owners as well as other team members in Scientific Tech and R&D.\n\nThe Principal Data Engineer is a leading technical contributor who can consistently take a poorly defined business or technical problem, work it to a well-defined data problem\/specification, and execute it at a high level. They have a strong focus on metrics, both for the impact of their work and for its inner workings\/operations.\n\nThey are a model for the team on best practices for software development in general (and data engineering in particular), including code quality, documentation, DevOps practices, and testing, and consistently mentor junior members of the team. They ensure the robustness of our services and serve as an escalation point in the operation of existing services, pipelines, and workflows.\n\nThe Principal Data Engineer should demonstrate core engineering knowledge\/experience of industry technologies, practices, and frameworks such as data Mesh and scaling data platforms, containerization, cloud-based platforms, data analytics, and data streaming. Examples of technologies include Java\/C#\/Python, Denodo, GIT, Azure DevOps, Data Bricks, Spark, Azure Data Factory, ADLS V2, Kafka, Selenium, JUnit\/NUnit, SAFe, Kanban, Docker, Azure Cloud Architecture including networking principles and scaling applications.\n\nPrimary responsibilities include the following:\n\u2022 Using Azure cloud services and GSK data platform tools to ingest, egress, and transform data from multiple sources.\n\u2022 Confidently optimizes the design and execution of complex solutions in data ingestion and data transformation\n\u2022 Produces well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\n\u2022 Provides input into the roadmaps of upstream teams (e.g., Data Platforms, DataOps, DevOps) to help improve the overall program of work\n\u2022 Ensure consistent application of platform capabilities to ensure quality and consistency concerning logging and lineage\n\u2022 Fully versed in coding best practices and ways of working, and participates in code reviews and partnering to improve the team's standards\n\u2022 Adhere to QMS framework, Security & Regulatory Standards, and CI\/CD best practices and helps to guide improvements to them that improve ways of working\n\u2022 Provide leadership to team members to help others get the job done right\n\u2022 Supporting engineering teams in the adoption and creation of data Mesh best practices.\n\u2022 Maintains best practices for engineering and architecture on our Confluence site.\n\u2022 Pro-actively engages in experimentation and innovation to drive relentless improvement\n\u2022 Provides leadership, technical direction, and GSK expertise to architecture and engineering teams composed of GSK FTEs, strategic partners, and software vendors.\nWhy you?\n\nBasic Qualifications:\n\nWe are looking for professionals with these required skills to achieve our goals:\n\u2022 BS in Computer Science\n\u2022 Experience in all the following:\n\u2022 Data Engineering development, architecture design & technology platforms\/frameworks\n\u2022 Azure Data Analytics services e.g. ADLS, Azure Data Factory, Azure Databricks, Purview, Azure Synapse, etc.\n\u2022 Data Platforms and Domain-driven design\n\u2022 Agile, DevOps & Automation [of testing, build, deployment, CI\/CD, etc.]\n\u2022 Data analytics & data quality\/integrity\n\u2022 Testing strategies & frameworks\n\u2022 Python experience required\nPreferred Qualifications:\n\nIf you have the following characteristics, it would be a plus:\n\u2022 MS in Computer Science\n\u2022 Experience with various open-source ecosystems including JavaScript, Bigdata, java, scala, python, etc.\n\u2022 Experience in agile software development and DevOps, relevant technology platforms [e.g., Kubernetes] and frameworks [e.g. Docker] including cloud technologies & data structures (i.e. information management), data models or relational database design\n\u2022 Subject matter expertise in Pharma CMC and scientific domains.\n\u2022 Experience in applying data curation, virtualization, workflow, and advanced visualization techniques to enable decision support across multiple products and assets to drive results across R&D business operations.\n\u2022 Role requires:\n\u2022 Demonstrated skill in delivering high-quality engineered data products\n\u2022 Knowledge of industry standards and technology platforms\n\u2022 Excellent communication, negotiation, influencing, and stakeholder management skills\n\u2022 Customer focus and excellent problem-solving skills\n\u2022 Good understanding of various software paradigms: domain-driven, procedural, data-driven, object-oriented, functional\n\u2022 Demonstrable knowledge depth in more than one area of software engineering and technology\n#LI-GSK\n\n#SCD\n\nWhy GSK?\n\nGSK is a global biopharma company with a special purpose - to unite science, technology and talent to get ahead of disease together - so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns - as an organisation where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.\n\nOur success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it's also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We're committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.\n\nIf you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).\n\nGSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity\/expression, age, disability, genetic information, military service, covered\/protected veteran status or any other federal, state or local protected class.\n\nImportant notice to Employment businesses\/ Agencies\n\nGSK does not accept referrals from employment businesses and\/or employment agencies in respect of the vacancies posted on this site. All employment businesses\/agencies are required to contact GSK's commercial and general procurement\/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business\/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business\/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses\/agencies in respect of the vacancies posted on this site.\n\nPlease note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK's compliance to all federal and state US Transparency requirements. For more information, please visit GSK's Transparency Reporting For the Record site.","job_is_remote":false,"job_posted_at_timestamp":1681989204,"job_posted_at_datetime_utc":"2023-04-20T11:13:24.000Z","job_city":"Stevenage","job_state":null,"job_country":"GB","job_latitude":51.903763,"job_longitude":-0.196612,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=QzHZeVRQgUwAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15111100","job_onet_job_zone":"5"},{"employer_name":"Dun & Bradstreet Europe","employer_logo":"https:\/\/www.dnb.com\/content\/dam\/english\/image-library\/dnb-mod\/logo-dnb.svg","employer_website":"http:\/\/www.dnb.com","employer_company_type":"Business Support","job_publisher":"LinkedIn","job_id":"4xNpGk_pPbYAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https:\/\/uk.linkedin.com\/jobs\/view\/data-engineer-at-dun-bradstreet-europe-3497500566","job_apply_is_direct":false,"job_apply_quality_score":0.5686,"job_description":"Why We Work at Dun & Bradstreet\n\nDun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!\n\nAbout The Role\n\nYou will be part of the team that is responsible for the accuracy and integrity of our UK and Ireland Identity Data. You will deliver and maintain data engineering solutions that ensure consistent operation of our UK and Ireland Data Management System. You will develop new innovative processes to manage data quality and streamline existing processes to execute data improvement plans more efficiently and effectively.\n\nYou will also be key technical support in conversations with our data partners to help understand their data and ensure we are maximizing value from all our data sources\n\nKey Responsibilities\n\u2022 Day-to-day operations of our Data Management System; ensuring process and procedures run as expected and any bugs are fixed in a timely manner with business-critical processes prioritised\n\u2022 Architecting solutions; Design, develop and test fit for purpose, resilient, scalable, and future-proof data services.\n\u2022 Recognise and exploit opportunities to ensure efficient and effective performance of Data processes. Explore new ways of conducting operational processes; developing ways of maximising the update cycle on data; achieving the best cost model whilst maintaining data quality\n\u2022 Write ETL scripts and code to make sure ETL processes perform optimally\n\u2022 Design, write and iterate code from development to production-ready. Understands security, accessibility, and version control. Can use a range of coding tools and languages.\n\u2022 Plan, design, manage, execute, and report tests, using appropriate tools and techniques, and works within internal policy and regulations. Ensuring risks associated with deployment are adequately understood and documented\n\u2022 Design and maintain appropriate metadata repositories to enable understanding of data assets and full auditability.\n\u2022 Partnering with cross-functional teams to understand how new sources will contribute towards the ongoing enhancement of data assets to achieve goals for database size, completeness, and other desirable improvements.\n\u2022 Creation of operational reports to measure usability and performance of data sources\n\u2022 Contribute to the vision and scope for the next generation of our data to drive revenue, performance quality and ensure operational efficiency, including new types of data and emerging capabilities for data collection.\n\u2022 Support operational plans that deliver business requirements through leading and coordinating their development, testing, and managing stabilisation activities.\n\nWhat We're Looking For\n\u2022 3+ years of proven in-depth knowledge and experience of SQL and database querying languages\n\u2022 Knowledge of other languages, like Python, would be advantageous\n\u2022 Ability to use PowerBI would be advantageous\n\u2022 Experience with ETL tools, in particular SSIS (SQL Server Integration Services)\n\u2022 Experience working with API\u2019s and services\n\u2022 Has a demonstrable understanding of how to expose data from systems (for example, through APIs), link data from multiple systems using different storage technologies\/access methods and deliver streaming services. Creates repeatable and reusable procedures.\n\u2022 Ability to correctly execute test scripts under supervision. Understanding the role of testing and how it works.\n\u2022 Aware of the types of problems in databases, data processes, data products and services.\n\u2022 Ability to run development using Agile and Kanban methodologies\n\u2022 Dynamic and results-driven with the focus on facilitating action and effecting change\n\u2022 An innovative and inspirational approach\n\u2022 Self-motivation with the desire to learn new techniques \u2013 relentlessly curious\n\u2022 Demonstrable experience in Database design, modelling and best practice\n\u2022 Analytical, process and problem-solving skills in a highly complex environment. A clear thinker who can articulate database issues and solutions and gain support for implementation, whilst remaining focused on what is important.\n\u2022 Ability to prioritise and multitask with flexible approach to changing deadlines and scope of project\n\u2022 Ability to work independently\n\u2022 A great team player\n\nAll Dun & Bradstreet job postings can be found at https:\/\/www.dnb.com\/about-us\/careers-and-people\/joblistings.html . Official communication from Dun & Bradstreet will come from an email address ending in @dnb.com.\n\nGlobal Recruitment Privacy Notice","job_is_remote":true,"job_posted_at_timestamp":1677602351,"job_posted_at_datetime_utc":"2023-02-28T16:39:11.000Z","job_city":"London","job_state":null,"job_country":"GB","job_latitude":51.507217,"job_longitude":-0.1275862,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+uk&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+uk&htidocid=4xNpGk_pPbYAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-28T04:38:53.000Z","job_offer_expiration_timestamp":1685248733.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":36,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"Google","employer_logo":"https:\/\/kgo.googleusercontent.com\/profile_vrt_raw_bytes_1587515358_10512.png","employer_website":"http:\/\/www.google.com","employer_company_type":"Information","job_publisher":"Salary.com","job_id":"Ks6uzFTPERsAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineering and Analytics, Google Data Centers","job_apply_link":"https:\/\/www.salary.com\/job\/google\/data-engineering-and-analytics-google-data-centers\/j202202151025478272060","job_apply_is_direct":false,"job_apply_quality_score":0.642,"job_description":"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Sunnyvale, CA, USA; Kirkland, WA, USA; Austell, GA, USA.\n\nMinimum qualifications:\n\u2022 Bachelor\u2019s degree in Information Systems, Computer Science, Data Science, Analytics, Mathematics, or equivalent pratical experience\n\u2022 5 years of experience leading data engineering and data analytics, business intelligence, and data models using SQL and Python languages\n\u2022 5 years of technical program management experience in a data related domain\n\nPreferred qualifications:\n\u2022 Master's degree in Information Systems, Computer Science, Data Science, Analytics, Mathematics, or related experience\n\u2022 2 years of experience developing real time streaming data pipelines using GCP BigQuery, Dataflow and Publish\/Subscribe (Pub\/Sub) from heterogeneous data sources (eg. Oracle, SAP, etc.), or predictive analytics\/machine learning\n\u2022 Experience leading organizational change efforts using data tools and solutions to improve organization efficiency\n\nAbout the job\n\nA problem isn\u2019t truly solved until it\u2019s solved for all. That\u2019s why Googlers build products that help create opportunities for everyone, whether down the street or across the globe. As a Program Manager at Google, you\u2019ll lead complex, multi-disciplinary projects from start to finish \u2014 working with stakeholders to plan requirements, manage project schedules, identify risks, and communicate clearly with cross-functional partners across the company. Your projects will often span offices, time zones, and hemispheres. It's your job to coordinate the players and keep them up to date on progress and deadlines.\n\nOur goal is to build a Google that looks like the world around us \u2014 and we want Googlers to stay and grow when they join us. As part of our efforts to build a Google for everyone, we build diversity, equity, and inclusion into our work and we aim to cultivate a sense of belonging throughout the company.\n\nAs a Technical Program Manager, you will architect and build data engineering processes and drive quality\/consistency of data across business functions. You will use your technical and data expertise to establish robust data pipelines and solutions to facilitate trusted data availability across multiple systems. You will work with our Data Center business stakeholders to understand their data issues and challenges, utilize your technical expertise to build and deploy simple, efficient, secure, scalable data solutions, services, and insights. You will manage a portfolio of programs that help Data Center teams successfully operate, while transforming the organization by building and integrating the next wave of data solutions to increase trust in data, insights, and data-driven decision making.\n\nBehind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.\n\nResponsibilities\n\u2022 Lead the technical delivery, implementation, and business adoption of new scalable and reliable data analytics and business intelligence solutions for cross-department leadership and business teams\n\u2022 Build the infrastructure required for optimal ETL of data from a wide variety of data sources using Google Cloud Platform (GCP) technologies\n\u2022 Implement real time data pipelines, predictive analytics, machine learning algorithms, and translate data and model results into strategic insights for leadership and business stakeholders\n\u2022 Manage all aspects of program deliverables from project inception to implementation and resource oversight\n\u2022 Traverse complex large datasets to extract business insights that directly help to maintain up-time of critical data center operations, and increase operating efficiency of teams responsible for designing and building Google\u2019s data center footprint\n\nGoogle is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.","job_is_remote":false,"job_posted_at_timestamp":1671235200,"job_posted_at_datetime_utc":"2022-12-17T00:00:00.000Z","job_city":"Sunnyvale","job_state":"CA","job_country":"US","job_latitude":37.36883,"job_longitude":-122.03635,"job_benefits":["retirement_savings"],"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=Ks6uzFTPERsAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-01T00:00:00.000Z","job_offer_expiration_timestamp":1685577600.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":60,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Bachelor\u2019s degree in Information Systems, Computer Science, Data Science, Analytics, Mathematics, or equivalent pratical experience","5 years of experience leading data engineering and data analytics, business intelligence, and data models using SQL and Python languages","5 years of technical program management experience in a data related domain","Oracle, SAP, etc.), or predictive analytics\/machine learning","Experience leading organizational change efforts using data tools and solutions to improve organization efficiency"],"Responsibilities":["As a Program Manager at Google, you\u2019ll lead complex, multi-disciplinary projects from start to finish \u2014 working with stakeholders to plan requirements, manage project schedules, identify risks, and communicate clearly with cross-functional partners across the company","Your projects will often span offices, time zones, and hemispheres","It's your job to coordinate the players and keep them up to date on progress and deadlines","As a Technical Program Manager, you will architect and build data engineering processes and drive quality\/consistency of data across business functions","You will use your technical and data expertise to establish robust data pipelines and solutions to facilitate trusted data availability across multiple systems","You will work with our Data Center business stakeholders to understand their data issues and challenges, utilize your technical expertise to build and deploy simple, efficient, secure, scalable data solutions, services, and insights","You will manage a portfolio of programs that help Data Center teams successfully operate, while transforming the organization by building and integrating the next wave of data solutions to increase trust in data, insights, and data-driven decision making","Lead the technical delivery, implementation, and business adoption of new scalable and reliable data analytics and business intelligence solutions for cross-department leadership and business teams","Build the infrastructure required for optimal ETL of data from a wide variety of data sources using Google Cloud Platform (GCP) technologies","Implement real time data pipelines, predictive analytics, machine learning algorithms, and translate data and model results into strategic insights for leadership and business stakeholders","Manage all aspects of program deliverables from project inception to implementation and resource oversight","Traverse complex large datasets to extract business insights that directly help to maintain up-time of critical data center operations, and increase operating efficiency of teams responsible for designing and building Google\u2019s data center footprint"]},"job_job_title":null,"job_posting_language":"en","job_onet_soc":"11302100","job_onet_job_zone":"4"},{"employer_name":"Skiltrek","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRwGF4Rk4S09WK7UvUMnGuR478ZkOYDtSYoPrqS&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"LinkedIn","job_id":"brQNVLIbITwAAAAAAAAAAA==","job_employment_type":"CONTRACTOR","job_title":"Sr. Data Analytics Engineer","job_apply_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analytics-engineer-at-skiltrek-3589332434","job_apply_is_direct":false,"job_apply_quality_score":0.5721,"job_description":"Description\n\nDescription:\n\nEngaging with business and analytic teams to understand data requirements and translating those requirements into technical solutions. Standardizing and implementing operational processes for data delivery, maintaining SLAs and ensuring accuracy\n\nAutomating technical solutions the integrate data from a variety of data sources. Spotting and implementing optimizations across data usage from multidisciplinary teams. Ensuring data health and quality through monitoring and alerting tools\n\nProven experience in\n\n\" Designing, building and maintaining data marts.\n\n\" Programming in Python, SQL (emphasis: postgres) ElasticSearch, GraphQL, and writing efficient and complex queries and ETL jobs that span Terabytes of data\n\n\" Working with Postgres Databases built on AWS or other distributed data technologies\n\n\" Implementing data pipelines and applications in a general programming language such as Python\n\n\" Working with DevOps and Agile methodologies such as JIRA, Jenkins, Gitlab and air flow\n\n\" Understanding of ETL, database and Object Oriented Programming Concepts\n\n\" Building and enhancing existing Tableau dashboards with minimal support\n\n\" Picking up and embracing new technologies and languages\n\n\" Would be nice to have an exposure to large-scale data warehouse solutions such as Snowflake and Redshift\n\nSkills\n\nPython, Sql, Etl, postgresql, Data, Aws, tableau\n\nTop Skills Details\n\nPython,Sql,Etl,postgresql\n\nAdditional Skills & Qualifications\n\nThis is a Data Analytics\/Insights team- will be responsible for providing analytics support\/solutions for business stakeholders.\n\nExperience Level\n\nExpert Level\n\nAbout Us\n\nSkiltrek is an award-winning IT staffing firm and the staffing partner of choice for many leading companies across the US. At Skiltrek, we promise you the perfect opportunity of building technical excellence, understand business performance and nuances, be abreast with the latest happenings in technology world and enjoy a satisfying work life balance.\n\nSkiltrek is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity\/expression, sexual orientation, veteran or military status, or any other category protected under the law. Skiltrek is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.","job_is_remote":false,"job_posted_at_timestamp":1683004082,"job_posted_at_datetime_utc":"2023-05-02T05:08:02.000Z","job_city":"Cupertino","job_state":"CA","job_country":"US","job_latitude":37.322998,"job_longitude":-122.03218,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=brQNVLIbITwAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-01T05:08:02.000Z","job_offer_expiration_timestamp":1685596082.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["\" Working with DevOps and Agile methodologies such as JIRA, Jenkins, Gitlab and air flow","Python, Sql, Etl, postgresql, Data, Aws, tableau"],"Responsibilities":["Engaging with business and analytic teams to understand data requirements and translating those requirements into technical solutions","Standardizing and implementing operational processes for data delivery, maintaining SLAs and ensuring accuracy","Automating technical solutions the integrate data from a variety of data sources","Spotting and implementing optimizations across data usage from multidisciplinary teams","Ensuring data health and quality through monitoring and alerting tools","\" Building and enhancing existing Tableau dashboards with minimal support","\" Picking up and embracing new technologies and languages"]},"job_job_title":"Engineer","job_posting_language":"en","job_onet_soc":"43911100","job_onet_job_zone":"4"},{"employer_name":"TSG Engineering","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSKmYBq8tCJjZ1lRx3hmVbf0_vwlqCpCw30vdZ-&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"Glassdoor","job_id":"VIcEneHZaAsAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Scientist\/Analyst [R, Python,Google Cloud]","job_apply_link":"https:\/\/www.glassdoor.com\/job-listing\/data-scientist-analyst-r-python-google-cloud-tsg-engineering-JV_IC1153560_KO0,44_KE45,60.htm?jl=1005787661074","job_apply_is_direct":true,"job_apply_quality_score":0.5586,"job_description":"Benefits\n\u2022 TSG Engineering offers a competitive and flexible compensation package for its employees.\n\nSend resumes to: jobs@tsg-eng.com\n\u2022 Network systems and cyber security\n\u2022 Scala, R, Python, Ruby, Java, C, C++\n\u2022 Data science\/machine learning libraries, algorithms and tools\n\u2022 Big data and analysis platforms (Spark, Hadoop, Kafka, etc.)\n\u2022 Analytic development on AWS\n\u2022 AI work experience, Machine Learning, Statistical Models, and Natural Language Processing\n\n- Security Clearance Required","job_is_remote":false,"job_posted_at_timestamp":1680652800,"job_posted_at_datetime_utc":"2023-04-05T00:00:00.000Z","job_city":"Ellicott City","job_state":"MD","job_country":"US","job_latitude":39.26733,"job_longitude":-76.79831,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=VIcEneHZaAsAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-06-01T00:00:00.000Z","job_offer_expiration_timestamp":1685577600.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Scala, R, Python, Ruby, Java, C, C++","Data science\/machine learning libraries, algorithms and tools","Big data and analysis platforms (Spark, Hadoop, Kafka, etc.)","Analytic development on AWS","AI work experience, Machine Learning, Statistical Models, and Natural Language Processing","Security Clearance Required"],"Benefits":["TSG Engineering offers a competitive and flexible compensation package for its employees"]},"job_job_title":null,"job_posting_language":"en","job_onet_soc":"15111100","job_onet_job_zone":"5"},{"employer_name":"NFI Industries","employer_logo":"https:\/\/www.nfiindustries.com\/wp-content\/uploads\/2021\/03\/Screen-Shot-2021-03-13-at-10.24.49-AM.png","employer_website":"http:\/\/www.nfiindustries.com","employer_company_type":"Logistics","job_publisher":"NFI Industries","job_id":"mqz1cb2K3lYAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Principal Data Engineer","job_apply_link":"https:\/\/careers.nfiindustries.com\/us\/en\/job\/NFINUSPRINC021942EXTERNALENUS\/Principal-Data-Engineer","job_apply_is_direct":true,"job_apply_quality_score":0.8118,"job_description":"At NFI, we offer innovative, integrated, and customized solutions that span the entire supply chain. Whatever our customer\u2019s challenge is, we have the knowledge, technology, scale, and commitment to help them solve it. It\u2019s simply what we do.\n\nThe NFI Data and Analytics team is looking for an experienced Principal Data Engineer to join our growing team to support NFI\u2019s needs for enterprise data services to support data-driven analytics and reporting. Guided by NFI\u2019s shared values, we work in an environment where collaboration, teamwork, respect, and openness are highly valued.\n\nThis is an opportunity to join NFI on its journey to become a data-driven organization, continue to develop its data analytics discipline and integrate best practices into the data environment. The ideal candidate will have solid experience in data architecture, and data engineering in a Cloud environment and big data platforms to process enterprise data for high throughput. High-level responsibilities will include designing, creating, deploying, and managing data pipelines in a cloud data analytics environment.\n\nEssential Duties & Responsibilities:\n\u2022 Work with the team and key business partners to evaluate business needs and priorities, define solutions, and address data pipeline and data management needs.\n\u2022 Translate business requirements into technical specifications; establish and define details, definitions, and data requirements for applications, reporting, and analytics.\n\u2022 Architect large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud, Azure, or AWS.\n\u2022 Generate database design, development, test plans, logical and physical ER diagrams, and ETL in support of integration, application development, and analytics teams.\n\u2022 Ensure that designs meet needs for fault tolerance, resiliency, and affordability.\n\u2022 Continuously optimize the data infrastructure to improve performance, reliability, and scalability\n\u2022 Use an analytical, data-driven approach to drive a deep understanding of fast-changing business.\n\u2022 Work with a team to build, implement and maintain a new data platform using cloud data technology to handle data ingestion, data transformation, data storage, etc.\n\u2022 Build large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud Platform or AWS, or Azure.\n\u2022 Mentor team members in developing standards, and best practices for using cloud services, data architectures, data platform design, and data operations.\n\nJob-Specific Requirements:\n\u2022 Bachelor\u2019s degree in Computer Science, Information Systems, or a related discipline.\n\u2022 5+ years\u2019 experience in IT\/Data Engineering with expert-level hands-on experience in building large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud or AWS, or Azure.\n\u2022 Expert in data pipeline design, engineering, and implementation of data lake, warehouse, and Lakehouse architecture.\n\u2022 Expert-level hands-on experience with SQL, ETL, Data Integration tools, Big Data tools, and database engineering.\n\u2022 Expertise in data modeling for star schema\/Kimball and relational modeling to 3rd normal form, or BCNF.\n\u2022 Proficient in programming languages such as Python, Java, or Scala.\n\u2022 Proficient in using one of the data warehouse platforms, Big Query, Redshift, Synapse, or Snowflake.\n\u2022 Experience with data processing frameworks like Apache Beam, Spark, PySpark, Apache Kafka, and Apache Airflow.\n\u2022 Experience in engineering enterprise data environments including database design, master data management, metadata, and performance tuning for analytics.\n\u2022 Experience with SSIS, Azure Data Factory, Big Data\/Hadoop, Big Data\/Databricks, R, etc.\n\u2022 Experience with Data Analytics and visualization tools such as Power BI, Looker, or Tableau.\n\u2022 Experience with Data Science and AI\/ML tools and technologies is a plus.\n\u2022 Familiarity with RPA tools like PowerAutomate, UIPath, and\/or Automation 360 and Terraform is a plus.\n\u2022 Experience with Master Data Management tools such as Reltio or similar is a plus.\n\u2022 Certification in Cloud Data Engineering or Data Architecture is a plus.\n\u2022 Experience with Retail Distribution, 3PL, or Transportation Logistics is a plus.\n\nExpected Competencies:\n\u2022 Functional Expertise: Possesses the skills and knowledge needed to perform essential functions efficiently and effectively\n\u2022 Communication and Collaboration: Communicates openly and honestly. Follows through on commitments. Takes ownership and does not misrepresent information. Supports colleague and team efforts\n\u2022 Development: Takes an active role in self-development, seeking to grow job-related knowledge and skills. Empowers and challenges team members to reach their full potential.\n\u2022 Analysis and Decision Making: Uses all available resources to make good decisions. Knows when and how to partner with others when facing a problem.\n\u2022 Results Focus: Action-oriented. Assumes an appropriate level of accountability for goals, critical issues, and performance.\n\u2022 Managing Change and Continuous Improvement: Demonstrates an entrepreneurial mindset towards change. Takes risks, and creates new, and better ways for the organization to be successful.\n\n#LI-BS1\n\nEqual Opportunity Employer\/Protected Veterans\/Individuals with Disabilities\n\nThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor\u2019s legal duty to furnish information. 41 CFR 60-1.35(c)","job_is_remote":false,"job_posted_at_timestamp":1682695070,"job_posted_at_datetime_utc":"2023-04-28T15:17:50.000Z","job_city":"Irving","job_state":"TX","job_country":"US","job_latitude":32.81402,"job_longitude":-96.94889,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=mqz1cb2K3lYAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":60,"experience_mentioned":true,"experience_preferred":true},"job_required_skills":["Data Engineering","Cloud Technologies","AWS","Data Analytics","Database Design","Data Science","Data Operations","Data Transformation","Data Modeling","data architectures","ETL","SQL","Data Storage","Scala","Data Infrastructure","big query","Cloud Services","Tableau","Data Warehouse","Java","Platforms","Information Systems","data processing frameworks","Applications","RPA Tools","Performance Tuning","Python","Automation","Apache Kafka","Analytical","Principal Data Engineer","Lead Data Engineer","Senior Data Engineer","Principal Big Data Engineer","Big Data Engineer","Principal Data Scientist","Cloud Data Engineer","Big Data Architect","Big Data Scientist","Principal Data Analyst"],"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":true},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Bachelor\u2019s degree in Computer Science, Information Systems, or a related discipline","5+ years\u2019 experience in IT\/Data Engineering with expert-level hands-on experience in building large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud or AWS, or Azure","Expert in data pipeline design, engineering, and implementation of data lake, warehouse, and Lakehouse architecture","Expert-level hands-on experience with SQL, ETL, Data Integration tools, Big Data tools, and database engineering","Expertise in data modeling for star schema\/Kimball and relational modeling to 3rd normal form, or BCNF","Proficient in programming languages such as Python, Java, or Scala","Proficient in using one of the data warehouse platforms, Big Query, Redshift, Synapse, or Snowflake","Experience with data processing frameworks like Apache Beam, Spark, PySpark, Apache Kafka, and Apache Airflow","Experience in engineering enterprise data environments including database design, master data management, metadata, and performance tuning for analytics","Experience with SSIS, Azure Data Factory, Big Data\/Hadoop, Big Data\/Databricks, R, etc","Experience with Data Analytics and visualization tools such as Power BI, Looker, or Tableau","Functional Expertise: Possesses the skills and knowledge needed to perform essential functions efficiently and effectively","Communication and Collaboration: Communicates openly and honestly"],"Responsibilities":["High-level responsibilities will include designing, creating, deploying, and managing data pipelines in a cloud data analytics environment","Work with the team and key business partners to evaluate business needs and priorities, define solutions, and address data pipeline and data management needs","Translate business requirements into technical specifications; establish and define details, definitions, and data requirements for applications, reporting, and analytics","Generate database design, development, test plans, logical and physical ER diagrams, and ETL in support of integration, application development, and analytics teams","Ensure that designs meet needs for fault tolerance, resiliency, and affordability","Continuously optimize the data infrastructure to improve performance, reliability, and scalability","Use an analytical, data-driven approach to drive a deep understanding of fast-changing business","Work with a team to build, implement and maintain a new data platform using cloud data technology to handle data ingestion, data transformation, data storage, etc","Build large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud Platform or AWS, or Azure","Mentor team members in developing standards, and best practices for using cloud services, data architectures, data platform design, and data operations","Supports colleague and team efforts","Development: Takes an active role in self-development, seeking to grow job-related knowledge and skills","Empowers and challenges team members to reach their full potential","Analysis and Decision Making: Uses all available resources to make good decisions","Managing Change and Continuous Improvement: Demonstrates an entrepreneurial mindset towards change"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"Murmuration","employer_logo":null,"employer_website":null,"employer_company_type":null,"job_publisher":"Jobs By Workable","job_id":"hnOBmZ4Bk1cAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineering Fellow","job_apply_link":"https:\/\/apply.workable.com\/murmuration\/j\/3F0BA13375\/","job_apply_is_direct":true,"job_apply_quality_score":0.7185,"job_description":"*This is a remote 10-week paid summer fellowship.*\n\nAbout Murmuration\n\nMurmuration is a nonprofit organization focused on leveraging civic engagement to drive greater equity. We are committed to transforming public education so that every child \u2013 regardless of who they are or where they live \u2013 can benefit from the same opportunities afforded by a quality education.\n\nWe provide sophisticated tools, data, strategic guidance, and programmatic support to help our partner organizations increase civic engagement and marshal support to drive change at the community level. Our best-in-class data and easy-to-use tools have been used by hundreds of organizations to make informed decisions about who they need to reach and how to achieve and sustain impact \u2013 and to put those decisions into action.\n\nOur team includes experts and innovators in data, analytics, and strategy. We are former teachers, organizers, data scientists, and campaign veterans, and we are looking for people whose passion and expertise can help realize our vision.\n\nAbout the Fellowship\n\nThe Murmuration Summer Fellowship provides fellows with the unique opportunity to work closely with Murmuration teams on summer projects while contributing to Murmuration\u2019s commitment to transforming public education across the United States.\n\nFellows will have meaningful, productive, and engaging summer experiences as they learn and grow with a cohort of peers. They will have the opportunity to learn more about career pathways in education, organizing and advocacy, and data through their project work, fellowship programming, and mentorship with Murmuration staff.\n\nAbout the Role\n\nThe Data Engineering Fellow role offers a variety of opportunities, including engineering tasks related to ETL\/ELT data pipelines, testing, integration, systems engineering, design, and analysis. The fellowship will include performance analysis on existing pipeline processes, documentation, and assisting in the design and development of future pipelines. At the end of the summer, this fellow will have migrated 90% of code-embedded transformation from Git to Snowflake, written tests, and documented analyses of the ETL\/ELT pipeline process. This person will work with Data Managers and Data Engineers to capture improvements and enhance Murmuration\u2019s pipeline processes. Strong communication skills are a must!\n\nThe Data Team is a highly collaborative, friendly, and hard-working group, and we are looking for team members that embody those values. The Data Engineering Fellow will report to the Sr. Data Engineer.\n\nWhat You\u2019ll Do\n\u2022 Git to Snowflake Migration\n\u2022 Support Data Engineers in enhancing Murmuration Data Pipeline processes,\n\u2022 Collaborate with the Data Managers to understand and analyze the data transformational logic within the Murmuration Data Pipeline,\n\u2022 Document pipeline processes and enhancements,\n\u2022 Work with senior team members to deploy and test applications.\n\u2022 Engineering Collaboration\n\u2022 Work on Murmuration Data Pipelines and organize data on Snowflake,\n\u2022 Contribute to Murmuration\u2019s document page by creating\/updating technical documentation,\n\u2022 Assist in architecting, implementing, and deploying new data models and data processes in production, and\n\u2022 Troubleshoot data processing issues\n\nWhat You Should Have\n\u2022 Murmuration attracts employees with distinctive and diverse backgrounds and accomplishments. Integrity, creativity, flexibility, and drive are key attributes of competitive candidates. The ideal candidate will have:\n\u2022 Education and\/or experience in Computer Science;\n\u2022 1-2 years experience with Python and Object-Oriented programming;\n\u2022 2-3 years experience working with large-scale databases\/cloud databases;\n\u2022 Excellent verbal and written communication skills.\n\nWhat You Might Have\n\u2022 1-2 years experience in version control systems (e.g. SVN, GIT, etc.);\n\u2022 1-2 years working with data transformation systems (e.g. AIrflow, dbt, etc.);\n\u2022 Experience within a support team providing technical support to other data functions (e.g. Data Scientists, Data Managers, etc.);\n\u2022 Working knowledge of SQL, Bash, or similar; and\n\u2022 Practical knowledge of software development lifecycle (SDLC).\n\nNote: If you\u2019re passionate about data engineering and civic engagement, please apply, even if you don\u2019t check every box!\n\nLocation, Compensation, and Benefits\n\nThe Data Engineering Fellow is a full-time summer position. Compensation for the 10-week fellowship is $8,000. It is based anywhere in the U.S.\n\nAn Equal-Opportunity Employer with a Commitment to Diversity\n\nMurmuration is proud to be an equal opportunity employer, and as an organization committed to diversity and the perspective of all voices, we consider applicants equally of race, gender, color, sexual orientation, religion, marital status, disability, political affiliation and national origin. We reasonably accommodate staff members and\/or applicants with disabilities, provided they are otherwise able to perform the essential functions of the job.","job_is_remote":true,"job_posted_at_timestamp":1678320000,"job_posted_at_datetime_utc":"2023-03-09T00:00:00.000Z","job_city":null,"job_state":null,"job_country":"US","job_latitude":37.09024,"job_longitude":-95.71289,"job_benefits":["health_insurance"],"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=hnOBmZ4Bk1cAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":24,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Strong communication skills are a must!","Murmuration attracts employees with distinctive and diverse backgrounds and accomplishments","Integrity, creativity, flexibility, and drive are key attributes of competitive candidates","Education and\/or experience in Computer Science;","1-2 years experience with Python and Object-Oriented programming;","2-3 years experience working with large-scale databases\/cloud databases;","Excellent verbal and written communication skills","1-2 years experience in version control systems (e.g. SVN, GIT, etc.);","1-2 years working with data transformation systems (e.g. AIrflow, dbt, etc.);","Experience within a support team providing technical support to other data functions (e.g","Working knowledge of SQL, Bash, or similar; and","Practical knowledge of software development lifecycle (SDLC)","Note: If you\u2019re passionate about data engineering and civic engagement, please apply, even if you don\u2019t check every box!"],"Responsibilities":["Fellows will have meaningful, productive, and engaging summer experiences as they learn and grow with a cohort of peers","They will have the opportunity to learn more about career pathways in education, organizing and advocacy, and data through their project work, fellowship programming, and mentorship with Murmuration staff","The Data Engineering Fellow role offers a variety of opportunities, including engineering tasks related to ETL\/ELT data pipelines, testing, integration, systems engineering, design, and analysis","The fellowship will include performance analysis on existing pipeline processes, documentation, and assisting in the design and development of future pipelines","At the end of the summer, this fellow will have migrated 90% of code-embedded transformation from Git to Snowflake, written tests, and documented analyses of the ETL\/ELT pipeline process","This person will work with Data Managers and Data Engineers to capture improvements and enhance Murmuration\u2019s pipeline processes","Collaborate with the Data Managers to understand and analyze the data transformational logic within the Murmuration Data Pipeline,","Document pipeline processes and enhancements,","Work with senior team members to deploy and test applications","Engineering Collaboration","Work on Murmuration Data Pipelines and organize data on Snowflake,","Contribute to Murmuration\u2019s document page by creating\/updating technical documentation,","Assist in architecting, implementing, and deploying new data models and data processes in production, and","Troubleshoot data processing issues"],"Benefits":["Compensation for the 10-week fellowship is $8,000"]},"job_job_title":"Data engineering","job_posting_language":"en","job_onet_soc":"15111100","job_onet_job_zone":"5"},{"employer_name":"Red Ventures","employer_logo":"https:\/\/www.redventures.com\/assets\/desktop-a\/images\/favicon\/apple-touch-icon.png?v=v2","employer_website":"http:\/\/www.redventures.com","employer_company_type":"Consulting","job_publisher":"LinkedIn","job_id":"56vQpuk7Z2oAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Engineer","job_apply_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-red-ventures-3570454427","job_apply_is_direct":false,"job_apply_quality_score":0.5567,"job_description":"Job Title: Data Engineer\n\nJob Location: 1101 Red Ventures Drive, Fort Mill, SC 29707\n\nDescription Of Duties\n\nTwo Data Engineers sought by RBUS, Inc., a Red Ventures Company, for its office in Ft. Mill, South Carolina to to build & maintain data products and create end to end solutions. Job duties include build ETL pipelines, develop operational efficiency solutions, root cause analysis, data analysis, and optimization of scripts.\n\nRate of Pay: $121,000.00 to $125,000.00\/year\n\nMinimum Job Requirements\n\n4 years of experience in the job offered or related occupation such as Business Data Analyst, or Application Developer is required and must include: 3.5 years of experience conducting root cause analysis on data quality using SSIS packages, QlikView, Power BI, SSRS and SAP Crystal reports to create solutions; 3.5 years of experience architecting optimizations using Qlikview, Power BI, SAP Crystal reports, SSRS to perform data analysis on operational metrics, KPI and productivity; 3 years of experience building ETL data pipelines for data containing PII using SSIS packages built with Visual Studio data tool for Microsoft SQL Server Data warehouse; 3 years of experience using QlikView NPrinting, CRM, ADP report delivery through Biztalk server using secure FTP adapter with internal & external customers to improve operational efficiency and 4 years of experience optimizing T-SQL, PL\/SQL scripts to improve data efficiency, reduce data load time and troubleshoot execution plan. Employer will accept any suitable combination of education, training, and experience.\n\nApplicants are to Respond to: RBUS, Inc., A Red Ventures Company, 1101 Red Ventures Drive, Fort Mill, SC 29707 Attn: HR, Req. #1026.\n\nIf you are based in California, we encourage you to read this important information for California residents linked here.","job_is_remote":false,"job_posted_at_timestamp":1682629799,"job_posted_at_datetime_utc":"2023-04-27T21:09:59.000Z","job_city":"Fort Mill","job_state":"SC","job_country":"US","job_latitude":35.00737,"job_longitude":-80.945076,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=56vQpuk7Z2oAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-27T21:09:59.000Z","job_offer_expiration_timestamp":1685221799.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":60,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":true,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"Thermo Fisher Scientific","employer_logo":"https:\/\/www.thermofisher.com\/blog\/clinical-conversations\/wp-content\/themes\/clinical-conversations\/images\/logo.png","employer_website":"https:\/\/www.thermofisher.com\/us\/en\/home.html","employer_company_type":"Manufacturing","job_publisher":"DataYoshi","job_id":"5DFQnmriJMEAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Sr. Data Analyst","job_apply_link":"https:\/\/3.136.182.153\/offer\/656841\/sr-data-analyst","job_apply_is_direct":false,"job_apply_quality_score":0.4303,"job_description":"Partner with business leaders and leverage strong analytical skills to recommend KPIs and targets that will generate meaningful insights for the business.\n\nInterpret business performance results and provide recommendations to the business on where to focus improvement efforts; partner with the development team to automate analysis.\n\nUnderstand business challenges in the areas of commercial, marketing and service, and use advanced analytics capabilities to mine data and recommend data science solutions.\n\nProvide on-going analysis services to the IES business at large.\n\nContribute to building and maintaining analytics solutions using PowerBI and existing data warehouse solutions.\n\nContribute to and help enable the strategy to build data lake and data infrastructure in Amazon Web Service environment needed to expand analytics capabilities in the future.\n\nREQUIREMENTS: Master\u2019s degree in Data Analytics, Business Analytics, Business Intelligence, or related field of study plus 3 years of data analysis or related experience. Experience may be gained concurrently through graduate level course work and\/or internships. Employer also accepts a Bachelor\u2019s degree in Data Analytics, Business Analytics, Business Intelligence, or related field of study plus 5 years of data analysis or related experience.\n\nMust have experience or knowledge of:\n\u2022 Data Mining: R, Python, MATLAB, SAS;\n\u2022 Visualization and analytics: Tableau, Power BI, Excel, R Shiny;\n\u2022 Database querying: SQL, PostgreSQL, Mysql, Microsoft Access, Oracle Sql;\n\u2022 Project management: Gitlab, Github, JIRA;\n\u2022 Cloud resources: AWS S3, AWS EC2; and\n\u2022 Machine learning: Regression, Classification, Clustering, neural networks, Ensemble-based models.\n\nSALARY: $139,568 - $166,400\/year","job_is_remote":false,"job_posted_at_timestamp":1680998400,"job_posted_at_datetime_utc":"2023-04-09T00:00:00.000Z","job_city":"Carlsbad","job_state":"CA","job_country":"US","job_latitude":33.158092,"job_longitude":-117.35059,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=5DFQnmriJMEAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-09T00:00:00.000Z","job_offer_expiration_timestamp":1683590400.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":60,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["Experience may be gained concurrently through graduate level course work and\/or internships","Employer also accepts a Bachelor\u2019s degree in Data Analytics, Business Analytics, Business Intelligence, or related field of study plus 5 years of data analysis or related experience","Must have experience or knowledge of:","Data Mining: R, Python, MATLAB, SAS;","Visualization and analytics: Tableau, Power BI, Excel, R Shiny;","Database querying: SQL, PostgreSQL, Mysql, Microsoft Access, Oracle Sql;","Project management: Gitlab, Github, JIRA;","Cloud resources: AWS S3, AWS EC2; and","Machine learning: Regression, Classification, Clustering, neural networks, Ensemble-based models"],"Responsibilities":["Partner with business leaders and leverage strong analytical skills to recommend KPIs and targets that will generate meaningful insights for the business","Interpret business performance results and provide recommendations to the business on where to focus improvement efforts; partner with the development team to automate analysis","Understand business challenges in the areas of commercial, marketing and service, and use advanced analytics capabilities to mine data and recommend data science solutions","Provide on-going analysis services to the IES business at large","Contribute to building and maintaining analytics solutions using PowerBI and existing data warehouse solutions","Contribute to and help enable the strategy to build data lake and data infrastructure in Amazon Web Service environment needed to expand analytics capabilities in the future"],"Benefits":["SALARY: $139,568 - $166,400\/year"]},"job_job_title":"Data analyst","job_posting_language":"en","job_onet_soc":"43911100","job_onet_job_zone":"4"},{"employer_name":"Booz Allen Hamilton","employer_logo":"https:\/\/boozallen.com\/content\/dam\/boozallen_site\/homepage\/booz-allen-logo.svg","employer_website":"http:\/\/www.boozallen.com","employer_company_type":"Consulting","job_publisher":"Booz Allen Hamilton","job_id":"R8M91SI1Oy0AAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Big Data Engineer, Mid","job_apply_link":"https:\/\/careers.boozallen.com\/teams\/JobDetail\/Norfolk-Big-Data-Engineer-Mid-R0170675\/78832","job_apply_is_direct":false,"job_apply_quality_score":0.8145,"job_description":"Big Data Engineer, Mid\n\nThe Opportunity:\n\nDo you want to work at the forefront of advanced technology and solve complex data challenges? You know that data yields pivotal insights when it\u2019s gathered from disparate sources and organized. As a data engineer, you have the chance to develop and deploy the pipelines and platforms that make this data meaningful. What\u2019s more, you\u2019ll have the chance to help grow Booz Allen\u2019s DataOps capabilities while working with a multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in a fast-paced, agile environment. We\u2019re looking for someone like you to work with our clients and meet their mission by working with a multi-disciplinary team of analysts, data engineers, data scientists, developers, machine learning engineers, and data consumers in a fast-paced agile environment.\n\nThis is an opportunity to implement data engineering activities on some of the most mission-driven projects in the industry. Supporting a multitude of clients across numerous domains, you\u2019ll have the chance to architect data systems, stand up data platforms, build out ETL pipelines, develop custom tooling, interface with data stores, and manage data life cycle operations. From sharing your skills in analytical exploration and examination of data to supporting the assessment, design, building, and maintenance of scalable platforms, you\u2019ll work with our clients to solve their most pressing challenges.\n\nReady to help drive innovation using cutting-edge data tools and techniques?\n\nJoin us. The world can\u2019t wait.\n\nYou Have:\n\u2022 3+ years of experience in a professional work environment\n\u2022 3+ years of experience with designing, developing, operationalizing, and maintaining complex data applications at an enterprise scale\n\u2022 3+ years of experience with creating data solutions in SQL or scripting languages to retrieve, parse, and process structured and unstructured data\n\u2022 3+ years of experience with building scalable Extract Transform Load (ETL) processes for reporting and analytics\n\u2022 Experience with management consulting techniques, including client interviews, data gathering, and problem-solving\n\u2022 Experience with using Microsoft Excel and Access\n\u2022 Ability to develop scripts and programs for converting types of data into usable formats and support project team to scale, monitor and operate data platforms\n\u2022 Ability to obtain a security clearance\n\u2022 Bachelor\u2019s degree\n\nNice If You Have:\n\u2022 Experience with GitHub or version control systems\n\u2022 Experience with UNIX\/Linux, including basic commands and Shell scripting\n\u2022 Experience with Microsoft Visual Basic for Applications (VBA)\n\u2022 Experience with a public cloud, including AWS, Microsoft Azure, or Google Cloud\n\u2022 Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka\n\u2022 Experience with NoSQL implementation, including MongoDB or Cassandra\n\u2022 Experience with data warehousing using AWS Redshift, MySQL, or Snowflake\n\u2022 Experience with Agile engineering practices and working on real-time data and streaming applications\n\u2022 Experience with data visualization tools, including Tableau, QlikSense, or Microsoft Power BI\n\u2022 Bachelor\u2019s degree in Economics, Operations Research, Management Science, Mathematics, or Statistics\n\n\u200b\n\nClearance:\n\n\u200b\u200bApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.\n\nCreate Your Career:\n\nAt Booz Allen, we know the power of analytics and we\u2019re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you\u2019ll have the chance to:\n\u2022 access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n\u2022 change the world with the Data Science Bowl\u2014the world\u2019s premier data science for social good competition\n\u2022 participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n\nYou\u2019ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We\u2019ll help you develop the career you want as you chart your own course for success.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n\nWork Model\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role.\n\nEEO Commitment\n\nWe\u2019re an equal employment opportunity\/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.","job_is_remote":false,"job_posted_at_timestamp":1683072000,"job_posted_at_datetime_utc":"2023-05-03T00:00:00.000Z","job_city":"Norfolk","job_state":"VA","job_country":"US","job_latitude":36.85077,"job_longitude":-76.28587,"job_benefits":["retirement_savings","health_insurance"],"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=R8M91SI1Oy0AAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":36,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":true},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Qualifications":["3+ years of experience in a professional work environment","3+ years of experience with designing, developing, operationalizing, and maintaining complex data applications at an enterprise scale","3+ years of experience with creating data solutions in SQL or scripting languages to retrieve, parse, and process structured and unstructured data","3+ years of experience with building scalable Extract Transform Load (ETL) processes for reporting and analytics","Experience with management consulting techniques, including client interviews, data gathering, and problem-solving","Experience with using Microsoft Excel and Access","Ability to develop scripts and programs for converting types of data into usable formats and support project team to scale, monitor and operate data platforms","Ability to obtain a security clearance","Experience with GitHub or version control systems","Experience with UNIX\/Linux, including basic commands and Shell scripting","Experience with Microsoft Visual Basic for Applications (VBA)","Experience with a public cloud, including AWS, Microsoft Azure, or Google Cloud","Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka","Experience with NoSQL implementation, including MongoDB or Cassandra","Experience with data warehousing using AWS Redshift, MySQL, or Snowflake","Experience with Agile engineering practices and working on real-time data and streaming applications","Experience with data visualization tools, including Tableau, QlikSense, or Microsoft Power BI","Bachelor\u2019s degree in Economics, Operations Research, Management Science, Mathematics, or Statistics"],"Responsibilities":["As a data engineer, you have the chance to develop and deploy the pipelines and platforms that make this data meaningful","This is an opportunity to implement data engineering activities on some of the most mission-driven projects in the industry","Supporting a multitude of clients across numerous domains, you\u2019ll have the chance to architect data systems, stand up data platforms, build out ETL pipelines, develop custom tooling, interface with data stores, and manage data life cycle operations","From sharing your skills in analytical exploration and examination of data to supporting the assessment, design, building, and maintenance of scalable platforms, you\u2019ll work with our clients to solve their most pressing challenges","If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role"],"Benefits":["You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips","At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being","Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care","The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD)"]},"job_job_title":"Data engineer","job_posting_language":"en","job_onet_soc":"15113200","job_onet_job_zone":"4"},{"employer_name":"ZETTALOGIX INC","employer_logo":"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTYFbg4mfZO5zBqZ9AZRbJj5ULwJz_7E4f67r-l&s=0","employer_website":null,"employer_company_type":null,"job_publisher":"LinkedIn","job_id":"_GrabFV1Q3kAAAAAAAAAAA==","job_employment_type":"CONTRACTOR","job_title":"Data Analyst with Salesforce Experience","job_apply_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-with-salesforce-experience-at-zettalogix-inc-3588948048","job_apply_is_direct":false,"job_apply_quality_score":0.5633,"job_description":"Job Role: Data Analyst with Salesforce Experience\n\nLocation: Remote\n\nDuration: 6+ Months Contract\n\nVisa: Any\n\nJob Responsibilities:\n\n-This individual should have a strong track record of executing well on daily tasks and have experience in importing, exporting, cleaning, transforming, validating and modeling data, especially in a MS Excel and Salesforce.com environment.\n\n-Responsible for maintenance, administration and support of data elements\n\n-Ensures metadata, reference documentation, data files and data flows are accurate and up to date\n\n-Support with data validation, quality issues, integrity, accuracy, consistency and works to resolve impacting issues related to data elements; de-duplication and cleaning\n\n-Assisting with data analysis in Salesforce and Excel as needed\n\n-Salesforce experience is essential","job_is_remote":true,"job_posted_at_timestamp":1682966998,"job_posted_at_datetime_utc":"2023-05-01T18:49:58.000Z","job_city":"New York","job_state":"NY","job_country":"US","job_latitude":40.712776,"job_longitude":-74.005974,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=_GrabFV1Q3kAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":"2023-05-31T18:49:58.000Z","job_offer_expiration_timestamp":1685558998.0,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":null,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":null,"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":true,"degree_mentioned":false,"degree_preferred":false,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":null,"job_max_salary":null,"job_salary_currency":null,"job_salary_period":null,"job_highlights":{"Responsibilities":["This individual should have a strong track record of executing well on daily tasks and have experience in importing, exporting, cleaning, transforming, validating and modeling data, especially in a MS Excel and Salesforce.com environment","Responsible for maintenance, administration and support of data elements","Ensures metadata, reference documentation, data files and data flows are accurate and up to date","Support with data validation, quality issues, integrity, accuracy, consistency and works to resolve impacting issues related to data elements; de-duplication and cleaning","Assisting with data analysis in Salesforce and Excel as needed"],"Benefits":["Duration: 6+ Months Contract"]},"job_job_title":"Experience","job_posting_language":"en","job_onet_soc":"43911100","job_onet_job_zone":"4"},{"employer_name":"Honda Motor","employer_logo":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/7\/7b\/Honda_Logo.svg\/2552px-Honda_Logo.svg.png","employer_website":"http:\/\/www.honda.co.jp","employer_company_type":"Manufacturing","job_publisher":"Karkidi","job_id":"1_BpS8dliToAAAAAAAAAAA==","job_employment_type":"FULLTIME","job_title":"Data Analyst","job_apply_link":"https:\/\/www.karkidi.com\/job-details\/30739-data-analyst-job","job_apply_is_direct":false,"job_apply_quality_score":0.545,"job_description":"What Makes a Honda, is Who makes a Honda\n\nHonda has a clear vision for the future, and it\u2019s a joyful one. We are looking for individuals with the skills, courage, persistence, and dreams that will help us reach our future-focused goals.\n\nAt our core is innovation. Honda is constantly innovating and developing solutions to drive our business with record success. We strive to be a company which serves as a source of power that supports people around the world who are trying to do things based on their own initiative and that helps people expand their own potential. To this end, Honda strives to realize the joy and freedom of mobility by developing new technologies and an innovative approach to achieve a zero environmental footprint.\n\nWe are looking for qualified individuals with diverse backgrounds, experiences, continuous improvement values, and a strong work ethic to join our team.\n\nIf your goals and values align with Honda\u2019s, we want you to join our team to Bring the Future!\n\nAbout this Position:\n\nThis role revolves around identifying, planning, and implementing system improvements and applies analytics from proof-of-concept to production. The Data Analytics Engineer generates new ideas to derive value from data and assists in project scoping, design, data analysis, and execution.\n\nResponsibilities include:\n\u2022 Development of standard procedures and best practices for data analytics projects.\n\u2022 Development of models and dashboards for use by all levels of the organization.\n\u2022 Development of processes and tools to monitor and analyze model performance and data accuracy.\n\u2022 Present results to senior management as required.\n\u2022 Mentor associates in analytics tools and projects.\n\u2022 Advises and coaches leaders on how to adopt new ideologies to transform outcomes\n\nWho we are seeking:\n\nRequired Work Experience:\n\u2022 2-6 years Applicable Experience\n\nRequired Education:\n\u2022 Bachelors\u2019 degree in engineering, data analytics, data science, mis, computer science; or equivalent relevant experience.\n\nDesired skills:\n\u2022 Experience with open-source data analytics in python and\/or r (data mining, data modelling)\n\u2022 Data visualization tools (tableau, power bi, plotly, etc)\n\u2022 Experienced VBA\/SQL Skills\n\u2022 Ability to multitask and manage projects effectively\n\nAdditional Position Factors:\n\u2022 Support Division activity at all HDMA sites as well as NA Activity.\n\u2022 Work in a fast-paced environment with demanding and critical deadlines.\n\u2022 Average overtime hours of 3-5 hours per week\n\u2022 Virtual Work Environment\n\u2022 Potential for limited travel","job_is_remote":false,"job_posted_at_timestamp":1674777600,"job_posted_at_datetime_utc":"2023-01-27T00:00:00.000Z","job_city":"Marysville","job_state":"OH","job_country":"US","job_latitude":40.23645,"job_longitude":-83.36714,"job_benefits":null,"job_google_link":"https:\/\/www.google.com\/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analysts+jobs+in+america&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analysts+jobs+in+america&htidocid=1_BpS8dliToAAAAAAAAAAA%3D%3D","job_offer_expiration_datetime_utc":null,"job_offer_expiration_timestamp":null,"job_required_experience":{"no_experience_required":false,"required_experience_in_months":24,"experience_mentioned":true,"experience_preferred":false},"job_required_skills":["Cloud computing"],"job_required_education":{"postgraduate_degree":false,"professional_certification":false,"high_school":false,"associates_degree":false,"bachelors_degree":false,"degree_mentioned":true,"degree_preferred":true,"professional_certification_mentioned":false},"job_experience_in_place_of_education":false,"job_min_salary":120000.0,"job_max_salary":190000.0,"job_salary_currency":"USD","job_salary_period":"YEAR","job_highlights":{"Qualifications":["2-6 years Applicable Experience","Bachelors\u2019 degree in engineering, data analytics, data science, mis, computer science; or equivalent relevant experience"],"Responsibilities":["This role revolves around identifying, planning, and implementing system improvements and applies analytics from proof-of-concept to production","The Data Analytics Engineer generates new ideas to derive value from data and assists in project scoping, design, data analysis, and execution","Development of standard procedures and best practices for data analytics projects","Development of models and dashboards for use by all levels of the organization","Development of processes and tools to monitor and analyze model performance and data accuracy","Present results to senior management as required","Mentor associates in analytics tools and projects","Advises and coaches leaders on how to adopt new ideologies to transform outcomes","Average overtime hours of 3-5 hours per week"]},"job_job_title":"Data analyst","job_posting_language":"en","job_onet_soc":"43911100","job_onet_job_zone":"4"}]