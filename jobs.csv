employer_website,job_id,job_employment_type,job_title,job_apply_link,job_description,job_city,job_country,job_posted_at_timestamp,employer_company_type
http://www.wattpad.com,PHB2re4Gv4cAAAAAAAAAAA==,FULLTIME,"Data Engineer, Analytics",https://ca.linkedin.com/jobs/view/data-engineer-analytics-at-wattpad-3594739979,"Wattpad is a global multiplatform entertainment company whose vision is to entertain and connect the world through stories. Since 2006, we’ve been on a mission to use the power of community and technology to unleash the full potential of stories to the world. Every month 85 million people around the world spend over 23 billion minutes on Wattpad to share and discover stories they can’t find anywhere else. Our brand banner includes: Wattpad, Wattpad WEBTOON Studios, Wattpad Books and Wattpad Brand Partnerships. We’re proudly based in Toronto, but our reach is global. Come build the future of entertainment and storytelling, and write your next chapter with us!  We are looking for a Data Engineer, Analytics to join our growing Data organization and support the Analytics squad. The squad's main focus is to partner with all of Wattpad's business units and product squads, to build ad-hoc reporting to metrics creation to forecasting and predictive insights projects. The goal is to advocate for and facilitate data-informed decision-making throughout the organization.  In this role, you will partner with data engineers, analysts and scientists. You will develop solutions and build analytics infrastructure to deliver trusted data. Data is critical to how we make decisions at Wattpad and you will play a key role in helping Wattpad continue to scale!  What you'll do: • Build and own analytics infrastructure that delivers good quality data, reliably • Support the building of robust, scalable data ingestion pipelines • Develop complex data models and transformations that standardize analytics products • Provide technical leadership on data solutions that are forward looking • Establish best practices for data warehousing • Evaluate new tools, build prototypes and be an advocate for modern, scalable data infrastructure  What we're looking for: • You have solid experience in designing schemas and data models for use in transformation and BI tools • You are comfortable building ETL/ELT flows that extract data from various systems • You have a good understanding of data engineering best practices (batch data processing, streaming, etc.) • You understand software engineering fundamentals and principles • You are comfortable leading data architecture and design discussions • You have curiosity towards experimenting with new data tools/methods and are abreast with the latest trends in data • Bonus: You have experience with DBT core/DBT cloud and LookML/Looker  Wattpad is conducting all interviews in a distributed manner using applicable third party software where needed and using visual interface tools such as Google Hangouts and Zoom.  About Wattpad  Who are we? Entrepreneurs and Do-ers. Our vision is to entertain and connect the world through stories, and our mission is to use the power of community and technology to unleash the full potential of stories to the world.  What does that mean? We are visionaries, community builders, passionate problem solvers, storytellers, coffee snobs (tea drinkers, too!), curious by nature, and culturally diverse.  What are we obsessed with? Our users. Solving complex problems and maximizing flow. Learning constantly. Building the next great storytelling product. Finding the greatest stories ever told. Dogs (and cats), coffee, and good snacks.  How do we work? Autonomously, collaboratively, respectfully. Balancing with work, family, and play...and all while having a great time.  Wattpad is a remote friendly company and encourages remote candidates to apply as long as they are located and authorized to work in either the US or Canada (excluding Quebec) as a precondition of employment. We are not able to sponsor applicants for work permits.  If you happen to live near the areas of either Toronto, Ontario or Halifax, Nova Scotia, you may also have the opportunity to work from our beautiful offices - 1 located in Downtown Toronto and the other in Halifax.  Culture and Diversity  Wattpad is an equal opportunity employer. We do not discriminate. Period.  Wattpad welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. We have taken a leadership position on creating a culture and an organization that truly values diversity. We are committed to fostering a global team that reflects the diversity of the Wattpad community. At Wattpad, we believe cultural fit doesn’t mean culturally identical, and diversity of thought helps us to challenge one another to think big and think differently. We consider employment applicants without regard to age, race, colour, national origin, citizenship, religion, creed, sex, sexual orientation, veteran status, marital status, disability status or any other protected status.  If you have any special needs or accessibility requirements, please let us know. We will do our utmost to accommodate, in accordance with applicable local legislation.  Don’t meet all the requirements? Studies show women and people of colour are less likely to apply to jobs if they do not meet all the qualifications. Therefore, in an effort to build a more diverse workplace, we encourage you to apply anyways. You might actually be the right person or you may be a good fit for a number of other openings we currently have.",Toronto,CA,1682979180,
http://www.rbi.com,dc-gsTIx27gAAAAAAAAAAA==,FULLTIME,"Data Engineer, Tim Hortons, Canada",https://careers.rbi.com/global/en/job/5727700002/Data-Engineer-Tim-Hortons-Canada,"About Restaurant Brands International:  Restaurant Brands International Inc. is one of the world's largest quick service restaurant companies with more than $35 billion in annual system-wide sales and over 28,000 restaurants in more than 100 countries. RBI owns four of the world's most prominent and iconic quick service restaurant brands – TIM HORTONS®, BURGER KING®, POPEYES® and FIREHOUSE SUBS®. These independently operated brands have been serving their respective guests, franchisees and communities for decades. Through its Restaurant Brands for Good framework, RBI working towards its goal of improving sustainable outcomes related to its food, the planet, and people and communities.  Tim Hortons® is one of North America's largest restaurant chains operating in the quick service segment, with more than 4,800 system wide restaurants located in Canada, the United States and around the world.  We are currently looking for experienced and motivated Data Engineering Specialist to join our Advanced Analytics team. The Data Engineer will report directly to Data Engineering Lead with the role principally located in Toronto King St office.  What You’ll Do: • Design, development and maintenance of big data pipelines • Integration with Enterprise Data Warehouse and other applications that generate and consume data from Big Data platforms – Databricks, mParticle, Braze, • Implement best practices across data industry to standardize and automate data pipelines • Understand business needs and coordinate with different stakeholders within and outside organization to translate business needs into technical requirements • Solve our data problems using optimal ETL techniques across structured and unstructured data sources • Implement security and governance guidelines and ensure compliance to regulations  Who You Are: • Have strong problem-solving skills with an emphasis on product development. • Take ownership, with the ability to manage in an environment of quick change to help strategic moves in this rapidly evolving QSR environment. • Are outcome focused, critical thinkers with the ability to analyze and visualize, to ensure continuous improvement across our entire business. • Have ability to work in a fast-paced Agile environment and is transparent and professional in their communication If you’re curious, ready to take on new challenges and open to doing things differently to help us evolve rapidly, then this is the place to  Requirements: • Minimum under graduation degree or equivalent in Computer Science, Engineering, Statistics, Mathematics, or related technical field • 5+ years experience in designed complex ETL solutions • 3+ years experience in Big Data Space – Apache Spark, Hadoop, HDFS • 3+ years experience in programming languages like Python, Scala, R, SQL • Ability to write complex SQL statements to query heterogenous big data sets to process, filter and present large quantities of data • Ability to integrate different data sources and familiarity with data modelling concepts • Knowledge of Databricks, Structured Streaming is an Asset • Good understanding of cloud platform concepts - AWS, such as EC2, S3, Dynamodb and Lambda • Experience with Loyalty Programs an asset  Benefits: • Pension matching • Hybrid • Health benefits (medical, dental) • Short- and long-term disability • Comprehensive global paid parental leave • Telehealth • Employee Assistance Program • Discounted Gym Memberships  Restaurant Brands International and all of its affiliated companies (collectively, RBI) are equal opportunity and affirmative action employers that do not discriminate on the basis of race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or veteran status, or any other characteristic protected by local, state, provincial or federal laws, rules, or regulations. RBI's policy applies to all terms and conditions of employment. Accommodation is available for applicants with disabilities upon request.  #LI-Hybrid",Toronto,CA,1678898754,Restaurant
http://curinos.com,CAL0o7sM8uAAAAAAAAAAAA==,FULLTIME,Data Engineer (Remote),https://ca.linkedin.com/jobs/view/data-engineer-remote-at-curinos-3544869920,"We find that the most successful candidates for the Data Engineerposition are natural and relentless problem solvers who are passionate about working with data to solve business problems. These individuals demonstrate ease with quantitative analysis, can work well as part of small multi-disciplinary teams, have a keen interest in software engineering and are passionate about developing leading edge analytical business applications.  Our Data Engineers are part of the engineering team responsible for data architecture, backend development and maintenance of our proprietary decision support software applications. They work closely with product management and the front end development team to ensure that our products are constantly improving and have leading edge functionality.  Job responsibilities include: • Engage with product owner to understand requirements about new features • Help navigate the cloud migration journey using a well-architected path • Support complex business logic encoded into the data/analytics platform • Work with data science and product teams to design solutions to meet their use cases • Design pipelines and processes using Scala and Spark SQL • Support an ecosystem of proprietary and third-party tools and technologies to empower high performing ML/data engineering and data science teams • Support continuous build and release process • Research and present emerging technologies and design patterns to engineering leadership  Qualifications  Desired Skills & Expertise  Aspiring candidates should have the following background, skills and characteristics: • Bachelor’s degree, preferably in computer science, or engineering field • 4+ years of ETL experience using flat files to transposed Data Models • 4+ years of working experience in Python and Scala. • Experience in troubleshooting and debugging SQL and Scala code • Working knowledge of enterprise data platforms like Databricks and/or Snowflake • Exposure to Spark • Experience supporting and working with cross-functional teams in a dynamic environment. • Strong project management and organizational skills. • Self–discipline and willingness to learn • Excellent verbal and written communication skills  Additional Information  Why work at Curinos? • Competitive benefits, including a range of Financial, Health and Lifestyle benefits tochoosefrom • Flexible working options, including home working, flexiblehoursand part time options,depending onthe rolerequirements– please ask! • Competitive annual leave,floatingholidays,volunteeringdaysand a day off for your birthday! • Learning and development tools to assist with your career development • Work with industry leadingSubject Matter Expertsandspecialist products • Regular social events and networking opportunities • Collaborative, supportive culture, includinganactiveDE&Iprogram • EmployeeAssistanceProgramwhich provides expert third-party advice on wellbeing, relationships, legal and financial matters,as well as access to counselling services  Applying  We know that sometimes the 'perfect candidate' doesn't exist, and that people can be put off applying for a job if they don'tmeetall the requirements. If you're excited about working for us and haverelevantskills or experience, please goaheadand apply. You could be just what we need!  If you need any adjustments to support your application, such as information in alternative formats,special requirements to access our buildingsor adjusted interview formatsplease contact usatcareers@curinos.comandwe’ll do everything we can to help.  Inclusivityat Curinos  We believe strongly in the value of diversity and creating supportive, inclusive environments where our colleagues can succeed.  As such, Curinos is proud to be an Equal Opportunity Employer. We do not discriminateon the basis ofrace,colour, ancestry, national origin, religion, or religious creed, mental or physical disability,medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other protected characteristics",Toronto,CA,1682545037,
,fy-vwEzYQbEAAAAAAAAAAA==,FULLTIME,Data Engineer,https://ai-jobs.net/job/48775-data-engineer/,"Company DescriptionYou will join a world-class team of engineers and data scientists from Facebook, Uber, Amazon and Google. We are a fast growing consulting firm based in Toronto with clients ranging from leading startups building impactful technologies to Fortune 500 companies looking to scale their engineering and data capabilities. Job DescriptionWe are looking for a data engineer who is passionate about analytics and helping companies build and scale data. You enjoy working with data and are motivated to produce high quality data tools and pipelines that help empower other data scientists. You are experienced in architecting data ETL workflows and schemas. Critical thinking and problem-solving skills are essential for this role.QualificationsBS (or higher, e.g., MS, or PhD) in Computer Science, Engineering, Math, or StatisticsHands on experience working with user engagement, social, marketing, and/or finance dataProficient in Python (i.e. Pandas, Numpy, scikit-learn, etc), R, TensorFlow, amongst other data science related tools and librariesExtensive experience working on relational databases, designing complex data schemas, and writing SQL queriesDeep knowledge on performance tuning of ETL Jobs, SQL, and databasesWorking knowledge of SnowflakeExperience working with Airflow is a strong plusDevops experiences is a plusAdditional InformationWe have very competitive compensation.Work on cool projects based on your interests and skills. We believe in accountability and NOT micro-management.",Toronto,CA,1682614701,
http://www.dataiku.com,fr2icExjjwIAAAAAAAAAAA==,FULLTIME,Data Scientist,https://wellfound.com/company/dataiku/jobs/2663448-data-scientist,"The role of a Data Scientist at Dataiku is quite unique. Our Data Scientists not only code up solutions to real-world problems, but also participate in client-facing endeavors throughout the customer journey. This includes supporting their discovery of the platform, helping integrate Dataiku with other tools and technologies, some user training, and co-developing data science projects from design to deployment.  Just as the non-technical skills are important, so too are the technical. Our Data Scientists work on the Dataiku platform every day. Aside from the visual tools, our team uses mostly python, with occasional work in other languages (e.g., R, SQL, pyspark, JavaScript, etc.). An ideal candidate is excited to learn complex new technologies and modeling techniques while being able to explain their work to other data scientists and clients.  In this role you'll help the team: • Co-develop production-level data science projects with our customers. • Analyze and investigate various kinds of data and machine learning applications across industries and use cases. • Help users discover and master the Dataiku platform, via user training, office hours, and ongoing consultative support. • Provide data science expertise both to customers and internally to Dataiku’s sales and marketing teams. • Develop custom Python or R-based “plugins” in collaboration with Solutions, R&D, and Product teams, to enhance Dataiku’s functionality.  You might be a good fit for the role if you have: • Curiosity and a desire to learn new topics and skills. • Empathy for others and an eagerness to share your knowledge and expertise with your colleagues, Dataiku’s customers, and the general public. • The ability to clearly explain complex topics to technical as well as non-technical audiences. • 1– 4 years’ of experience with ML tools (e.g., Python, R). • 1 – 4 years’ of experience building models. • Familiarity with data visualization in python, R. • Understanding of underlying data systems such as Cloud architectures, Hadoop, or SQL. • Being bilingual in French would be a plus. • Location: Must be located on the East Coast or Central regions of the United States or Canada and can work remotely (20% client-based travel).  Technical skills that may help you in the role: • Experience with Consulting and/or Customer-facing Data Science roles. • Experience with Data Engineering or MLOps. • Experience developing WebApps in Javascript, RShiny, or Dash. • Experience building APIs. • Experience using enterprise data science tools. • Passion for teaching or public speaking.  #LI-Remote  Dataiku focuses on Enterprise Software, Analytics, Machine Learning, Big Data, and Artificial Intelligence. Their company has offices in New York City, New York, Denver, Dubai, and Singapore. They have a very large team that's between 1001-5000 employees. To date, Dataiku has raised $837.29M of funding; their latest round was closed on December 2022.  You can view their website at http://www.dataiku.com/ or find them on Twitter, Facebook, and LinkedIn.",,US,1683064038,Information
,f6C4BNDndQgAAAAAAAAAAA==,FULLTIME,Data Engineer/Analyst,"https://www.ziprecruiter.com/c/Software-International/Job/Data-Engineer-Analyst/-in-Saint-Catherines,PE?jid=356b2f944fcba822","Our client is an Government Crown Corporation entity in Canada and they are looking to add a Data Engineer/Analyst who has a strong background with Python, Databricks, Power BI and  Azure Data Lakes.  Role: Data Engineer/Analyst  Type: Contract  Duration: 12 months  Location: Remote  Client: Canada Government  Number of openings: 1  Skills  Experience and Skill Set Requirements  Evaluation Criteria  Data Storage and Preparation - 35%  The candidate must demonstrate their experience with Azure Storage, Azure Data Lake Azure SQL DB, Azure Synapse and Azure Analysis Service structures in real world implementations  Data Pipelines - 35%  The candidate must demonstrate their experience with automating data pipelines using appropriate Microsoft Azure Platform/Technologies (Python, Databricks and Azure Data Factory)  Data Analytics - 15%  The candidate must demonstrate their experience with Power BI reports and dashboards  Knowledge Transfer - 15%  The candidate must demonstrate experience in conducting knowledge transfer sessions and building documentation for technical staff related to architecting, designing, and implementing end to end analytics solutions  Must Haves: • Python • Databricks • Power BI • Azure Data Lake",Saint Catherines,CA,1648045378,
http://www.sunlife.com,9_9r93HiARUAAAAAAAAAAA==,FULLTIME,Data Engineer (Security Analytics),https://ca.linkedin.com/jobs/view/data-engineer-security-analytics-at-sun-life-3586542162,"You are as unique as your background, experience and point of view. Here, you’ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world.  Job Description:  As a member of the Security Analytics team, you will play a pivotal role in working closely with our partners to enable threat intelligence, internal threat identification, predictive modelling, business intelligence and deep dive analytics to understand and identify new threats and incidents to make client data safer. As a security analytics Data Engineer you will join a team that leverages and is on a journey of quickly enhancing our Big Data and Cloud capabilities to enable various use cases by ensuring there is a solid data foundation in place to support data mining, strategic insight and automated capability enablement.  Given this mandate, the role requires 1-2+ years of intermediate experience in data management/programming and an understanding of the data needs of analytics and business and new technologies in the world of data.  Note: The ability to attain Reliability Status Clearance for this role is essential. When you are required to apply for this clearance, you must have lived continuously in Canada for the last 5+ years at the time of your clearance application. No exceptions please.  What will you do? • Work with the core security analytics team (data engineers and Business intelligence (BI) specialists) for data ingestion, management, AWS infra management and user 360s • Build data pipelines using AWS services that clean and structure data sets into a readable and searchable format for reporting, data science, analytics, and ad-hoc querying. • Maintain a large and complex data repository that provides accurate and reliable data to support reporting and insights about the user behavior. • Develop a strong understanding of the insights roadmap with the focus on providing data engineering solutions and continuous platform improvements to support real-time analytics. • Work intimately building a user data model to create easy access to user data and behavior. • Deepen the organizations understanding of user level data and provide expert guidance on how best to leverage data to provide actionable insights. • Execute on business data requests ensuring requests are aligned to Information Security priorities and the request fulfillment meets the stakeholder needs. • Demonstrates business values via PoC and promoting PoC to production. • Collaborates well in an agile environment to understand objectives and develop data solutions that deliver best in class, engaging and highly relevant experiences.  What do you need to succeed? • Bachelor’s Degree in Computer Science is preferred. • SQL/Python Programming along with experience in database technologies with 1-2 years of hands-on experience • Experience in data, analytics technology with relevant experience in data modelling. • Some experience is required on cloud technologies. Good to have AWS skills like S3, Glue, Lambda, Redshift • Able to understand the structure and build processes to build a data repository (includes basic ETL type processes, QA, data model etc.) with expertise with Python/ Spark/ Scala/ Glue/ Lambda/ RedShift or similar technologies. Knowledge of Java or any OOP is a Plus. • As a self-starter and someone who champions improvements, you will be expected to bring new ideas. • Work and coordinate on projects from initiation through planning, requirements, construction to implementation and post-implementation reviews. • Experience working within the Agile methodology. • Good communication skills and a team player • Information Security background is a PLUS but not mandatory.  The Base Pay range is for the primary location for which the job is posted. It may vary depending on the work location of the successful candidate or other factors. In addition to Base Pay, eligible Sun Life employees participate in various incentive plans, payment under which is discretionary and subject to individual and company performance. Certain sales focused roles have sales incentive plans based on individual or group sales results.  Diversity and inclusion have always been at the core of our values at Sun Life. A diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. We welcome applications from qualified individuals from all backgrounds.  Persons with disabilities who need accommodation in the application process or those needing job postings in an alternative format may e-mail a request to thebrightside@sunlife.com.  At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.  We thank all applicants for showing an interest in this position. Only those selected for an interview will be contacted.  Salary Range:  58,700/58 700 - 93,900/93 900  Job Category:  IT - Technology Services  Posting End Date:",,CA,1682701479,Finance
http://www.wattpad.com,P1oVKy4cWtoAAAAAAAAAAA==,FULLTIME,"Data Engineer, Analytics",https://wellfound.com/company/wattpad/jobs/2662146-data-engineer-analytics,"Wattpad is a global multiplatform entertainment company whose vision is to entertain and connect the world through stories. Since 2006, we’ve been on a mission to use the power of community and technology to unleash the full potential of stories to the world. Every month 85 million people around the world spend over 23 billion minutes on Wattpad to share and discover stories they can’t find anywhere else. Our brand banner includes: Wattpad, Wattpad WEBTOON Studios, Wattpad Books and Wattpad Brand Partnerships. We’re proudly based in Toronto, but our reach is global. Come build the future of entertainment and storytelling, and write your next chapter with us!  We are looking for a Data Engineer, Analytics to join our growing Data organization and support the Analytics squad. The squad's main focus is to partner with all of Wattpad's business units and product squads, to build ad-hoc reporting to metrics creation to forecasting and predictive insights projects. The goal is to advocate for and facilitate data-informed decision-making throughout the organization.  In this role, you will partner with data engineers, analysts and scientists. You will develop solutions and build analytics infrastructure to deliver trusted data. Data is critical to how we make decisions at Wattpad and you will play a key role in helping Wattpad continue to scale!  What you'll do: • Build and own analytics infrastructure that delivers good quality data, reliably • Support the building of robust, scalable data ingestion pipelines • Develop complex data models and transformations that standardize analytics products • Provide technical leadership on data solutions that are forward looking • Establish best practices for data warehousing • Evaluate new tools, build prototypes and be an advocate for modern, scalable data infrastructure  What we're looking for: • You have solid experience in designing schemas and data models for use in transformation and BI tools • You are comfortable building ETL/ELT flows that extract data from various systems • You have a good understanding of data engineering best practices (batch data processing, streaming, etc.) • You understand software engineering fundamentals and principles • You are comfortable leading data architecture and design discussions • You have curiosity towards experimenting with new data tools/methods and are abreast with the latest trends in data • Bonus: You have experience with DBT core/DBT cloud and LookML/Looker  Wattpad focuses on Mobile, Digital Media, Social Media, Entertainment, and Publishing. Their company has offices in Toronto. They have a large team that's between 201-500 employees. To date, Wattpad has raised $117.8M of funding; their latest round was closed on January 2018.  You can view their website at https://www.wattpad.com/ or find them on Twitter, Facebook, and LinkedIn.",,CA,1683007854,
,4P-Ve2RMltUAAAAAAAAAAA==,FULLTIME,Senior Data Engineer,"https://www.ziprecruiter.com/c/BCE/Job/Senior-Data-Engineer/-in-Mississauga,ON?jid=e9a3b5bf47dbc65e","Req Id: 410879  At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content - we advance how Canadians connect with each other and the world.  If you're ready to bring game-changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the Bell team.  The Finance Team manages the performance and risk profile of Bell, ensuring the needs of customers, investors and employees are balanced with long-term business success. We work closely with internal and external stakeholders to develop and execute plans that help the company achieve its strategic objectives and ensure financial sustainability.  A Senior Data Engineer reporting to the Director of Finance, you will need to consult with various stakeholders to understand business and technology challenges, design solutions in partnership with other subject matter experts. The ideal candidate will deliver solutions that improve Finance efficiencies and insights. Using your Leadership, technical, Business Intelligence and Finance skills, you will build tools to improve speed and accuracy in reports and generate insights that will allow Finance Operations to analyze, predict and optimize business results.  In particular, you will lead a team to create solutions and insight that combine, transform, analyze, share and catalyze consumption of financial results and related performance KPIs. The ideal candidate will leverage their leadership, technical, business, digital and creative competencies to drive information and insight from the large amount of data stored within our environments reporting status to the Senior Leadership.  The ideal candidate will leverage your natural curiosity, in testing and learning various tools, models, media and design as you continually look for new ways to glean key insights from the data, display results, and engage the stakeholder community with relevant solutions.  This unique position will expose you to the finance, BI, visualization and analytics fields. Leveraging leading edge enterprise technologies, process and governance will enable you to gather and share valuable information allowing us to better evaluate operational strategies while at the same time, from a finance perspective, allowing us to determine potential impact on future financial results.  Working individually and leading a team, you will provide accurate and useful information to the appropriate audiences.  The opportunity to communicate and work with employees & senior finance leadership from across the company, advocating the D&A CoE vision, will provide excellent networking opportunities.  Responsibilities: Lead a team of Data Engineers & Data Analyst Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL 'big data' technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems.  Critical Qualifications & Experience: Candidate with 5+ years of senior experience working in the telecom industry on complex data sets Strong leadership and high tolerance of ambiguity Polished written and verbal communication skills Experience leading team to build and optimize 'big data' data pipelines, architectures and data sets Proven Leadership and business acumen, with demonstrated ability to influence and to be a trusted advisor to senior management Advanced working SaS knowledge and experience working with relational databases, query authoring (PROC SQL). Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Strong organizational and communication skills. Experience supporting and working with cross-functional teams in a dynamic environment. We are looking for a candidate with 3+ years of experience in a Data Engineer role Experience with relational databases SaS, Teradata, Oracle & MS SQL.  Other Qualifications & Experience: Internal Bell systems knowledge required (ie: P77, PBW, Network Capital) Experience with data pipeline and workflow management tools. Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools: Alteryx, SaS EG, SQL Assistant, MS Office Experience with big data tools: Hadoop, Spark, Kafka, ""Cloud computing solutions"", an asset Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.  #EmployeeReferralProgram  Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.  Additional Information:  Position Type: Management Job Status: Regular - Full Time Job Location: Canada : Ontario : Mississauga || Canada : Ontario : Ottawa || Canada : Ontario : Toronto || Canada : Quebec : Montreal Flexible work profile: Mobile Application Deadline: 05/11/2023  Please apply directly online to be considered for this role. Applications through email will not be accepted.  At Bell, we don't just accept difference - we celebrate it. We're committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.  Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.  Created: Canada, ON, Mississauga  #Talent #Indeed #Tech  Bell, one of Canada's Top 100 Employers.",Mississauga,CA,1682660280,
https://www.pcfinancial.ca/en,VDWig3go7kgAAAAAAAAAAA==,FULLTIME,Data Engineer,https://ca.linkedin.com/jobs/view/data-engineer-at-president-s-choice-financial-3585960539,"Referred applicants should not apply directly to this role.  All referred applicants must first be submitted through Workday by a current Loblaw Colleague.  Location:  500 Lakeshore Blvd. West, Toronto, Ontario, M5V 2V9  When you hire great people, great things can happen.  PC Financial offers unprecedented value to Canadians through payment products. We're a different kind of bank with a different type of team—we’re collaborative and supportive and have the freedom and responsibility to thrive. Our purpose is to make the everyday simple and better for our customers, and we strive to make every dollar worth more.  Proudly serving over 3 million customers, PC Financial continues to grow by offering payment solutions and services that reward our customers every day. As a subsidiary of Loblaws Company Inc., we share the CORE values of Care, Ownership, Respect and Excellence. We are dedicated to helping Canadians Live Life Well. Join us on our journey.  Our mission is to build the PC Bank Payment & Rewards Data Platform, which would serve as an integrated data platform to perform complex big-data processing, advanced analytics, and machine learning. The Data Engineer position is a fantastic opportunity to join our expanding PC Bank Payment & Rewards Engineering team.  The Data Engineering team is looking for passionate engineers working in a fast-paced organization using Agile/Scrum methodology to deliver excellent solutions for our demanding customer service, operations requirements, and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy.  Some Of The Challenges The Candidate Would Tackle Are  You will participate in defining technical solutions, code architectures, and will be responsible for developing and delivering production-ready code. The ideal candidate will be someone who genuinely enjoys problem-solving and writing high-quality code to build robust, highly distributed, and scalable data processing systems and pipelines. • Design, implement and operate PC Bank’s core datasets that have extreme requirements on scalability, reliability, maintainability, flexibility, auditability, and quality • Design large scale streaming and batch data pipelines (billions of data points) that involve analyzing transactions over a long period without reprocessing vast amounts of data • Perform data profiling and source to target mapping analysis for the best design • Collaborate with business solution analysts, other engineers, solution architects, and other team members to innovate and evolve our datasets to data products to create a single coherent platform with sources of truth that serve a plethora of stakeholders within PC Bank  What You’ll Do • Apply your expertise in data and software engineering to design and implement data products that meet extreme requirements on scalability, reliability, maintainability, flexibility, auditability, and quality • Be T-Shaped. Your primary area is data engineering, but you are comfortable working in a secondary area of expertise such as data presentation/visualization, backend engineering, or data modeling (SQL, NoSQL, Graph & Time-series) • Work closely with cross-functional teams of data, backend and frontend engineers, product owners, technical product owners, and technical support personnel • Gaining technical expertise in building a data platform at scale to solve business, product, and technical use cases • Getting hands-on experience with technologies such as Elasticsearch, Apache Airflow, Apache Kafka, Apache Beam, Apache Spark, Hive, HDFS, Kubernetes (Openshift) • Getting hands-on experience with Google Cloud Platform and technologies such as BigQuery, Cloud Composer, Pub/Sub, Dataflow, Dataproc, GCS, Looker, and other cloud-native offerings in GCP  Who You Are • An undergraduate or Master’s degree in Computer Science or equivalent engineering experience • 2+ years of professional software engineering and programming experience (Java, Python) with a focus on designing and developing complex data-intensive applications • Familiarity with architecture and design (patterns, reliability, scalability, quality) of complex systems • Advanced coding skills and practices (concurrency, distributed systems, functional principles, performance optimization) • Professional experience working in an agile environment • Strong analytical and problem-solving ability • Strong written and verbal communication skills • Experience in operating and maintaining production-grade software • Comfortable with tackling very loosely defined problems and thrive when working on a team which has autonomy in their day to day decisions  Preferred Skills • Knowledge of software and data engineering best practices • Experience with large scale distributed data technologies and tools • Experience pulling data from a variety of data source types including Mainframe (EBCDIC), Fixed Length and delimited files, databases (SQL, NoSQL, Time-series) • Strong coding skills for analytics and data engineering (Java, Python, and Scala) • Experience performing analysis with large datasets in a cloud-based environment, preferably with an understanding of Google’s Cloud Platform (GCP) • Understands how to translate business requirements to technical architectures and designs • Comfortable communicating with various stakeholders (technical and non-technical)  Nice To Have Skills (though Not Required) • Exposure to data-science or machine-learning packages (Pandas, Pytorch, Keras, TensorFlow, etc...) • Contributions to open-source software (code, docs, or mailing list posts) • GCP Professional Data Engineer Certification • Confluent Certified Developer for Kafka  COVID-19 is a serious condition and has had a devastating impact on Canadians and others across the globe. As a leading Health and Wellness provider for millions of Canadians, our goal is to help all Canadians ""Live Life Well"".  In support of this goal, we have adopted a COVID-19 Vaccination Policy to protect the health and well-being of our employees as we continue our phased approach of office reopening. Employees will be required either to be fully vaccinated or undergo regular COVID-19 Rapid Antigen Screening in order to access the workplace.  Come and join a winning team who demonstrates innovation, energy, creativity and vision. We recognize the importance of a diverse workforce and we therefor encourage applications from Aboriginal Peoples, women, members of a visible minority and persons with a disability. We thank all applicants for their interest, however, only those selected for an interview will be contacted.  Number Of Openings  0  PC Financial recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. Accommodation is available upon request for applicants and colleagues with disabilities.  In addition, we believe that compliance with laws is about doing the right thing. Upholding the law is part of our Code of Conduct – it reinforces what our customers and stakeholders expect of us.  Please Note: If you have Employee Self Service (ESS) on Workday, apply to this job via the Workday application.",Toronto,CA,1682681737,Finance
,mxrut48of94AAAAAAAAAAA==,FULLTIME,Data Engineering Analyst,https://www.reed.co.uk/jobs/data-engineering-analyst/50344348?source=searchResults&filter=%2Fjobs%2Fgeneral-insurance-jobs%3Fsortby%3DDisplayDate,"• Responsibilities will include, but are not limited to, the following: • Provide technical support for the design, construction and maintenance of data for the business • Coordination of data projects with different levels of complexity depending on existing methods, processes and tools • Manages and coordinates stakeholders and builds a robust communication structure for data-related projects • Advises stakeholders and actively clarifies their expectations and requirements • Ability to assume responsibility for change, communication, quality and risk management • Understand the data relationships that exist between the business processes and systems. In turn apply this knowledge when interpreting the information requirements from the business • Translate data, analysis and commentary into a format for presentation to senior management • Gather, interpret, identify gaps and translate business MI and reporting requirements into solutions • Carry out analysis and interpret data to support the business in strategic and commercial decisions • Understand database and data science concepts and terminology, design principles and elements in order to deliver data and analytics • REQUIREMENTS • To be successful in this position you will need to have the following skills/ experience: • Programming experience essential with direct exposure to SQL and ideally Power BI. • Exceptional academic background in Maths and IT from top tier university • Experience in working cross functionally and collaboratively with others • Ability to interpret user needs and translate into technical requirements • Works with little guidance and direction and performs majority of tasks independently • Customer Focused • Ability to work effectively within a team environment • Honesty and Integrity • Excellent communication skills, with the ability to explain complicated processes and concepts to non-experts • Excellent analytical skills (capable of understanding complex data structures, organise and structure data extracts) • High attention to detail including a commitment to accuracy of work. • Ability to work independently and resolve complex problems without direct supervision",London,GB,1683072000,
,dOJ1uLt1HsoAAAAAAAAAAA==,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-the-people-network-3594559414,"Are you an experienced Data Engineer with expertise in the AWS package looking to progress your experience in a highly innovative consultancy that is leading the forefront delivering digital transformations across the globe.  Required Skills/Experience: • Expertise in both Python and SQL • Good exposure to AWS Services like AWS Lambda, AWS Glue, S3, IAM, Cloudwatch, SQS, etc. • Proficiency in working on data platforms such as Teradata and Snowflake • Experience evaluating business requirements and mapping technical stories  Desirable Skills/Experience: • Experience of Apache Airflow. • Exposure of developing an automation framework to validate data. • Good understanding of CI/CD process.  Applications from candidates working on a dependant visa, as well as post-study work visa's are accepted.(As long as you currently living in the UK, and possess full time working rights in the UK)  Salary expectations for this role are between £45k and £50k  If you are ready to advance your career and join a dynamic team of Data Engineering professionals, apply now!",London,GB,1683122022,
http://www.iwoca.co.uk,hFbonp6_B04AAAAAAAAAAA==,FULLTIME,Data Engineer - Core Systems,https://ai-jobs.net/job/48785-data-engineer-core-systems/,"We’re here because we believe in small businesses. We believe they deserve better than waiting weeks for a loan. And we believe it’s our job to help them grow. We started in 2012 with these principles, and we hold true to them today – now that we’re one of the fastest-growing fintechs in Europe. In the time between, we’ve built the best tech platform in lending, won several awards and opened up £3.5 billion in loans to over 90,000 businesses. So what’s next? Our mission now is to help one million businesses who need us. To do this, we’ll need new products and partnerships. But most of all, we’ll need smart, hands-on people to join us on the journey and get us to our goal. The roleAt iwoca we are dedicated to building the smartest lending platform in the world as we believe that finance should be as simple, seamless and powerful as electricity. We like to use Agile(ish) processes, which means features or projects go live in days or weeks rather than months or years. We run our Django-powered site on AWS, use asynchronous tools (Twisted, Celery) for time-consuming tasks and scientific libraries (NumPy, Scikit-learn, SciPy, Pandas) for risk aspects. Application orchestration is done with Docker/Terraform/ECS and our monitoring is set up using DataDog/Sentry. We are looking for someone who has a solid amount of data engineering experience across different environments. Who can advise on and implement data architecture design. Who will collaborate with business users, analysts and data scientists to deliver high-quality reporting products. You'll have the opportunity to learn lots on the job and develop rapidly within a high performing team of engineers. Responsibilities Develop, construct, test and maintain data architectures and pipelines that align with business requirements. Identify practical ways to improve data reliability, efficiency and quality. Build, maintain, and document reporting tools that support data driven decision-making by business users. Liaise with stakeholders in the wider business to help improve data quality, advise on data strategy and help implement ingestion of new data assets from external sources. Assist data scientists in systemising data analysis to be deployed into a production environment. Work with analysts to streamline and improve operational and developmental access to data. Troubleshoot emerging data and operational problems, and be a source of knowledge for end-users on the most appropriate way of using data for their purposes. Support your teammates by learning and sharing your knowledge. RequirementsWe look for people that are smart, humble, motivated and who are always looking to improve. Ideally, you’ll have: Experience in implementing reliable and performant data architectures, including ETL pipelines, relational databases, and columnar-storage data warehouses. Professional experience in data engineering / software development. Professional experience or a degree in a quantitative field, such as Mathematics, Physics, Engineering or Computer Sciences. Solid understanding of SQL and relational databases (esp. PostgreSQL). Comfortable implementing custom (in-house) data solutions where off-the-shelf products are unavailable or unsuitable. Bonus: Advanced LookML knowledge. Experience using TensorFlow, Scikit-learn, Matplotlib. Building backend systems, frameworks, and libraries. DevOps practices (CI/CD), Docker and Kubernetes. Understanding of data science concepts. Typescript / React. Experience with Docker. We expect to pay from £100,000 - £120,000 for this role. But, we’re open-minded, so definitely include your salary goals with your application. We routinely benchmark salaries against market rates, and regularly remunerate staff for their increasing value to our business. At iwoca, we prioritise a culture of learning, growth, and support, and invest in the professional development of our team members. You'll have access to ample opportunities for skill-building, mentorship, and career progression, and can decide your career path, focusing on frontend, branching into full-stack, or developing your skills in project and people leadership. We value thought and skill diversity, and encourage you to explore new areas of interest to help us innovate and improve our products and services. Our friendly and inclusive environment, combined with our flexible work policies, ensures that you'll have the perfect balance between work and life, empowering you to thrive both personally and professionally.BenefitsWe put a lot of effort into making iwoca a brilliant place to work: Offices in London, Leeds, and Frankfurt Events and clubs, like bingo, comedy nights, yoga classes, football… Two company retreats a year, we’ve been to France, Italy, Spain and further afield Plenty of drinks and snacks in our offices. We offer a wide range of benefits: Medical insurance from Vitality, including discounted gym membership 25 days’ holiday and an extra day off for your birthday Instant access to emotional and mental health support with our partner, Spill Generous maternity leave and shared parental leave A nursery tax benefit scheme to help you save money Paid volunteering time to support your chosen charity Extra leave if you want to travel or study One-month fully paid sabbatical after 4 years Cycle-to-work scheme and electric car scheme And to make sure we all keep learning, we offer: An L&D budget for everyone, including a book budget Company-wide talks with internal and external speakers Access to learning platforms like Treehouse, Frontend-masters and Pluralsight",London,GB,1682589985,Retail
,mKRlvgskrkkAAAAAAAAAAA==,FULLTIME,Data Analyst / Junior Data Engineer,https://www.totaljobs.com/job/analyst-junior/cervello-limited-job100236189,"Data Analyst / Junior Data Engineer  Cervello is looking for innovative data-driven individuals who are keen to get hands-on experience working with businesses to unleash the value from their data. As a data analyst/junior data engineer, you will join an interdisciplinary team of architects, data scientists and big data consultants and get exposed to data in a commercial context.  Required skills: • Bachelor’s degree in STEM subjects • Strong analytic abilities, with the demonstrable desire to identify insights from qualitative and quantitative data • Ability to understand and apply highly technical specification to datasets across different industries • High attention to detail and flexibility in juggling different responsibilities • Ability to work independently in a high pressure, time-critical / client-centric environment • Proficient in data visualization skills with technologies such as PowerBI, Tableau • SQL, relational database and (structured/unstructured) data querying  Desired skills: • Master’s degree in STEM subjects • Ability to gather and process raw data at scale (including writing scripts, web scraping, working with APIs, writing SQL queries, etc.) Strong programming experience in Python, R, Java, Scala, Bash • Understanding of data warehousing and data modelling • Practical knowledge of data structures and algorithm • Distributed cloud computing (AWS / Azure / GCP) • Experience working with a variety of ELT/ETL tools like Matillion, Talend, Streamsets  About us: our workplace is fun and fast-paced:  We are Cervello. We believe in the power of connected data. We are laser focused on helping organizations harness the interconnectedness of digital, data and decision-making. We are problem solvers and builders focused on helping our clients win with data. Our culture is cool and innovative. Our environment is casual and conducive to collaboration and problem solving. We take our work seriously but not ourselves. It’s the perfect balance of freedom and accountability. If you want to be part of something great – join us!  Equal Employment Opportunity and Non-discrimination  Cervello prides itself on providing a culture that allows employees to bring their best selves to work every day. Our people can feel comfortable, confident, and joyful to do great things for our firm, our teams, and our clients. Cervello aims to build diverse capabilities to help our clients solve their most mission critical problems. Cervello is committed to building a diverse, unbiased and inclusive workforce. Cervello is an equal opportunity employer; we recruit, hire, train, promote, develop, and provide other conditions of employment without regard to a person’s gender identity or expression, sexual orientation, race, religion, age, national origin, disability, marital status, pregnancy status, veteran status, genetic information or any other differences consistent with applicable laws. This includes providing reasonable accommodation for disabilities, or religious beliefs and practices. Members of communities historically underrepresented in analytics and consulting are encouraged to apply.",London,GB,1681471320,
http://www.mottmac.com,rG6boSIEbdQAAAAAAAAAAA==,FULLTIME,2023 UK Graduate Data Scientist Career Path,https://uk.linkedin.com/jobs/view/2023-uk-graduate-data-scientist-career-path-at-mott-macdonald-3589659823,"Job Description  Working as a Data Scientist for our buildings and cities (BNC) business, you will join our growing digital solutions team to deliver leading-edge digital solutions to our clients from various industries. By working together, you will help solve complex problems and develop innovative data-driven analytics and solutions in the field of physical and digital infrastructure, all through the application of data science.  You will join an enthusiastic and diverse team of geographic information systems and data science professionals passionate about data, location intelligence, analytics and powerful visualisation of the results. Through connected thinking and collaboration with colleagues across the Mott MacDonald organisation internationally you will be part of the wider team of data scientist, software engineers, solution architects, and engineers focusing on excellence and digital innovation.  You will support development of innovative solutions to client’s asset management problems, applying data science and data engineering, including machine learning/deep learning and computer vision as well as analysing a broad range of spatial and non-spatial information within the public domain including openly available data, websites, new feeds, connecting to data stream through web services and APIs.  Responsibilities  Within the scope of the projects delivered, you may be responsible for any number of these elements  As a Data Scientist you will have a chance to work with and learn from the other members of our team. • Applying AI and advanced analytics, including spatial and geostatistical analytics, to large data sets within the asset management domain and across sectors including Buildings and Cities, Transport, Energy, Water and Environment. • Partnering with other GIS consultants, data scientists and software engineers to define and develop machine learning and data engineering products on premise or cloud-based platforms. • Working with cloud based platforms such as Azure or AWS • Designing and implementing ETL processes. • Presenting information using data visualisation techniques. • Inspiring self-serve data use by building dashboards and reports to drive awareness and understanding. Our ideal candidate would have experience developing/implementing real-time computer vision algorithms on GPU will be advantageous as well as experience with a version control system such as Git to collaborate and manage a large codebase, ability to create fully reproducible and documented results with machine learning using principles like data versioning. Familiarity with using Linux shell, and SSH for remote code deployment would also be beneficial.  As a Data Scientist you will have a chance to work with and learn from the other members of our team, including GIS professionals and data scientists, join first class GIS and Data Science communities as well as wider teams at Mott MacDonald including software engineers, solution architects, and engineers. Duties to include; • Define and develop machine learning products. • Define and develop data engineering pipelines. • Designing and implementing ETL processes, including spatial ETL. • Presenting information using data visualisation techniques. • Inspiring self-serve data use by building dashboards and reports to drive awareness and understanding  Candidate Specification  We are looking for committed and motivated graduates with a genuine passion and a desire to make a difference in the world. If this describes you, apply today to launch your career at Mott MacDonald.  To Be Eligible For This Opportunity, You Will Have Less Than 12 Months Experience And Have a Degree Or Are Expected To Achieve One Of The Following Degree Disciplines • Data Science • Mathematics • Statistics • Machine Learning In your application you should be able to demonstrate your interest through relevant experience, such as studying relevant modules, or previous work experience.  We Are Looking For Graduates With The Following Characteristics • Methodical approach to problem solving • Ability to use your initiative to undertake tasks efficiently and independently. • Excellent verbal communication skills, which allow you to confidently liaise with clients and team members. • Excellent written communication and attention to detail and be able to demonstrate accurate technical drawings and good report writing. • Strong programming skills (Python/R) with exposure to Machine Learning packages such as Tensorflow/Keras, Pytorch or scikit-learn. As we want the best people for the role, it is available as part time, job share or full time. This is because we recognise that sometimes people are not available full time. Please ask us at interview stage about any flexibility you may need.  Job Profile  About Your Development  A graduate position should be more than just a job. We know this and so do you. That’s why with our graduate roles, we aim to give you the experience and technical knowledge you need to progress your career.  From the moment you join us, you’ll receive the training you need. You will be assigned a chartered mentor, who will guide you to meet the objectives of your professional training agreement. We’ll support you on your journey to gaining chartered status with your chosen institution.  What else is involved?  You’ll be enrolled onto Accelerate Your Future, a structured three-year soft-skills development programme which develops the strengths that we know graduates need to be successful at Mott MacDonald. It also gives you the opportunity to network and meet other graduates in your cohort. The programme is a mix of residential events, classroom-based learning, virtual webinars, and CSR (Corporate Social Responsibility) challenges. We understand that each person’s career goals vary, therefore we tailor make each individual’s development programme to suit them. With our vast library of e-learning courses available to you, you can choose which direction you want your career to go in.  You will have the opportunity to make a difference; learn more about our Social Outcomes and the difference we can make!  Did you know that Mott MacDonald are Work180 accredited – which means we actively support and encourage women to join our work force!  You’re probably wondering what else is on offer. Join us, and you’ll get: • Biannual salary reviews: we believe that hard work should be rewarded and recognised. Therefore, for the first three years of your career with us, you’ll have biannual salary reviews. • A competitive salary: in addition to biannual reviews, we will ensure that you’re given a salary that matches the current industry standard. • Contributory pension up to 7% of your salary: we have the best people on our team, and we like to look out for them. With our support, you’ll have all the advice and options you need to be able to invest in your future. • A flexible benefits scheme: our company is made up of a range of different people and we understand that different people want different things. That’s why with our flexible plan, you’ll have the ability to manage the range of benefits we have on offer, to suit your specific needs. Our social side  Being part of Mott MacDonald means more than just work, there’s a huge range of fun and exciting things that you can get involved in.  From the moment you join us, you’ll have the opportunity to expand your social and professional network, whether it’s meeting other graduates or joining forces with other members of staff from around the company at our annual sports day. Each of our offices have a sports and social committee which will give you the chance to be part of a variety of sports, social and charity events. We’re committed to promoting a strong culture of social responsibility and encourage our staff to play active roles in the local community.  It's worth noting that sports and social committees tend to vary from office to office, so as well as getting involved in what’s already on offer, don’t be afraid to suggest new events or initiatives that you think could be a great addition.  It doesn’t stop there. As well as events, you’ll also have access to discounts on cinema tickets, travel, fashion, utilities and much more as part of our company benefits which you can take advantage of the moment you join.  Other Information  Equality, diversity and inclusion  We put equality, diversity and inclusion at the heart of our business, seeking to promote fair employment procedures and practices to ensure equal opportunities for all. We encourage individual expression in our workplace and are committed to creating an inclusive environment where everyone feels they have the opportunity to contribute.  Agile working  At Mott MacDonald, we believe it makes business sense for you and your manager to choose how you can work most effectively to meet your client, team and personal commitments. We embrace agility, flexibility and trust.  More About Mott MacDonald  We’re a global engineering, management and development consultancy.  Our purpose is to improve society by considering social outcomes in everything we do, relentlessly focusing on excellence and digital innovation, transforming our clients’ businesses, our communities and employee opportunities.  A fundamental part of this is respecting each person’s differences and striving to meet their needs.  Our values: progress, respect, integrity, drive, excellence  Job Ref  59364BR  Recruiter Contact  earlycareers.recruitment@mottmac.com  Country  United Kingdom  Region/State  England - South West  Discipline  Consultancy  Sector  Built environment  Website Region  Europe and Central Asia  Website Sector  Buildings",Birmingham,GB,1682621729,Engineering Services
http://www.apple.com,tF1GONrVQNIAAAAAAAAAAA==,FULLTIME,Data Analytics Site Reliability Engineer,https://jobs.apple.com/en-us/details/200449123/data-analytics-site-reliability-engineer,"Summary Posted: Apr 11, 2023 Weekly Hours: 35 Role Number:200449123  At Apple, our Data Analytics team focuses on improving the user experience by improving operating system stability, gathering feature usage telemetry, and evaluating device performance. This requires capturing data from customers who have given consent, utilizes strong privacy preserving techniques, and entails aggregating information, all to help inform direction. We develop and operate a variety of Big Data infrastructure products and applications in support of these goals.  Key Qualifications  Key Qualifications • Demonstrable experience of production experience managing and supporting large scale distributed Big Data applications (from development to production) • Experience with at least one of the following languages and related development tools: (Python, Ruby, Java, Scala) • Experience with one or more of the following platforms: HDFS, Yarn, Spark, Impala, Hbase, MapReduce, Kubernetes, other cloud services • Passion for quality and attention to detail • Excellent written and verbal communication skills  Description  Description We are looking for Site Reliability Engineer to be a member of our team. If working on large scale problems excites you then we’re excited to talk to you! Our team helps Apple engineers answer mission critical questions about their hardware, firmware, and software. We work with engineers across Apple to help keep our suite of analytics applications available and to ensure the integrity of their data. The successful candidate will write code to automate our processes to ensure reliability and manage thousands of compute and storage instances across large heterogeneous infrastructure. You'll dive into complex data and application issues to drive root cause analysis of large scale problems. You'll partner with your teammates and peers to solve problems, applying critical thinking skills and understanding of complex distributed systems. The candidate will have to opportunity to contribute to the development of Apple's applications such as Mail and Safari, in addition to help to improve the performance of macOS and iOS. Build, monitor, troubleshoot complex data infrastructure at the petabyte scale - Support the continuous development and deployment of multi service analytics applications - Develop tools and processes to automate the management of our systems and data  Education & Experience  Education & Experience Bachelor's degree or equivalent experience  Additional Requirements  Additional Requirements • Apple’s most important resource, our soul, is our people. Apple benefits help further the well-being of our employees and their families in meaningful ways. No matter where you work at Apple, you can take advantage of our health and wellness resources and time-away programmes. We’re proud to provide stock grants to employees at all levels of the company, and we also give employees the option to buy Apple stock at a discount — both offer everyone at Apple the chance to share in the company’s success. You’ll discover many more benefits of working at Apple, such as programmes that match your charitable contributions, reimburse you for continuing your education and give you special employee pricing on Apple products. • Apple benefits programmes vary by country and are subject to eligibility requirements. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities.",London,GB,1681171200,Manufacturing
,xgI86In4K4MAAAAAAAAAAA==,FULLTIME,Lead Data Engineer-Data Management,https://uk.linkedin.com/jobs/view/lead-data-engineer-data-management-at-insight-international-uk-ltd-3585919733,"Role: Lead Data Engineer-Data Management  Location: Bristol or London, UK  Job Type: Contract  Job Description: • Overall 15 years or more experience in delivering Data projects • Experience in introducing new products and maturing the services and adoption of new technologies/ features within the organisation • Experience in designing and developing integration patterns for the products, components or features being introduced, including the security aspects of the solution design • Integration experience with Cloud (GCP) hosted applications • Experience in at least two of the domains of Reference Data (Informatica Ref360), Unstructured Data Management, Archiving (Informatica ILM), Data Protection (Protegrity) and Model Inventory (IBM OpenPages)  Important: • Need either MDM/Ref Data and/or Unstructured data and someone who can adapt and extend. • A good data architect who can work on multiple fronts and has great communication will fit.",London,GB,1682676148,
http://www.bp.com,rEjc6XF3vIYAAAAAAAAAAA==,FULLTIME,Staff Data Engineer,https://www.bp.com/en/global/corporate/careers/jobs-at-bp/Staff-Data-Engineer-130846BR.html,"Responsible for delivering business analysis and consulting activities for the defined specialism using advanced technical capabilities, building and maintaining effective working relationships with a range of stakeholders, ensuring relevant standards are defined and maintained, and managing process and system improvements to deliver business value. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.",,GB,1683072000,Mining
http://www.gsk.com,QzHZeVRQgUwAAAAAAAAAAA==,FULLTIME,"Principal Data Engineer, Scientific Digital & Tech",https://www.themuse.com/jobs/gsk/principal-data-engineer-scientific-digital-tech-345632,"Site Name: USA - Pennsylvania - Upper Providence, UK - Hertfordshire - Stevenage, Wavre Posted Date: Apr 19 2023  Come join us as we supercharge GSK's data capability! At GSK we are building a best-in-class data and prediction powered team that is ambitious for patients.  Scientific Digital and Tech's goal is to power the discovery, development and supply of medicines and vaccines to patients. This means new tools to discover new medicines and vaccines, predictive capability for pre-clinical research, accelerated CMC and supply chain and an improved day-to-day laboratory experience for our scientists. Our Digital & Tech solutions will automate workflows and speed up decisions; freeing hands and releasing minds to focus on science.  As R&D enters a new era of data driven science, we are building a data engineering capability to ensure we have high quality data captured with context and aligned data models, so that the data is useable and reusable for a variety of use cases.  GSK R&D and Digital and Tech's collective goal is to deliver business impact, including the acceleration of the discovery and development of medicines and vaccines to patients. The R&D Digital and Tech remit has expanded over the past 2 years, and to position GSK for the future, The change will strengthen R&D Tech, to provide more strategic impact, focus, accountability, and improved decision making in the use of Digital, Data and Analytics (DDA) to strengthen the pipeline.  The Scientific Digital and Tech organization part of R&D Digital & Tech is an integrated family that powers the GSK R&D discovery, manufacture, and supply of new medicines and vaccines to patients. It focuses on optimizing CMC, informing Vaccine and Medicine design, and delivering a competitive, modern laboratory experience.  Scientific Data Engineering is a new organization responsible for enterprise data and architecture, providing thought leadership and architecture services for all aspects of data across the Scientific area. This includes the use of, and augmentation to, the two GSK data platforms on GCP and Azure, design and creation of data pipelines to surface data as a ""product"" in a data Mesh architecture across two platforms.  Job Purpose:  The Principal Data Engineer contributes to the construction of the CMC data Mesh and data strategy. This role will interact with architects, engineers, data modelers, product owners as well as other team members in Scientific Tech and R&D.  The Principal Data Engineer is a leading technical contributor who can consistently take a poorly defined business or technical problem, work it to a well-defined data problem/specification, and execute it at a high level. They have a strong focus on metrics, both for the impact of their work and for its inner workings/operations.  They are a model for the team on best practices for software development in general (and data engineering in particular), including code quality, documentation, DevOps practices, and testing, and consistently mentor junior members of the team. They ensure the robustness of our services and serve as an escalation point in the operation of existing services, pipelines, and workflows.  The Principal Data Engineer should demonstrate core engineering knowledge/experience of industry technologies, practices, and frameworks such as data Mesh and scaling data platforms, containerization, cloud-based platforms, data analytics, and data streaming. Examples of technologies include Java/C#/Python, Denodo, GIT, Azure DevOps, Data Bricks, Spark, Azure Data Factory, ADLS V2, Kafka, Selenium, JUnit/NUnit, SAFe, Kanban, Docker, Azure Cloud Architecture including networking principles and scaling applications.  Primary responsibilities include the following: • Using Azure cloud services and GSK data platform tools to ingest, egress, and transform data from multiple sources. • Confidently optimizes the design and execution of complex solutions in data ingestion and data transformation • Produces well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy • Provides input into the roadmaps of upstream teams (e.g., Data Platforms, DataOps, DevOps) to help improve the overall program of work • Ensure consistent application of platform capabilities to ensure quality and consistency concerning logging and lineage • Fully versed in coding best practices and ways of working, and participates in code reviews and partnering to improve the team's standards • Adhere to QMS framework, Security & Regulatory Standards, and CI/CD best practices and helps to guide improvements to them that improve ways of working • Provide leadership to team members to help others get the job done right • Supporting engineering teams in the adoption and creation of data Mesh best practices. • Maintains best practices for engineering and architecture on our Confluence site. • Pro-actively engages in experimentation and innovation to drive relentless improvement • Provides leadership, technical direction, and GSK expertise to architecture and engineering teams composed of GSK FTEs, strategic partners, and software vendors. Why you?  Basic Qualifications:  We are looking for professionals with these required skills to achieve our goals: • BS in Computer Science • Experience in all the following: • Data Engineering development, architecture design & technology platforms/frameworks • Azure Data Analytics services e.g. ADLS, Azure Data Factory, Azure Databricks, Purview, Azure Synapse, etc. • Data Platforms and Domain-driven design • Agile, DevOps & Automation [of testing, build, deployment, CI/CD, etc.] • Data analytics & data quality/integrity • Testing strategies & frameworks • Python experience required Preferred Qualifications:  If you have the following characteristics, it would be a plus: • MS in Computer Science • Experience with various open-source ecosystems including JavaScript, Bigdata, java, scala, python, etc. • Experience in agile software development and DevOps, relevant technology platforms [e.g., Kubernetes] and frameworks [e.g. Docker] including cloud technologies & data structures (i.e. information management), data models or relational database design • Subject matter expertise in Pharma CMC and scientific domains. • Experience in applying data curation, virtualization, workflow, and advanced visualization techniques to enable decision support across multiple products and assets to drive results across R&D business operations. • Role requires: • Demonstrated skill in delivering high-quality engineered data products • Knowledge of industry standards and technology platforms • Excellent communication, negotiation, influencing, and stakeholder management skills • Customer focus and excellent problem-solving skills • Good understanding of various software paradigms: domain-driven, procedural, data-driven, object-oriented, functional • Demonstrable knowledge depth in more than one area of software engineering and technology #LI-GSK  #SCD  Why GSK?  GSK is a global biopharma company with a special purpose - to unite science, technology and talent to get ahead of disease together - so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns - as an organisation where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.  Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it's also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We're committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.  If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).  GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.  Important notice to Employment businesses/ Agencies  GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.  Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK's compliance to all federal and state US Transparency requirements. For more information, please visit GSK's Transparency Reporting For the Record site.",Stevenage,GB,1681989204,Manufacturing
http://www.dnb.com,4xNpGk_pPbYAAAAAAAAAAA==,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-dun-bradstreet-europe-3497500566,"Why We Work at Dun & Bradstreet  Dun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!  About The Role  You will be part of the team that is responsible for the accuracy and integrity of our UK and Ireland Identity Data. You will deliver and maintain data engineering solutions that ensure consistent operation of our UK and Ireland Data Management System. You will develop new innovative processes to manage data quality and streamline existing processes to execute data improvement plans more efficiently and effectively.  You will also be key technical support in conversations with our data partners to help understand their data and ensure we are maximizing value from all our data sources  Key Responsibilities • Day-to-day operations of our Data Management System; ensuring process and procedures run as expected and any bugs are fixed in a timely manner with business-critical processes prioritised • Architecting solutions; Design, develop and test fit for purpose, resilient, scalable, and future-proof data services. • Recognise and exploit opportunities to ensure efficient and effective performance of Data processes. Explore new ways of conducting operational processes; developing ways of maximising the update cycle on data; achieving the best cost model whilst maintaining data quality • Write ETL scripts and code to make sure ETL processes perform optimally • Design, write and iterate code from development to production-ready. Understands security, accessibility, and version control. Can use a range of coding tools and languages. • Plan, design, manage, execute, and report tests, using appropriate tools and techniques, and works within internal policy and regulations. Ensuring risks associated with deployment are adequately understood and documented • Design and maintain appropriate metadata repositories to enable understanding of data assets and full auditability. • Partnering with cross-functional teams to understand how new sources will contribute towards the ongoing enhancement of data assets to achieve goals for database size, completeness, and other desirable improvements. • Creation of operational reports to measure usability and performance of data sources • Contribute to the vision and scope for the next generation of our data to drive revenue, performance quality and ensure operational efficiency, including new types of data and emerging capabilities for data collection. • Support operational plans that deliver business requirements through leading and coordinating their development, testing, and managing stabilisation activities.  What We're Looking For • 3+ years of proven in-depth knowledge and experience of SQL and database querying languages • Knowledge of other languages, like Python, would be advantageous • Ability to use PowerBI would be advantageous • Experience with ETL tools, in particular SSIS (SQL Server Integration Services) • Experience working with API’s and services • Has a demonstrable understanding of how to expose data from systems (for example, through APIs), link data from multiple systems using different storage technologies/access methods and deliver streaming services. Creates repeatable and reusable procedures. • Ability to correctly execute test scripts under supervision. Understanding the role of testing and how it works. • Aware of the types of problems in databases, data processes, data products and services. • Ability to run development using Agile and Kanban methodologies • Dynamic and results-driven with the focus on facilitating action and effecting change • An innovative and inspirational approach • Self-motivation with the desire to learn new techniques – relentlessly curious • Demonstrable experience in Database design, modelling and best practice • Analytical, process and problem-solving skills in a highly complex environment. A clear thinker who can articulate database issues and solutions and gain support for implementation, whilst remaining focused on what is important. • Ability to prioritise and multitask with flexible approach to changing deadlines and scope of project • Ability to work independently • A great team player  All Dun & Bradstreet job postings can be found at https://www.dnb.com/about-us/careers-and-people/joblistings.html . Official communication from Dun & Bradstreet will come from an email address ending in @dnb.com.  Global Recruitment Privacy Notice",London,GB,1677602351,Business Support
http://www.google.com,Ks6uzFTPERsAAAAAAAAAAA==,FULLTIME,"Data Engineering and Analytics, Google Data Centers",https://www.salary.com/job/google/data-engineering-and-analytics-google-data-centers/j202202151025478272060,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Sunnyvale, CA, USA; Kirkland, WA, USA; Austell, GA, USA.  Minimum qualifications: • Bachelor’s degree in Information Systems, Computer Science, Data Science, Analytics, Mathematics, or equivalent pratical experience • 5 years of experience leading data engineering and data analytics, business intelligence, and data models using SQL and Python languages • 5 years of technical program management experience in a data related domain  Preferred qualifications: • Master's degree in Information Systems, Computer Science, Data Science, Analytics, Mathematics, or related experience • 2 years of experience developing real time streaming data pipelines using GCP BigQuery, Dataflow and Publish/Subscribe (Pub/Sub) from heterogeneous data sources (eg. Oracle, SAP, etc.), or predictive analytics/machine learning • Experience leading organizational change efforts using data tools and solutions to improve organization efficiency  About the job  A problem isn’t truly solved until it’s solved for all. That’s why Googlers build products that help create opportunities for everyone, whether down the street or across the globe. As a Program Manager at Google, you’ll lead complex, multi-disciplinary projects from start to finish — working with stakeholders to plan requirements, manage project schedules, identify risks, and communicate clearly with cross-functional partners across the company. Your projects will often span offices, time zones, and hemispheres. It's your job to coordinate the players and keep them up to date on progress and deadlines.  Our goal is to build a Google that looks like the world around us — and we want Googlers to stay and grow when they join us. As part of our efforts to build a Google for everyone, we build diversity, equity, and inclusion into our work and we aim to cultivate a sense of belonging throughout the company.  As a Technical Program Manager, you will architect and build data engineering processes and drive quality/consistency of data across business functions. You will use your technical and data expertise to establish robust data pipelines and solutions to facilitate trusted data availability across multiple systems. You will work with our Data Center business stakeholders to understand their data issues and challenges, utilize your technical expertise to build and deploy simple, efficient, secure, scalable data solutions, services, and insights. You will manage a portfolio of programs that help Data Center teams successfully operate, while transforming the organization by building and integrating the next wave of data solutions to increase trust in data, insights, and data-driven decision making.  Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.  Responsibilities • Lead the technical delivery, implementation, and business adoption of new scalable and reliable data analytics and business intelligence solutions for cross-department leadership and business teams • Build the infrastructure required for optimal ETL of data from a wide variety of data sources using Google Cloud Platform (GCP) technologies • Implement real time data pipelines, predictive analytics, machine learning algorithms, and translate data and model results into strategic insights for leadership and business stakeholders • Manage all aspects of program deliverables from project inception to implementation and resource oversight • Traverse complex large datasets to extract business insights that directly help to maintain up-time of critical data center operations, and increase operating efficiency of teams responsible for designing and building Google’s data center footprint  Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",Sunnyvale,US,1671235200,Information
,brQNVLIbITwAAAAAAAAAAA==,CONTRACTOR,Sr. Data Analytics Engineer,https://www.linkedin.com/jobs/view/sr-data-analytics-engineer-at-skiltrek-3589332434,"Description  Description:  Engaging with business and analytic teams to understand data requirements and translating those requirements into technical solutions. Standardizing and implementing operational processes for data delivery, maintaining SLAs and ensuring accuracy  Automating technical solutions the integrate data from a variety of data sources. Spotting and implementing optimizations across data usage from multidisciplinary teams. Ensuring data health and quality through monitoring and alerting tools  Proven experience in  "" Designing, building and maintaining data marts.  "" Programming in Python, SQL (emphasis: postgres) ElasticSearch, GraphQL, and writing efficient and complex queries and ETL jobs that span Terabytes of data  "" Working with Postgres Databases built on AWS or other distributed data technologies  "" Implementing data pipelines and applications in a general programming language such as Python  "" Working with DevOps and Agile methodologies such as JIRA, Jenkins, Gitlab and air flow  "" Understanding of ETL, database and Object Oriented Programming Concepts  "" Building and enhancing existing Tableau dashboards with minimal support  "" Picking up and embracing new technologies and languages  "" Would be nice to have an exposure to large-scale data warehouse solutions such as Snowflake and Redshift  Skills  Python, Sql, Etl, postgresql, Data, Aws, tableau  Top Skills Details  Python,Sql,Etl,postgresql  Additional Skills & Qualifications  This is a Data Analytics/Insights team- will be responsible for providing analytics support/solutions for business stakeholders.  Experience Level  Expert Level  About Us  Skiltrek is an award-winning IT staffing firm and the staffing partner of choice for many leading companies across the US. At Skiltrek, we promise you the perfect opportunity of building technical excellence, understand business performance and nuances, be abreast with the latest happenings in technology world and enjoy a satisfying work life balance.  Skiltrek is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Skiltrek is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.",Cupertino,US,1683004082,
,VIcEneHZaAsAAAAAAAAAAA==,FULLTIME,"Data Scientist/Analyst [R, Python,Google Cloud]","https://www.glassdoor.com/job-listing/data-scientist-analyst-r-python-google-cloud-tsg-engineering-JV_IC1153560_KO0,44_KE45,60.htm?jl=1005787661074","Benefits • TSG Engineering offers a competitive and flexible compensation package for its employees.  Send resumes to: jobs@tsg-eng.com • Network systems and cyber security • Scala, R, Python, Ruby, Java, C, C++ • Data science/machine learning libraries, algorithms and tools • Big data and analysis platforms (Spark, Hadoop, Kafka, etc.) • Analytic development on AWS • AI work experience, Machine Learning, Statistical Models, and Natural Language Processing  - Security Clearance Required",Ellicott City,US,1680652800,
http://www.nfiindustries.com,mqz1cb2K3lYAAAAAAAAAAA==,FULLTIME,Principal Data Engineer,https://careers.nfiindustries.com/us/en/job/NFINUSPRINC021942EXTERNALENUS/Principal-Data-Engineer,"At NFI, we offer innovative, integrated, and customized solutions that span the entire supply chain. Whatever our customer’s challenge is, we have the knowledge, technology, scale, and commitment to help them solve it. It’s simply what we do.  The NFI Data and Analytics team is looking for an experienced Principal Data Engineer to join our growing team to support NFI’s needs for enterprise data services to support data-driven analytics and reporting. Guided by NFI’s shared values, we work in an environment where collaboration, teamwork, respect, and openness are highly valued.  This is an opportunity to join NFI on its journey to become a data-driven organization, continue to develop its data analytics discipline and integrate best practices into the data environment. The ideal candidate will have solid experience in data architecture, and data engineering in a Cloud environment and big data platforms to process enterprise data for high throughput. High-level responsibilities will include designing, creating, deploying, and managing data pipelines in a cloud data analytics environment.  Essential Duties & Responsibilities: • Work with the team and key business partners to evaluate business needs and priorities, define solutions, and address data pipeline and data management needs. • Translate business requirements into technical specifications; establish and define details, definitions, and data requirements for applications, reporting, and analytics. • Architect large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud, Azure, or AWS. • Generate database design, development, test plans, logical and physical ER diagrams, and ETL in support of integration, application development, and analytics teams. • Ensure that designs meet needs for fault tolerance, resiliency, and affordability. • Continuously optimize the data infrastructure to improve performance, reliability, and scalability • Use an analytical, data-driven approach to drive a deep understanding of fast-changing business. • Work with a team to build, implement and maintain a new data platform using cloud data technology to handle data ingestion, data transformation, data storage, etc. • Build large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud Platform or AWS, or Azure. • Mentor team members in developing standards, and best practices for using cloud services, data architectures, data platform design, and data operations.  Job-Specific Requirements: • Bachelor’s degree in Computer Science, Information Systems, or a related discipline. • 5+ years’ experience in IT/Data Engineering with expert-level hands-on experience in building large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud or AWS, or Azure. • Expert in data pipeline design, engineering, and implementation of data lake, warehouse, and Lakehouse architecture. • Expert-level hands-on experience with SQL, ETL, Data Integration tools, Big Data tools, and database engineering. • Expertise in data modeling for star schema/Kimball and relational modeling to 3rd normal form, or BCNF. • Proficient in programming languages such as Python, Java, or Scala. • Proficient in using one of the data warehouse platforms, Big Query, Redshift, Synapse, or Snowflake. • Experience with data processing frameworks like Apache Beam, Spark, PySpark, Apache Kafka, and Apache Airflow. • Experience in engineering enterprise data environments including database design, master data management, metadata, and performance tuning for analytics. • Experience with SSIS, Azure Data Factory, Big Data/Hadoop, Big Data/Databricks, R, etc. • Experience with Data Analytics and visualization tools such as Power BI, Looker, or Tableau. • Experience with Data Science and AI/ML tools and technologies is a plus. • Familiarity with RPA tools like PowerAutomate, UIPath, and/or Automation 360 and Terraform is a plus. • Experience with Master Data Management tools such as Reltio or similar is a plus. • Certification in Cloud Data Engineering or Data Architecture is a plus. • Experience with Retail Distribution, 3PL, or Transportation Logistics is a plus.  Expected Competencies: • Functional Expertise: Possesses the skills and knowledge needed to perform essential functions efficiently and effectively • Communication and Collaboration: Communicates openly and honestly. Follows through on commitments. Takes ownership and does not misrepresent information. Supports colleague and team efforts • Development: Takes an active role in self-development, seeking to grow job-related knowledge and skills. Empowers and challenges team members to reach their full potential. • Analysis and Decision Making: Uses all available resources to make good decisions. Knows when and how to partner with others when facing a problem. • Results Focus: Action-oriented. Assumes an appropriate level of accountability for goals, critical issues, and performance. • Managing Change and Continuous Improvement: Demonstrates an entrepreneurial mindset towards change. Takes risks, and creates new, and better ways for the organization to be successful.  #LI-BS1  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)",Irving,US,1682695070,Logistics
,hnOBmZ4Bk1cAAAAAAAAAAA==,FULLTIME,Data Engineering Fellow,https://apply.workable.com/murmuration/j/3F0BA13375/,"*This is a remote 10-week paid summer fellowship.*  About Murmuration  Murmuration is a nonprofit organization focused on leveraging civic engagement to drive greater equity. We are committed to transforming public education so that every child – regardless of who they are or where they live – can benefit from the same opportunities afforded by a quality education.  We provide sophisticated tools, data, strategic guidance, and programmatic support to help our partner organizations increase civic engagement and marshal support to drive change at the community level. Our best-in-class data and easy-to-use tools have been used by hundreds of organizations to make informed decisions about who they need to reach and how to achieve and sustain impact – and to put those decisions into action.  Our team includes experts and innovators in data, analytics, and strategy. We are former teachers, organizers, data scientists, and campaign veterans, and we are looking for people whose passion and expertise can help realize our vision.  About the Fellowship  The Murmuration Summer Fellowship provides fellows with the unique opportunity to work closely with Murmuration teams on summer projects while contributing to Murmuration’s commitment to transforming public education across the United States.  Fellows will have meaningful, productive, and engaging summer experiences as they learn and grow with a cohort of peers. They will have the opportunity to learn more about career pathways in education, organizing and advocacy, and data through their project work, fellowship programming, and mentorship with Murmuration staff.  About the Role  The Data Engineering Fellow role offers a variety of opportunities, including engineering tasks related to ETL/ELT data pipelines, testing, integration, systems engineering, design, and analysis. The fellowship will include performance analysis on existing pipeline processes, documentation, and assisting in the design and development of future pipelines. At the end of the summer, this fellow will have migrated 90% of code-embedded transformation from Git to Snowflake, written tests, and documented analyses of the ETL/ELT pipeline process. This person will work with Data Managers and Data Engineers to capture improvements and enhance Murmuration’s pipeline processes. Strong communication skills are a must!  The Data Team is a highly collaborative, friendly, and hard-working group, and we are looking for team members that embody those values. The Data Engineering Fellow will report to the Sr. Data Engineer.  What You’ll Do • Git to Snowflake Migration • Support Data Engineers in enhancing Murmuration Data Pipeline processes, • Collaborate with the Data Managers to understand and analyze the data transformational logic within the Murmuration Data Pipeline, • Document pipeline processes and enhancements, • Work with senior team members to deploy and test applications. • Engineering Collaboration • Work on Murmuration Data Pipelines and organize data on Snowflake, • Contribute to Murmuration’s document page by creating/updating technical documentation, • Assist in architecting, implementing, and deploying new data models and data processes in production, and • Troubleshoot data processing issues  What You Should Have • Murmuration attracts employees with distinctive and diverse backgrounds and accomplishments. Integrity, creativity, flexibility, and drive are key attributes of competitive candidates. The ideal candidate will have: • Education and/or experience in Computer Science; • 1-2 years experience with Python and Object-Oriented programming; • 2-3 years experience working with large-scale databases/cloud databases; • Excellent verbal and written communication skills.  What You Might Have • 1-2 years experience in version control systems (e.g. SVN, GIT, etc.); • 1-2 years working with data transformation systems (e.g. AIrflow, dbt, etc.); • Experience within a support team providing technical support to other data functions (e.g. Data Scientists, Data Managers, etc.); • Working knowledge of SQL, Bash, or similar; and • Practical knowledge of software development lifecycle (SDLC).  Note: If you’re passionate about data engineering and civic engagement, please apply, even if you don’t check every box!  Location, Compensation, and Benefits  The Data Engineering Fellow is a full-time summer position. Compensation for the 10-week fellowship is $8,000. It is based anywhere in the U.S.  An Equal-Opportunity Employer with a Commitment to Diversity  Murmuration is proud to be an equal opportunity employer, and as an organization committed to diversity and the perspective of all voices, we consider applicants equally of race, gender, color, sexual orientation, religion, marital status, disability, political affiliation and national origin. We reasonably accommodate staff members and/or applicants with disabilities, provided they are otherwise able to perform the essential functions of the job.",,US,1678320000,
http://www.redventures.com,56vQpuk7Z2oAAAAAAAAAAA==,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-red-ventures-3570454427,"Job Title: Data Engineer  Job Location: 1101 Red Ventures Drive, Fort Mill, SC 29707  Description Of Duties  Two Data Engineers sought by RBUS, Inc., a Red Ventures Company, for its office in Ft. Mill, South Carolina to to build & maintain data products and create end to end solutions. Job duties include build ETL pipelines, develop operational efficiency solutions, root cause analysis, data analysis, and optimization of scripts.  Rate of Pay: $121,000.00 to $125,000.00/year  Minimum Job Requirements  4 years of experience in the job offered or related occupation such as Business Data Analyst, or Application Developer is required and must include: 3.5 years of experience conducting root cause analysis on data quality using SSIS packages, QlikView, Power BI, SSRS and SAP Crystal reports to create solutions; 3.5 years of experience architecting optimizations using Qlikview, Power BI, SAP Crystal reports, SSRS to perform data analysis on operational metrics, KPI and productivity; 3 years of experience building ETL data pipelines for data containing PII using SSIS packages built with Visual Studio data tool for Microsoft SQL Server Data warehouse; 3 years of experience using QlikView NPrinting, CRM, ADP report delivery through Biztalk server using secure FTP adapter with internal & external customers to improve operational efficiency and 4 years of experience optimizing T-SQL, PL/SQL scripts to improve data efficiency, reduce data load time and troubleshoot execution plan. Employer will accept any suitable combination of education, training, and experience.  Applicants are to Respond to: RBUS, Inc., A Red Ventures Company, 1101 Red Ventures Drive, Fort Mill, SC 29707 Attn: HR, Req. #1026.  If you are based in California, we encourage you to read this important information for California residents linked here.",Fort Mill,US,1682629799,Consulting
https://www.thermofisher.com/us/en/home.html,5DFQnmriJMEAAAAAAAAAAA==,FULLTIME,Sr. Data Analyst,https://3.136.182.153/offer/656841/sr-data-analyst,"Partner with business leaders and leverage strong analytical skills to recommend KPIs and targets that will generate meaningful insights for the business.  Interpret business performance results and provide recommendations to the business on where to focus improvement efforts; partner with the development team to automate analysis.  Understand business challenges in the areas of commercial, marketing and service, and use advanced analytics capabilities to mine data and recommend data science solutions.  Provide on-going analysis services to the IES business at large.  Contribute to building and maintaining analytics solutions using PowerBI and existing data warehouse solutions.  Contribute to and help enable the strategy to build data lake and data infrastructure in Amazon Web Service environment needed to expand analytics capabilities in the future.  REQUIREMENTS: Master’s degree in Data Analytics, Business Analytics, Business Intelligence, or related field of study plus 3 years of data analysis or related experience. Experience may be gained concurrently through graduate level course work and/or internships. Employer also accepts a Bachelor’s degree in Data Analytics, Business Analytics, Business Intelligence, or related field of study plus 5 years of data analysis or related experience.  Must have experience or knowledge of: • Data Mining: R, Python, MATLAB, SAS; • Visualization and analytics: Tableau, Power BI, Excel, R Shiny; • Database querying: SQL, PostgreSQL, Mysql, Microsoft Access, Oracle Sql; • Project management: Gitlab, Github, JIRA; • Cloud resources: AWS S3, AWS EC2; and • Machine learning: Regression, Classification, Clustering, neural networks, Ensemble-based models.  SALARY: $139,568 - $166,400/year",Carlsbad,US,1680998400,Manufacturing
http://www.boozallen.com,R8M91SI1Oy0AAAAAAAAAAA==,FULLTIME,"Big Data Engineer, Mid",https://careers.boozallen.com/teams/JobDetail/Norfolk-Big-Data-Engineer-Mid-R0170675/78832,"Big Data Engineer, Mid  The Opportunity:  Do you want to work at the forefront of advanced technology and solve complex data challenges? You know that data yields pivotal insights when it’s gathered from disparate sources and organized. As a data engineer, you have the chance to develop and deploy the pipelines and platforms that make this data meaningful. What’s more, you’ll have the chance to help grow Booz Allen’s DataOps capabilities while working with a multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in a fast-paced, agile environment. We’re looking for someone like you to work with our clients and meet their mission by working with a multi-disciplinary team of analysts, data engineers, data scientists, developers, machine learning engineers, and data consumers in a fast-paced agile environment.  This is an opportunity to implement data engineering activities on some of the most mission-driven projects in the industry. Supporting a multitude of clients across numerous domains, you’ll have the chance to architect data systems, stand up data platforms, build out ETL pipelines, develop custom tooling, interface with data stores, and manage data life cycle operations. From sharing your skills in analytical exploration and examination of data to supporting the assessment, design, building, and maintenance of scalable platforms, you’ll work with our clients to solve their most pressing challenges.  Ready to help drive innovation using cutting-edge data tools and techniques?  Join us. The world can’t wait.  You Have: • 3+ years of experience in a professional work environment • 3+ years of experience with designing, developing, operationalizing, and maintaining complex data applications at an enterprise scale • 3+ years of experience with creating data solutions in SQL or scripting languages to retrieve, parse, and process structured and unstructured data • 3+ years of experience with building scalable Extract Transform Load (ETL) processes for reporting and analytics • Experience with management consulting techniques, including client interviews, data gathering, and problem-solving • Experience with using Microsoft Excel and Access • Ability to develop scripts and programs for converting types of data into usable formats and support project team to scale, monitor and operate data platforms • Ability to obtain a security clearance • Bachelor’s degree  Nice If You Have: • Experience with GitHub or version control systems • Experience with UNIX/Linux, including basic commands and Shell scripting • Experience with Microsoft Visual Basic for Applications (VBA) • Experience with a public cloud, including AWS, Microsoft Azure, or Google Cloud • Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka • Experience with NoSQL implementation, including MongoDB or Cassandra • Experience with data warehousing using AWS Redshift, MySQL, or Snowflake • Experience with Agile engineering practices and working on real-time data and streaming applications • Experience with data visualization tools, including Tableau, QlikSense, or Microsoft Power BI • Bachelor’s degree in Economics, Operations Research, Management Science, Mathematics, or Statistics  ​  Clearance:  ​​Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.  Create Your Career:  At Booz Allen, we know the power of analytics and we’re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you’ll have the chance to: • access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk • change the world with the Data Science Bowl—the world’s premier data science for social good competition • participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government  You’ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We’ll help you develop the career you want as you chart your own course for success.  Compensation  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.  Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. • If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. • If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.  EEO Commitment  We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",Norfolk,US,1683072000,Consulting
,_GrabFV1Q3kAAAAAAAAAAA==,CONTRACTOR,Data Analyst with Salesforce Experience,https://www.linkedin.com/jobs/view/data-analyst-with-salesforce-experience-at-zettalogix-inc-3588948048,"Job Role: Data Analyst with Salesforce Experience  Location: Remote  Duration: 6+ Months Contract  Visa: Any  Job Responsibilities:  -This individual should have a strong track record of executing well on daily tasks and have experience in importing, exporting, cleaning, transforming, validating and modeling data, especially in a MS Excel and Salesforce.com environment.  -Responsible for maintenance, administration and support of data elements  -Ensures metadata, reference documentation, data files and data flows are accurate and up to date  -Support with data validation, quality issues, integrity, accuracy, consistency and works to resolve impacting issues related to data elements; de-duplication and cleaning  -Assisting with data analysis in Salesforce and Excel as needed  -Salesforce experience is essential",New York,US,1682966998,
http://www.honda.co.jp,1_BpS8dliToAAAAAAAAAAA==,FULLTIME,Data Analyst,https://www.karkidi.com/job-details/30739-data-analyst-job,"What Makes a Honda, is Who makes a Honda  Honda has a clear vision for the future, and it’s a joyful one. We are looking for individuals with the skills, courage, persistence, and dreams that will help us reach our future-focused goals.  At our core is innovation. Honda is constantly innovating and developing solutions to drive our business with record success. We strive to be a company which serves as a source of power that supports people around the world who are trying to do things based on their own initiative and that helps people expand their own potential. To this end, Honda strives to realize the joy and freedom of mobility by developing new technologies and an innovative approach to achieve a zero environmental footprint.  We are looking for qualified individuals with diverse backgrounds, experiences, continuous improvement values, and a strong work ethic to join our team.  If your goals and values align with Honda’s, we want you to join our team to Bring the Future!  About this Position:  This role revolves around identifying, planning, and implementing system improvements and applies analytics from proof-of-concept to production. The Data Analytics Engineer generates new ideas to derive value from data and assists in project scoping, design, data analysis, and execution.  Responsibilities include: • Development of standard procedures and best practices for data analytics projects. • Development of models and dashboards for use by all levels of the organization. • Development of processes and tools to monitor and analyze model performance and data accuracy. • Present results to senior management as required. • Mentor associates in analytics tools and projects. • Advises and coaches leaders on how to adopt new ideologies to transform outcomes  Who we are seeking:  Required Work Experience: • 2-6 years Applicable Experience  Required Education: • Bachelors’ degree in engineering, data analytics, data science, mis, computer science; or equivalent relevant experience.  Desired skills: • Experience with open-source data analytics in python and/or r (data mining, data modelling) • Data visualization tools (tableau, power bi, plotly, etc) • Experienced VBA/SQL Skills • Ability to multitask and manage projects effectively  Additional Position Factors: • Support Division activity at all HDMA sites as well as NA Activity. • Work in a fast-paced environment with demanding and critical deadlines. • Average overtime hours of 3-5 hours per week • Virtual Work Environment • Potential for limited travel",Marysville,US,1674777600,Manufacturing
